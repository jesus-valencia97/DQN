{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFz_NRKrx_hl"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from collections import deque \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  0\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Gy5DCfcRyGOI"
      },
      "outputs": [],
      "source": [
        "X,y = make_classification(15_000,500,random_state=50,weights=[0.9])\n",
        "X, X_validate, y, y_validate = train_test_split(X,y, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =  0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train_ = X_train.copy()\n",
        "# y_train_ = y_train.copy()\n",
        "# rng_idx = pd.Series(y_train).sample(len(y_train)).index\n",
        "# X_train_ = X_train_[rng_idx]\n",
        "# y_train_ = y_train_[rng_idx]\n",
        "# M_idx, m_idx = pd.DataFrame(y_train_).groupby(0).apply(lambda x: x.index.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pd.Series(y_train).value_counts()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bal_idx = pd.DataFrame(y_train, columns = ['y']).groupby('y').apply(lambda x: x.sample(250)).index.to_frame()[1].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rng = np.random.default_rng(1235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rng.shuffle(bal_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_bal = X_train[bal_idx]\n",
        "# y_bal = y_train[bal_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 235,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_bal = X_train.copy()\n",
        "# y_bal = y_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 236,
      "metadata": {},
      "outputs": [],
      "source": [
        "# M_idx, m_idx = pd.DataFrame(y_bal).groupby(0).apply(lambda x: x.index.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 262,
      "metadata": {
        "id": "lC5LkJ-6zCIF"
      },
      "outputs": [],
      "source": [
        "%run -i ./DQN_Class.py\n",
        "gamma=0.5\n",
        "epsilon=.8\n",
        "numberEpisodes= 120\n",
        "LearningQDeep=DeepQLearning(gamma,epsilon,numberEpisodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NN approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 263,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "nn = LearningQDeep.buildNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_95\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_355 (Dense)           (None, 30)                15030     \n",
            "                                                                 \n",
            " dense_356 (Dense)           (None, 64)                1984      \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_357 (Dense)           (None, 20)                1300      \n",
            "                                                                 \n",
            " dense_358 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,335\n",
            "Trainable params: 18,335\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 265,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_f1', \n",
        "                                verbose=1,\n",
        "                                patience=100,\n",
        "                                mode='max',\n",
        "                                restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 266,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "106/106 [==============================] - 2s 7ms/step - loss: 0.4291 - recall_m: 0.1144 - precision_m: 0.0462 - f1: 0.0513 - val_loss: 0.3416 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1: 0.0000e+00\n",
            "Epoch 2/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.3112 - recall_m: 0.0267 - precision_m: 0.0943 - f1: 0.0398 - val_loss: 0.3233 - val_recall_m: 0.0000e+00 - val_precision_m: 0.0000e+00 - val_f1: 0.0000e+00\n",
            "Epoch 3/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.2560 - recall_m: 0.0598 - precision_m: 0.1462 - f1: 0.0794 - val_loss: 0.3043 - val_recall_m: 0.0095 - val_precision_m: 0.0283 - val_f1: 0.0128\n",
            "Epoch 4/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.2061 - recall_m: 0.2113 - precision_m: 0.4371 - f1: 0.2641 - val_loss: 0.2875 - val_recall_m: 0.1013 - val_precision_m: 0.2618 - val_f1: 0.1369\n",
            "Epoch 5/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.1515 - recall_m: 0.4342 - precision_m: 0.7162 - f1: 0.5070 - val_loss: 0.2735 - val_recall_m: 0.2546 - val_precision_m: 0.5002 - val_f1: 0.3103\n",
            "Epoch 6/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.1046 - recall_m: 0.7010 - precision_m: 0.8715 - f1: 0.7533 - val_loss: 0.2918 - val_recall_m: 0.2782 - val_precision_m: 0.5265 - val_f1: 0.3339\n",
            "Epoch 7/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0732 - recall_m: 0.7851 - precision_m: 0.9085 - f1: 0.8248 - val_loss: 0.2952 - val_recall_m: 0.3401 - val_precision_m: 0.5700 - val_f1: 0.3913\n",
            "Epoch 8/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0480 - recall_m: 0.8580 - precision_m: 0.9214 - f1: 0.8753 - val_loss: 0.3144 - val_recall_m: 0.3633 - val_precision_m: 0.5684 - val_f1: 0.4053\n",
            "Epoch 9/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0307 - recall_m: 0.8989 - precision_m: 0.9231 - f1: 0.9041 - val_loss: 0.3505 - val_recall_m: 0.3542 - val_precision_m: 0.5819 - val_f1: 0.4028\n",
            "Epoch 10/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0179 - recall_m: 0.9343 - precision_m: 0.9544 - f1: 0.9404 - val_loss: 0.3605 - val_recall_m: 0.3876 - val_precision_m: 0.5828 - val_f1: 0.4280\n",
            "Epoch 11/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0112 - recall_m: 0.9651 - precision_m: 0.9698 - f1: 0.9669 - val_loss: 0.3943 - val_recall_m: 0.3747 - val_precision_m: 0.5862 - val_f1: 0.4181\n",
            "Epoch 12/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0092 - recall_m: 0.9101 - precision_m: 0.9245 - f1: 0.9158 - val_loss: 0.4112 - val_recall_m: 0.3803 - val_precision_m: 0.5940 - val_f1: 0.4264\n",
            "Epoch 13/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0054 - recall_m: 0.8994 - precision_m: 0.9057 - f1: 0.9017 - val_loss: 0.4199 - val_recall_m: 0.3980 - val_precision_m: 0.5910 - val_f1: 0.4382\n",
            "Epoch 14/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0047 - recall_m: 0.9772 - precision_m: 0.9769 - f1: 0.9765 - val_loss: 0.4398 - val_recall_m: 0.3908 - val_precision_m: 0.6007 - val_f1: 0.4366\n",
            "Epoch 15/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.0036 - recall_m: 0.9497 - precision_m: 0.9528 - f1: 0.9509 - val_loss: 0.4579 - val_recall_m: 0.3908 - val_precision_m: 0.6082 - val_f1: 0.4395\n",
            "Epoch 16/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.0028 - recall_m: 0.9686 - precision_m: 0.9717 - f1: 0.9698 - val_loss: 0.4745 - val_recall_m: 0.3906 - val_precision_m: 0.6124 - val_f1: 0.4400\n",
            "Epoch 17/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.0022 - recall_m: 0.9675 - precision_m: 0.9717 - f1: 0.9693 - val_loss: 0.4854 - val_recall_m: 0.3946 - val_precision_m: 0.6061 - val_f1: 0.4427\n",
            "Epoch 18/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 0.0014 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.4962 - val_recall_m: 0.3925 - val_precision_m: 0.6121 - val_f1: 0.4413\n",
            "Epoch 19/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0016 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.5046 - val_recall_m: 0.3960 - val_precision_m: 0.6055 - val_f1: 0.4420\n",
            "Epoch 20/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0011 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.5144 - val_recall_m: 0.3921 - val_precision_m: 0.6022 - val_f1: 0.4370\n",
            "Epoch 21/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 8.8127e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.5235 - val_recall_m: 0.3940 - val_precision_m: 0.5982 - val_f1: 0.4390\n",
            "Epoch 22/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 9.7496e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.5306 - val_recall_m: 0.3990 - val_precision_m: 0.6046 - val_f1: 0.4423\n",
            "Epoch 23/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 6.0480e-04 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.5400 - val_recall_m: 0.3963 - val_precision_m: 0.6018 - val_f1: 0.4392\n",
            "Epoch 24/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 6.2463e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.5477 - val_recall_m: 0.3957 - val_precision_m: 0.6101 - val_f1: 0.4418\n",
            "Epoch 25/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.2778e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.5569 - val_recall_m: 0.3856 - val_precision_m: 0.5972 - val_f1: 0.4308\n",
            "Epoch 26/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.3887e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.5668 - val_recall_m: 0.3841 - val_precision_m: 0.6028 - val_f1: 0.4322\n",
            "Epoch 27/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.1277e-04 - recall_m: 1.0000 - precision_m: 1.0000 - f1: 1.0000 - val_loss: 0.5753 - val_recall_m: 0.3846 - val_precision_m: 0.5991 - val_f1: 0.4323\n",
            "Epoch 28/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 3.3641e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.5774 - val_recall_m: 0.3894 - val_precision_m: 0.6058 - val_f1: 0.4382\n",
            "Epoch 29/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.3865e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.5810 - val_recall_m: 0.3907 - val_precision_m: 0.6026 - val_f1: 0.4377\n",
            "Epoch 30/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.9402e-04 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.5887 - val_recall_m: 0.3957 - val_precision_m: 0.6030 - val_f1: 0.4408\n",
            "Epoch 31/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.9744e-04 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.5917 - val_recall_m: 0.3942 - val_precision_m: 0.6050 - val_f1: 0.4398\n",
            "Epoch 32/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.6644e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6002 - val_recall_m: 0.3911 - val_precision_m: 0.6026 - val_f1: 0.4374\n",
            "Epoch 33/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.3838e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.6094 - val_recall_m: 0.3890 - val_precision_m: 0.6054 - val_f1: 0.4371\n",
            "Epoch 34/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.8522e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6191 - val_recall_m: 0.3857 - val_precision_m: 0.6123 - val_f1: 0.4360\n",
            "Epoch 35/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.9732e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6212 - val_recall_m: 0.3890 - val_precision_m: 0.6102 - val_f1: 0.4389\n",
            "Epoch 36/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.6515e-04 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.6278 - val_recall_m: 0.3850 - val_precision_m: 0.6075 - val_f1: 0.4352\n",
            "Epoch 37/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.7379e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6335 - val_recall_m: 0.3864 - val_precision_m: 0.6048 - val_f1: 0.4355\n",
            "Epoch 38/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.7673e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6365 - val_recall_m: 0.3908 - val_precision_m: 0.6050 - val_f1: 0.4399\n",
            "Epoch 39/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.3779e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6412 - val_recall_m: 0.3888 - val_precision_m: 0.6048 - val_f1: 0.4375\n",
            "Epoch 40/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.0699e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6466 - val_recall_m: 0.3839 - val_precision_m: 0.6052 - val_f1: 0.4340\n",
            "Epoch 41/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.2164e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6529 - val_recall_m: 0.3816 - val_precision_m: 0.6065 - val_f1: 0.4325\n",
            "Epoch 42/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1634e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.6586 - val_recall_m: 0.3836 - val_precision_m: 0.6079 - val_f1: 0.4351\n",
            "Epoch 43/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 8.3482e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6637 - val_recall_m: 0.3820 - val_precision_m: 0.6025 - val_f1: 0.4317\n",
            "Epoch 44/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 9.6733e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6688 - val_recall_m: 0.3817 - val_precision_m: 0.6112 - val_f1: 0.4331\n",
            "Epoch 45/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.6417e-05 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.6725 - val_recall_m: 0.3835 - val_precision_m: 0.6092 - val_f1: 0.4334\n",
            "Epoch 46/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.2685e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.6764 - val_recall_m: 0.3828 - val_precision_m: 0.6115 - val_f1: 0.4348\n",
            "Epoch 47/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.1963e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6789 - val_recall_m: 0.3957 - val_precision_m: 0.6200 - val_f1: 0.4437\n",
            "Epoch 48/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.7851e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6835 - val_recall_m: 0.4018 - val_precision_m: 0.6141 - val_f1: 0.4460\n",
            "Epoch 49/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.2582e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.6945 - val_recall_m: 0.4023 - val_precision_m: 0.6218 - val_f1: 0.4492\n",
            "Epoch 50/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 9.3154e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.7069 - val_recall_m: 0.3982 - val_precision_m: 0.6202 - val_f1: 0.4452\n",
            "Epoch 51/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 6.3351e-05 - recall_m: 0.9057 - precision_m: 0.9057 - f1: 0.9057 - val_loss: 0.7148 - val_recall_m: 0.4002 - val_precision_m: 0.6323 - val_f1: 0.4497\n",
            "Epoch 52/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 5.4178e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7193 - val_recall_m: 0.3993 - val_precision_m: 0.6301 - val_f1: 0.4490\n",
            "Epoch 53/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.6905e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7221 - val_recall_m: 0.3981 - val_precision_m: 0.6303 - val_f1: 0.4483\n",
            "Epoch 54/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 6.1690e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.7270 - val_recall_m: 0.4002 - val_precision_m: 0.6287 - val_f1: 0.4493\n",
            "Epoch 55/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.2363e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7294 - val_recall_m: 0.4054 - val_precision_m: 0.6314 - val_f1: 0.4539\n",
            "Epoch 56/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.0028e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.7447 - val_recall_m: 0.3986 - val_precision_m: 0.6189 - val_f1: 0.4460\n",
            "Epoch 57/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.1311e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.7645 - val_recall_m: 0.3967 - val_precision_m: 0.6222 - val_f1: 0.4484\n",
            "Epoch 58/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.6988e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7668 - val_recall_m: 0.3962 - val_precision_m: 0.6210 - val_f1: 0.4470\n",
            "Epoch 59/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.8135e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.7859 - val_recall_m: 0.4199 - val_precision_m: 0.6074 - val_f1: 0.4563\n",
            "Epoch 60/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.1277e-04 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.8024 - val_recall_m: 0.4056 - val_precision_m: 0.5880 - val_f1: 0.4410\n",
            "Epoch 61/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.4381e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8368 - val_recall_m: 0.4042 - val_precision_m: 0.5694 - val_f1: 0.4352\n",
            "Epoch 62/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0389 - recall_m: 0.9211 - precision_m: 0.9227 - f1: 0.9157 - val_loss: 0.7912 - val_recall_m: 0.3902 - val_precision_m: 0.5261 - val_f1: 0.4095\n",
            "Epoch 63/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0432 - recall_m: 0.9035 - precision_m: 0.9146 - f1: 0.8993 - val_loss: 0.5697 - val_recall_m: 0.4330 - val_precision_m: 0.5855 - val_f1: 0.4595\n",
            "Epoch 64/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0063 - recall_m: 0.9277 - precision_m: 0.9396 - f1: 0.9312 - val_loss: 0.5791 - val_recall_m: 0.4420 - val_precision_m: 0.5836 - val_f1: 0.4685\n",
            "Epoch 65/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0023 - recall_m: 0.9580 - precision_m: 0.9623 - f1: 0.9599 - val_loss: 0.6053 - val_recall_m: 0.4459 - val_precision_m: 0.5861 - val_f1: 0.4700\n",
            "Epoch 66/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0013 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.6279 - val_recall_m: 0.4397 - val_precision_m: 0.5879 - val_f1: 0.4665\n",
            "Epoch 67/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.4226e-04 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.6448 - val_recall_m: 0.4417 - val_precision_m: 0.5957 - val_f1: 0.4708\n",
            "Epoch 68/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.1103e-04 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.6535 - val_recall_m: 0.4453 - val_precision_m: 0.6019 - val_f1: 0.4732\n",
            "Epoch 69/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.0938e-04 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.6677 - val_recall_m: 0.4437 - val_precision_m: 0.6051 - val_f1: 0.4751\n",
            "Epoch 70/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.3606e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.6866 - val_recall_m: 0.4396 - val_precision_m: 0.6077 - val_f1: 0.4740\n",
            "Epoch 71/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.3504e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.6993 - val_recall_m: 0.4341 - val_precision_m: 0.6039 - val_f1: 0.4684\n",
            "Epoch 72/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.3069e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.7093 - val_recall_m: 0.4284 - val_precision_m: 0.6076 - val_f1: 0.4672\n",
            "Epoch 73/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.3863e-04 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.7166 - val_recall_m: 0.4264 - val_precision_m: 0.6019 - val_f1: 0.4636\n",
            "Epoch 74/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.6449e-04 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.7205 - val_recall_m: 0.4417 - val_precision_m: 0.6061 - val_f1: 0.4745\n",
            "Epoch 75/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.8361e-04 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.7281 - val_recall_m: 0.4422 - val_precision_m: 0.6081 - val_f1: 0.4758\n",
            "Epoch 76/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.5790e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.7364 - val_recall_m: 0.4417 - val_precision_m: 0.6118 - val_f1: 0.4767\n",
            "Epoch 77/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.4527e-04 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 0.7461 - val_recall_m: 0.4362 - val_precision_m: 0.6068 - val_f1: 0.4707\n",
            "Epoch 78/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1949e-04 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.7515 - val_recall_m: 0.4366 - val_precision_m: 0.6086 - val_f1: 0.4720\n",
            "Epoch 79/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.6081e-04 - recall_m: 0.9137 - precision_m: 0.9151 - f1: 0.9144 - val_loss: 0.7407 - val_recall_m: 0.4525 - val_precision_m: 0.6032 - val_f1: 0.4779\n",
            "Epoch 80/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1867e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7474 - val_recall_m: 0.4525 - val_precision_m: 0.6046 - val_f1: 0.4783\n",
            "Epoch 81/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.4412e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.7543 - val_recall_m: 0.4518 - val_precision_m: 0.6044 - val_f1: 0.4779\n",
            "Epoch 82/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3436e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.7625 - val_recall_m: 0.4518 - val_precision_m: 0.6112 - val_f1: 0.4801\n",
            "Epoch 83/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1488e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7666 - val_recall_m: 0.4568 - val_precision_m: 0.6148 - val_f1: 0.4845\n",
            "Epoch 84/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3079e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.7728 - val_recall_m: 0.4568 - val_precision_m: 0.6120 - val_f1: 0.4838\n",
            "Epoch 85/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 7.9928e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.7791 - val_recall_m: 0.4568 - val_precision_m: 0.6121 - val_f1: 0.4835\n",
            "Epoch 86/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 8.6944e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.7868 - val_recall_m: 0.4568 - val_precision_m: 0.6121 - val_f1: 0.4835\n",
            "Epoch 87/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 5.0269e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.7928 - val_recall_m: 0.4568 - val_precision_m: 0.6141 - val_f1: 0.4849\n",
            "Epoch 88/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 5.1175e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.7990 - val_recall_m: 0.4519 - val_precision_m: 0.6101 - val_f1: 0.4806\n",
            "Epoch 89/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.5126e-05 - recall_m: 1.0000 - precision_m: 1.0000 - f1: 1.0000 - val_loss: 0.8061 - val_recall_m: 0.4527 - val_precision_m: 0.6124 - val_f1: 0.4826\n",
            "Epoch 90/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 8.6179e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8127 - val_recall_m: 0.4503 - val_precision_m: 0.6150 - val_f1: 0.4816\n",
            "Epoch 91/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.5688e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.8170 - val_recall_m: 0.4518 - val_precision_m: 0.6139 - val_f1: 0.4823\n",
            "Epoch 92/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3470e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.8266 - val_recall_m: 0.4512 - val_precision_m: 0.6253 - val_f1: 0.4859\n",
            "Epoch 93/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.9490e-05 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 0.8329 - val_recall_m: 0.4512 - val_precision_m: 0.6253 - val_f1: 0.4859\n",
            "Epoch 94/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.4249e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.8381 - val_recall_m: 0.4475 - val_precision_m: 0.6223 - val_f1: 0.4827\n",
            "Epoch 95/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.0032e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.8436 - val_recall_m: 0.4475 - val_precision_m: 0.6203 - val_f1: 0.4826\n",
            "Epoch 96/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.7417e-05 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.8483 - val_recall_m: 0.4475 - val_precision_m: 0.6203 - val_f1: 0.4826\n",
            "Epoch 97/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.7338e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8537 - val_recall_m: 0.4475 - val_precision_m: 0.6203 - val_f1: 0.4826\n",
            "Epoch 98/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.4509e-05 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 0.8614 - val_recall_m: 0.4453 - val_precision_m: 0.6191 - val_f1: 0.4804\n",
            "Epoch 99/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.5431e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.8675 - val_recall_m: 0.4445 - val_precision_m: 0.6208 - val_f1: 0.4808\n",
            "Epoch 100/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.1846e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8740 - val_recall_m: 0.4432 - val_precision_m: 0.6208 - val_f1: 0.4798\n",
            "Epoch 101/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.7123e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.8806 - val_recall_m: 0.4403 - val_precision_m: 0.6188 - val_f1: 0.4771\n",
            "Epoch 102/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.9854e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8819 - val_recall_m: 0.4440 - val_precision_m: 0.6172 - val_f1: 0.4787\n",
            "Epoch 103/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.5975e-05 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 0.8857 - val_recall_m: 0.4450 - val_precision_m: 0.6158 - val_f1: 0.4787\n",
            "Epoch 104/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.3949e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8900 - val_recall_m: 0.4450 - val_precision_m: 0.6158 - val_f1: 0.4787\n",
            "Epoch 105/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.6422e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.8960 - val_recall_m: 0.4450 - val_precision_m: 0.6158 - val_f1: 0.4787\n",
            "Epoch 106/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.1701e-05 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 0.9086 - val_recall_m: 0.4391 - val_precision_m: 0.6162 - val_f1: 0.4740\n",
            "Epoch 107/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.2327e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9124 - val_recall_m: 0.4391 - val_precision_m: 0.6162 - val_f1: 0.4740\n",
            "Epoch 108/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.8409e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9141 - val_recall_m: 0.4414 - val_precision_m: 0.6169 - val_f1: 0.4758\n",
            "Epoch 109/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.7368e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9215 - val_recall_m: 0.4398 - val_precision_m: 0.6182 - val_f1: 0.4758\n",
            "Epoch 110/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.4171e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9245 - val_recall_m: 0.4426 - val_precision_m: 0.6198 - val_f1: 0.4784\n",
            "Epoch 111/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 8.4217e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9279 - val_recall_m: 0.4426 - val_precision_m: 0.6198 - val_f1: 0.4784\n",
            "Epoch 112/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3891e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9309 - val_recall_m: 0.4426 - val_precision_m: 0.6198 - val_f1: 0.4784\n",
            "Epoch 113/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.3515e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9291 - val_recall_m: 0.4536 - val_precision_m: 0.6188 - val_f1: 0.4832\n",
            "Epoch 114/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.1711e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9373 - val_recall_m: 0.4528 - val_precision_m: 0.6244 - val_f1: 0.4842\n",
            "Epoch 115/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.0866e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9424 - val_recall_m: 0.4508 - val_precision_m: 0.6257 - val_f1: 0.4834\n",
            "Epoch 116/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.5306e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9461 - val_recall_m: 0.4528 - val_precision_m: 0.6254 - val_f1: 0.4834\n",
            "Epoch 117/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3309e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9494 - val_recall_m: 0.4528 - val_precision_m: 0.6261 - val_f1: 0.4841\n",
            "Epoch 118/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 6.0612e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9526 - val_recall_m: 0.4528 - val_precision_m: 0.6261 - val_f1: 0.4841\n",
            "Epoch 119/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1632e-05 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.9609 - val_recall_m: 0.4508 - val_precision_m: 0.6257 - val_f1: 0.4834\n",
            "Epoch 120/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.9275e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9650 - val_recall_m: 0.4508 - val_precision_m: 0.6257 - val_f1: 0.4834\n",
            "Epoch 121/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.2374e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9681 - val_recall_m: 0.4519 - val_precision_m: 0.6176 - val_f1: 0.4816\n",
            "Epoch 122/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 3.7812e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9710 - val_recall_m: 0.4559 - val_precision_m: 0.6197 - val_f1: 0.4853\n",
            "Epoch 123/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.3719e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9771 - val_recall_m: 0.4554 - val_precision_m: 0.6238 - val_f1: 0.4860\n",
            "Epoch 124/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.2108e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9804 - val_recall_m: 0.4541 - val_precision_m: 0.6232 - val_f1: 0.4841\n",
            "Epoch 125/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.5150e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.9857 - val_recall_m: 0.4541 - val_precision_m: 0.6242 - val_f1: 0.4852\n",
            "Epoch 126/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.1616e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9903 - val_recall_m: 0.4541 - val_precision_m: 0.6249 - val_f1: 0.4855\n",
            "Epoch 127/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.3341e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9977 - val_recall_m: 0.4498 - val_precision_m: 0.6296 - val_f1: 0.4855\n",
            "Epoch 128/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.6659e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0031 - val_recall_m: 0.4569 - val_precision_m: 0.6196 - val_f1: 0.4862\n",
            "Epoch 129/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.7513e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0101 - val_recall_m: 0.4529 - val_precision_m: 0.6237 - val_f1: 0.4857\n",
            "Epoch 130/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 6.1301e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0132 - val_recall_m: 0.4566 - val_precision_m: 0.6241 - val_f1: 0.4881\n",
            "Epoch 131/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.8099e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0161 - val_recall_m: 0.4560 - val_precision_m: 0.6239 - val_f1: 0.4876\n",
            "Epoch 132/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.5515e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0207 - val_recall_m: 0.4548 - val_precision_m: 0.6235 - val_f1: 0.4866\n",
            "Epoch 133/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.5074e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0299 - val_recall_m: 0.4498 - val_precision_m: 0.6262 - val_f1: 0.4846\n",
            "Epoch 134/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.4748e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0355 - val_recall_m: 0.4437 - val_precision_m: 0.6235 - val_f1: 0.4798\n",
            "Epoch 135/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.6822e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0408 - val_recall_m: 0.4484 - val_precision_m: 0.6294 - val_f1: 0.4852\n",
            "Epoch 136/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.5646e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0440 - val_recall_m: 0.4484 - val_precision_m: 0.6294 - val_f1: 0.4852\n",
            "Epoch 137/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.2354e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0467 - val_recall_m: 0.4485 - val_precision_m: 0.6316 - val_f1: 0.4858\n",
            "Epoch 138/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.2571e-06 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.0519 - val_recall_m: 0.4470 - val_precision_m: 0.6314 - val_f1: 0.4847\n",
            "Epoch 139/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.4714e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0576 - val_recall_m: 0.4470 - val_precision_m: 0.6280 - val_f1: 0.4835\n",
            "Epoch 140/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.5669e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0620 - val_recall_m: 0.4486 - val_precision_m: 0.6287 - val_f1: 0.4849\n",
            "Epoch 141/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0738e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0646 - val_recall_m: 0.4486 - val_precision_m: 0.6287 - val_f1: 0.4849\n",
            "Epoch 142/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.7286e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0677 - val_recall_m: 0.4547 - val_precision_m: 0.6325 - val_f1: 0.4899\n",
            "Epoch 143/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.4172e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0714 - val_recall_m: 0.4567 - val_precision_m: 0.6325 - val_f1: 0.4912\n",
            "Epoch 144/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.1254e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0745 - val_recall_m: 0.4567 - val_precision_m: 0.6325 - val_f1: 0.4912\n",
            "Epoch 145/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.6551e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0789 - val_recall_m: 0.4533 - val_precision_m: 0.6325 - val_f1: 0.4886\n",
            "Epoch 146/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.2325e-06 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.0818 - val_recall_m: 0.4533 - val_precision_m: 0.6325 - val_f1: 0.4886\n",
            "Epoch 147/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.8676e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0872 - val_recall_m: 0.4557 - val_precision_m: 0.6264 - val_f1: 0.4899\n",
            "Epoch 148/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.6647e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0917 - val_recall_m: 0.4557 - val_precision_m: 0.6257 - val_f1: 0.4895\n",
            "Epoch 149/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0421e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0971 - val_recall_m: 0.4543 - val_precision_m: 0.6284 - val_f1: 0.4893\n",
            "Epoch 150/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.5227e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1019 - val_recall_m: 0.4547 - val_precision_m: 0.6210 - val_f1: 0.4873\n",
            "Epoch 151/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.8141e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1050 - val_recall_m: 0.4547 - val_precision_m: 0.6210 - val_f1: 0.4873\n",
            "Epoch 152/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.1114e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1100 - val_recall_m: 0.4574 - val_precision_m: 0.6232 - val_f1: 0.4906\n",
            "Epoch 153/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.0071e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1150 - val_recall_m: 0.4564 - val_precision_m: 0.6239 - val_f1: 0.4899\n",
            "Epoch 154/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.3008e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1188 - val_recall_m: 0.4564 - val_precision_m: 0.6266 - val_f1: 0.4909\n",
            "Epoch 155/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.7609e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1235 - val_recall_m: 0.4564 - val_precision_m: 0.6266 - val_f1: 0.4909\n",
            "Epoch 156/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.6475e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1261 - val_recall_m: 0.4564 - val_precision_m: 0.6266 - val_f1: 0.4909\n",
            "Epoch 157/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.0463e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1301 - val_recall_m: 0.4564 - val_precision_m: 0.6266 - val_f1: 0.4909\n",
            "Epoch 158/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.3370e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1379 - val_recall_m: 0.4564 - val_precision_m: 0.6282 - val_f1: 0.4918\n",
            "Epoch 159/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.6778e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1441 - val_recall_m: 0.4602 - val_precision_m: 0.6297 - val_f1: 0.4943\n",
            "Epoch 160/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.4442e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1487 - val_recall_m: 0.4592 - val_precision_m: 0.6305 - val_f1: 0.4935\n",
            "Epoch 161/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.4132e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.1522 - val_recall_m: 0.4592 - val_precision_m: 0.6305 - val_f1: 0.4935\n",
            "Epoch 162/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.2735e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1602 - val_recall_m: 0.4592 - val_precision_m: 0.6342 - val_f1: 0.4953\n",
            "Epoch 163/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0132e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.1647 - val_recall_m: 0.4585 - val_precision_m: 0.6359 - val_f1: 0.4938\n",
            "Epoch 164/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.9563e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1712 - val_recall_m: 0.4565 - val_precision_m: 0.6352 - val_f1: 0.4926\n",
            "Epoch 165/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.6559e-07 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 1.1739 - val_recall_m: 0.4585 - val_precision_m: 0.6359 - val_f1: 0.4938\n",
            "Epoch 166/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.7547e-07 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1770 - val_recall_m: 0.4585 - val_precision_m: 0.6359 - val_f1: 0.4938\n",
            "Epoch 167/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.1104e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.1835 - val_recall_m: 0.4560 - val_precision_m: 0.6356 - val_f1: 0.4924\n",
            "Epoch 168/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.1618e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1869 - val_recall_m: 0.4560 - val_precision_m: 0.6376 - val_f1: 0.4931\n",
            "Epoch 169/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 9.7075e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1985 - val_recall_m: 0.4528 - val_precision_m: 0.6356 - val_f1: 0.4900\n",
            "Epoch 170/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.8760e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2008 - val_recall_m: 0.4554 - val_precision_m: 0.6376 - val_f1: 0.4925\n",
            "Epoch 171/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.2556e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2077 - val_recall_m: 0.4617 - val_precision_m: 0.6259 - val_f1: 0.4920\n",
            "Epoch 172/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 2.2579e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.2110 - val_recall_m: 0.4617 - val_precision_m: 0.6259 - val_f1: 0.4920\n",
            "Epoch 173/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.0102e-07 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.2185 - val_recall_m: 0.4607 - val_precision_m: 0.6336 - val_f1: 0.4944\n",
            "Epoch 174/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.5452e-07 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.2254 - val_recall_m: 0.4593 - val_precision_m: 0.6370 - val_f1: 0.4941\n",
            "Epoch 175/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.7886e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.2329 - val_recall_m: 0.4559 - val_precision_m: 0.6350 - val_f1: 0.4922\n",
            "Epoch 176/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.5806e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.2409 - val_recall_m: 0.4547 - val_precision_m: 0.6354 - val_f1: 0.4910\n",
            "Epoch 177/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.1533e-07 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 1.2443 - val_recall_m: 0.4547 - val_precision_m: 0.6368 - val_f1: 0.4910\n",
            "Epoch 178/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 9.3958e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.2420 - val_recall_m: 0.4681 - val_precision_m: 0.6322 - val_f1: 0.4975\n",
            "Epoch 179/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3148e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.2464 - val_recall_m: 0.4681 - val_precision_m: 0.6308 - val_f1: 0.4975\n",
            "Epoch 180/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.1035e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.2512 - val_recall_m: 0.4681 - val_precision_m: 0.6308 - val_f1: 0.4975\n",
            "Epoch 181/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.4808e-07 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 1.2583 - val_recall_m: 0.4681 - val_precision_m: 0.6315 - val_f1: 0.4982\n",
            "Epoch 182/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 5.1346e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.3932 - val_recall_m: 0.4176 - val_precision_m: 0.6299 - val_f1: 0.4633\n",
            "Epoch 183/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0115 - recall_m: 0.9403 - precision_m: 0.9446 - f1: 0.9400 - val_loss: 1.2744 - val_recall_m: 0.4782 - val_precision_m: 0.5615 - val_f1: 0.4759\n",
            "Epoch 184/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0445 - recall_m: 0.9008 - precision_m: 0.9119 - f1: 0.9009 - val_loss: 1.0420 - val_recall_m: 0.4577 - val_precision_m: 0.6222 - val_f1: 0.4862\n",
            "Epoch 185/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 0.0148 - recall_m: 0.9603 - precision_m: 0.9593 - f1: 0.9559 - val_loss: 0.9948 - val_recall_m: 0.4473 - val_precision_m: 0.6271 - val_f1: 0.4802\n",
            "Epoch 186/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0026 - recall_m: 0.9564 - precision_m: 0.9599 - f1: 0.9577 - val_loss: 0.9822 - val_recall_m: 0.4694 - val_precision_m: 0.6139 - val_f1: 0.4886\n",
            "Epoch 187/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0020 - recall_m: 0.9528 - precision_m: 0.9497 - f1: 0.9509 - val_loss: 0.9953 - val_recall_m: 0.4454 - val_precision_m: 0.6198 - val_f1: 0.4773\n",
            "Epoch 188/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 0.0012 - recall_m: 0.9651 - precision_m: 0.9717 - f1: 0.9675 - val_loss: 0.9879 - val_recall_m: 0.4564 - val_precision_m: 0.6085 - val_f1: 0.4797\n",
            "Epoch 189/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.1598e-04 - recall_m: 0.9623 - precision_m: 0.9591 - f1: 0.9604 - val_loss: 0.9952 - val_recall_m: 0.4447 - val_precision_m: 0.6154 - val_f1: 0.4761\n",
            "Epoch 190/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 2.2871e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9946 - val_recall_m: 0.4506 - val_precision_m: 0.6152 - val_f1: 0.4793\n",
            "Epoch 191/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.7446e-04 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0044 - val_recall_m: 0.4494 - val_precision_m: 0.6152 - val_f1: 0.4781\n",
            "Epoch 192/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.5924e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0101 - val_recall_m: 0.4423 - val_precision_m: 0.6166 - val_f1: 0.4754\n",
            "Epoch 193/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.6533e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0117 - val_recall_m: 0.4413 - val_precision_m: 0.6166 - val_f1: 0.4746\n",
            "Epoch 194/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 6.0791e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0132 - val_recall_m: 0.4403 - val_precision_m: 0.6163 - val_f1: 0.4739\n",
            "Epoch 195/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.6979e-05 - recall_m: 1.0000 - precision_m: 1.0000 - f1: 1.0000 - val_loss: 1.0154 - val_recall_m: 0.4403 - val_precision_m: 0.6163 - val_f1: 0.4739\n",
            "Epoch 196/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3010e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0189 - val_recall_m: 0.4403 - val_precision_m: 0.6163 - val_f1: 0.4739\n",
            "Epoch 197/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.3580e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0207 - val_recall_m: 0.4413 - val_precision_m: 0.6166 - val_f1: 0.4746\n",
            "Epoch 198/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.3960e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0221 - val_recall_m: 0.4413 - val_precision_m: 0.6166 - val_f1: 0.4746\n",
            "Epoch 199/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 2.8543e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0237 - val_recall_m: 0.4420 - val_precision_m: 0.6160 - val_f1: 0.4752\n",
            "Epoch 200/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.2358e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0230 - val_recall_m: 0.4476 - val_precision_m: 0.6161 - val_f1: 0.4781\n",
            "Epoch 201/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.8874e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0258 - val_recall_m: 0.4476 - val_precision_m: 0.6161 - val_f1: 0.4781\n",
            "Epoch 202/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.6051e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0238 - val_recall_m: 0.4587 - val_precision_m: 0.6182 - val_f1: 0.4847\n",
            "Epoch 203/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.6266e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0253 - val_recall_m: 0.4587 - val_precision_m: 0.6153 - val_f1: 0.4838\n",
            "Epoch 204/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.8430e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0268 - val_recall_m: 0.4587 - val_precision_m: 0.6129 - val_f1: 0.4822\n",
            "Epoch 205/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.7470e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0298 - val_recall_m: 0.4587 - val_precision_m: 0.6136 - val_f1: 0.4826\n",
            "Epoch 206/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.4255e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0318 - val_recall_m: 0.4587 - val_precision_m: 0.6136 - val_f1: 0.4826\n",
            "Epoch 207/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3805e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0335 - val_recall_m: 0.4587 - val_precision_m: 0.6142 - val_f1: 0.4829\n",
            "Epoch 208/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.6797e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0366 - val_recall_m: 0.4587 - val_precision_m: 0.6136 - val_f1: 0.4826\n",
            "Epoch 209/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 3.6097e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0409 - val_recall_m: 0.4581 - val_precision_m: 0.6165 - val_f1: 0.4829\n",
            "Epoch 210/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.0306e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0464 - val_recall_m: 0.4563 - val_precision_m: 0.6148 - val_f1: 0.4808\n",
            "Epoch 211/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.4399e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0502 - val_recall_m: 0.4563 - val_precision_m: 0.6185 - val_f1: 0.4832\n",
            "Epoch 212/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.3868e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0525 - val_recall_m: 0.4571 - val_precision_m: 0.6171 - val_f1: 0.4832\n",
            "Epoch 213/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.7803e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0566 - val_recall_m: 0.4558 - val_precision_m: 0.6189 - val_f1: 0.4831\n",
            "Epoch 214/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.2899e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0597 - val_recall_m: 0.4574 - val_precision_m: 0.6196 - val_f1: 0.4847\n",
            "Epoch 215/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.2931e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0634 - val_recall_m: 0.4531 - val_precision_m: 0.6220 - val_f1: 0.4837\n",
            "Epoch 216/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.5092e-05 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.0660 - val_recall_m: 0.4511 - val_precision_m: 0.6183 - val_f1: 0.4816\n",
            "Epoch 217/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 1.4074e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0698 - val_recall_m: 0.4511 - val_precision_m: 0.6220 - val_f1: 0.4835\n",
            "Epoch 218/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 8.1467e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0719 - val_recall_m: 0.4511 - val_precision_m: 0.6220 - val_f1: 0.4835\n",
            "Epoch 219/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.1445e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0758 - val_recall_m: 0.4503 - val_precision_m: 0.6183 - val_f1: 0.4813\n",
            "Epoch 220/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.2685e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0779 - val_recall_m: 0.4513 - val_precision_m: 0.6220 - val_f1: 0.4827\n",
            "Epoch 221/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 4.3004e-05 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 1.0777 - val_recall_m: 0.4585 - val_precision_m: 0.6250 - val_f1: 0.4881\n",
            "Epoch 222/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 7.7249e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0801 - val_recall_m: 0.4575 - val_precision_m: 0.6250 - val_f1: 0.4874\n",
            "Epoch 223/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 6.3279e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0819 - val_recall_m: 0.4585 - val_precision_m: 0.6250 - val_f1: 0.4881\n",
            "Epoch 224/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 4.5427e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0836 - val_recall_m: 0.4575 - val_precision_m: 0.6250 - val_f1: 0.4874\n",
            "Epoch 225/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 8.4724e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0856 - val_recall_m: 0.4585 - val_precision_m: 0.6250 - val_f1: 0.4881\n",
            "Epoch 226/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 7.9585e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0888 - val_recall_m: 0.4558 - val_precision_m: 0.6250 - val_f1: 0.4869\n",
            "Epoch 227/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.3351e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0913 - val_recall_m: 0.4585 - val_precision_m: 0.6277 - val_f1: 0.4900\n",
            "Epoch 228/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 5.5148e-06 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 1.0940 - val_recall_m: 0.4585 - val_precision_m: 0.6277 - val_f1: 0.4900\n",
            "Epoch 229/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.9180e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1042 - val_recall_m: 0.4503 - val_precision_m: 0.6225 - val_f1: 0.4843\n",
            "Epoch 230/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 8.4810e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.1110 - val_recall_m: 0.4496 - val_precision_m: 0.6225 - val_f1: 0.4838\n",
            "Epoch 231/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.6563e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1114 - val_recall_m: 0.4510 - val_precision_m: 0.6225 - val_f1: 0.4852\n",
            "Epoch 232/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 6.3010e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1124 - val_recall_m: 0.4510 - val_precision_m: 0.6198 - val_f1: 0.4831\n",
            "Epoch 233/500\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 5.1736e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1146 - val_recall_m: 0.4510 - val_precision_m: 0.6232 - val_f1: 0.4847\n",
            "Epoch 234/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 5.2697e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1169 - val_recall_m: 0.4523 - val_precision_m: 0.6235 - val_f1: 0.4855\n",
            "Epoch 235/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 3.8164e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1188 - val_recall_m: 0.4523 - val_precision_m: 0.6235 - val_f1: 0.4855\n",
            "Epoch 236/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 3.8988e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1216 - val_recall_m: 0.4523 - val_precision_m: 0.6242 - val_f1: 0.4857\n",
            "Epoch 237/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 5.0733e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1246 - val_recall_m: 0.4513 - val_precision_m: 0.6242 - val_f1: 0.4850\n",
            "Epoch 238/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 4.3401e-06 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 1.1270 - val_recall_m: 0.4513 - val_precision_m: 0.6242 - val_f1: 0.4850\n",
            "Epoch 239/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 3.6243e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1295 - val_recall_m: 0.4513 - val_precision_m: 0.6242 - val_f1: 0.4850\n",
            "Epoch 240/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 4.2304e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1315 - val_recall_m: 0.4513 - val_precision_m: 0.6235 - val_f1: 0.4847\n",
            "Epoch 241/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 3.4176e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1340 - val_recall_m: 0.4513 - val_precision_m: 0.6249 - val_f1: 0.4856\n",
            "Epoch 242/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.2527e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1358 - val_recall_m: 0.4513 - val_precision_m: 0.6249 - val_f1: 0.4856\n",
            "Epoch 243/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 2.1668e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1385 - val_recall_m: 0.4506 - val_precision_m: 0.6228 - val_f1: 0.4846\n",
            "Epoch 244/500\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 6.3550e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1477 - val_recall_m: 0.4486 - val_precision_m: 0.6239 - val_f1: 0.4841\n",
            "Epoch 245/500\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1.8871e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1495 - val_recall_m: 0.4486 - val_precision_m: 0.6239 - val_f1: 0.4841\n",
            "Epoch 246/500\n",
            "106/106 [==============================] - 1s 10ms/step - loss: 3.2566e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.1518 - val_recall_m: 0.4486 - val_precision_m: 0.6235 - val_f1: 0.4839\n",
            "Epoch 247/500\n",
            "106/106 [==============================] - 1s 12ms/step - loss: 3.0238e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1547 - val_recall_m: 0.4486 - val_precision_m: 0.6225 - val_f1: 0.4838\n",
            "Epoch 248/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 7.4845e-05 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1431 - val_recall_m: 0.4702 - val_precision_m: 0.6234 - val_f1: 0.4942\n",
            "Epoch 249/500\n",
            "106/106 [==============================] - 1s 11ms/step - loss: 1.0816e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1505 - val_recall_m: 0.4609 - val_precision_m: 0.6190 - val_f1: 0.4875\n",
            "Epoch 250/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 2.9317e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1539 - val_recall_m: 0.4609 - val_precision_m: 0.6170 - val_f1: 0.4862\n",
            "Epoch 251/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 6.4282e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1620 - val_recall_m: 0.4592 - val_precision_m: 0.6218 - val_f1: 0.4888\n",
            "Epoch 252/500\n",
            "106/106 [==============================] - 1s 9ms/step - loss: 1.4532e-04 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1876 - val_recall_m: 0.4584 - val_precision_m: 0.6161 - val_f1: 0.4855\n",
            "Epoch 253/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 0.0017 - recall_m: 0.9305 - precision_m: 0.9305 - f1: 0.9302 - val_loss: 1.2265 - val_recall_m: 0.4630 - val_precision_m: 0.6310 - val_f1: 0.4996\n",
            "Epoch 254/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 0.0403 - recall_m: 0.9450 - precision_m: 0.9407 - f1: 0.9355 - val_loss: 0.8807 - val_recall_m: 0.4684 - val_precision_m: 0.6021 - val_f1: 0.4891\n",
            "Epoch 255/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 0.0066 - recall_m: 0.9377 - precision_m: 0.9415 - f1: 0.9365 - val_loss: 0.8601 - val_recall_m: 0.4805 - val_precision_m: 0.6411 - val_f1: 0.5095\n",
            "Epoch 256/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 0.0011 - recall_m: 0.9575 - precision_m: 0.9599 - f1: 0.9578 - val_loss: 0.8557 - val_recall_m: 0.4866 - val_precision_m: 0.6427 - val_f1: 0.5109\n",
            "Epoch 257/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 5.4992e-04 - recall_m: 0.9434 - precision_m: 0.9418 - f1: 0.9425 - val_loss: 0.8695 - val_recall_m: 0.4725 - val_precision_m: 0.6478 - val_f1: 0.5039\n",
            "Epoch 258/500\n",
            "106/106 [==============================] - 1s 8ms/step - loss: 3.3900e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.8812 - val_recall_m: 0.4661 - val_precision_m: 0.6446 - val_f1: 0.4989\n",
            "Epoch 259/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 3.9617e-04 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.8869 - val_recall_m: 0.4668 - val_precision_m: 0.6421 - val_f1: 0.4987\n",
            "Epoch 260/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.2620e-04 - recall_m: 0.9906 - precision_m: 0.9906 - f1: 0.9906 - val_loss: 0.8912 - val_recall_m: 0.4657 - val_precision_m: 0.6387 - val_f1: 0.4964\n",
            "Epoch 261/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.0697e-04 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.8971 - val_recall_m: 0.4701 - val_precision_m: 0.6421 - val_f1: 0.5003\n",
            "Epoch 262/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.5260e-04 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9040 - val_recall_m: 0.4715 - val_precision_m: 0.6471 - val_f1: 0.5030\n",
            "Epoch 263/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.2945e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9089 - val_recall_m: 0.4695 - val_precision_m: 0.6444 - val_f1: 0.5009\n",
            "Epoch 264/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 8.8552e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9125 - val_recall_m: 0.4691 - val_precision_m: 0.6518 - val_f1: 0.5037\n",
            "Epoch 265/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.1999e-04 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 0.9150 - val_recall_m: 0.4712 - val_precision_m: 0.6447 - val_f1: 0.5029\n",
            "Epoch 266/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0885e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9227 - val_recall_m: 0.4712 - val_precision_m: 0.6452 - val_f1: 0.5032\n",
            "Epoch 267/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.9633e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9284 - val_recall_m: 0.4692 - val_precision_m: 0.6439 - val_f1: 0.5016\n",
            "Epoch 268/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0511e-04 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9366 - val_recall_m: 0.4665 - val_precision_m: 0.6426 - val_f1: 0.5015\n",
            "Epoch 269/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 9.0221e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9440 - val_recall_m: 0.4665 - val_precision_m: 0.6493 - val_f1: 0.5037\n",
            "Epoch 270/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 4.5291e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9488 - val_recall_m: 0.4639 - val_precision_m: 0.6429 - val_f1: 0.5002\n",
            "Epoch 271/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.5224e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9556 - val_recall_m: 0.4639 - val_precision_m: 0.6436 - val_f1: 0.5005\n",
            "Epoch 272/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.4191e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9576 - val_recall_m: 0.4644 - val_precision_m: 0.6436 - val_f1: 0.5010\n",
            "Epoch 273/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.0060e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9603 - val_recall_m: 0.4644 - val_precision_m: 0.6430 - val_f1: 0.5008\n",
            "Epoch 274/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.2921e-05 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 0.9631 - val_recall_m: 0.4644 - val_precision_m: 0.6430 - val_f1: 0.5008\n",
            "Epoch 275/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.4801e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9653 - val_recall_m: 0.4644 - val_precision_m: 0.6430 - val_f1: 0.5008\n",
            "Epoch 276/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 6.8184e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9691 - val_recall_m: 0.4661 - val_precision_m: 0.6464 - val_f1: 0.5021\n",
            "Epoch 277/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.2609e-05 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 0.9736 - val_recall_m: 0.4661 - val_precision_m: 0.6464 - val_f1: 0.5021\n",
            "Epoch 278/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 9.5798e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 0.9757 - val_recall_m: 0.4661 - val_precision_m: 0.6464 - val_f1: 0.5021\n",
            "Epoch 279/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.1548e-05 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 0.9778 - val_recall_m: 0.4661 - val_precision_m: 0.6485 - val_f1: 0.5030\n",
            "Epoch 280/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 1.7880e-05 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 0.9803 - val_recall_m: 0.4671 - val_precision_m: 0.6505 - val_f1: 0.5048\n",
            "Epoch 281/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 2.6142e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9834 - val_recall_m: 0.4678 - val_precision_m: 0.6495 - val_f1: 0.5051\n",
            "Epoch 282/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 7.4389e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 0.9850 - val_recall_m: 0.4671 - val_precision_m: 0.6454 - val_f1: 0.5040\n",
            "Epoch 283/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.0895e-05 - recall_m: 0.9245 - precision_m: 0.9245 - f1: 0.9245 - val_loss: 0.9878 - val_recall_m: 0.4671 - val_precision_m: 0.6454 - val_f1: 0.5040\n",
            "Epoch 284/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 6.5747e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 0.9983 - val_recall_m: 0.4645 - val_precision_m: 0.6444 - val_f1: 0.5017\n",
            "Epoch 285/500\n",
            "106/106 [==============================] - 1s 7ms/step - loss: 2.2994e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0013 - val_recall_m: 0.4645 - val_precision_m: 0.6417 - val_f1: 0.5009\n",
            "Epoch 286/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.6155e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0049 - val_recall_m: 0.4678 - val_precision_m: 0.6428 - val_f1: 0.5032\n",
            "Epoch 287/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 6.9117e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0073 - val_recall_m: 0.4665 - val_precision_m: 0.6424 - val_f1: 0.5025\n",
            "Epoch 288/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 8.7397e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0101 - val_recall_m: 0.4671 - val_precision_m: 0.6427 - val_f1: 0.5031\n",
            "Epoch 289/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 1.5354e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0143 - val_recall_m: 0.4649 - val_precision_m: 0.6430 - val_f1: 0.5013\n",
            "Epoch 290/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.8914e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0164 - val_recall_m: 0.4649 - val_precision_m: 0.6464 - val_f1: 0.5026\n",
            "Epoch 291/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 8.0685e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0197 - val_recall_m: 0.4635 - val_precision_m: 0.6457 - val_f1: 0.5015\n",
            "Epoch 292/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.7074e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0226 - val_recall_m: 0.4642 - val_precision_m: 0.6460 - val_f1: 0.5021\n",
            "Epoch 293/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0066e-05 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0248 - val_recall_m: 0.4661 - val_precision_m: 0.6467 - val_f1: 0.5037\n",
            "Epoch 294/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 7.9253e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0269 - val_recall_m: 0.4675 - val_precision_m: 0.6458 - val_f1: 0.5039\n",
            "Epoch 295/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 8.6450e-06 - recall_m: 1.0000 - precision_m: 1.0000 - f1: 1.0000 - val_loss: 1.0302 - val_recall_m: 0.4675 - val_precision_m: 0.6461 - val_f1: 0.5041\n",
            "Epoch 296/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.3703e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0326 - val_recall_m: 0.4661 - val_precision_m: 0.6454 - val_f1: 0.5030\n",
            "Epoch 297/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.9787e-05 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 1.0400 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5025\n",
            "Epoch 298/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0755e-05 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0444 - val_recall_m: 0.4645 - val_precision_m: 0.6478 - val_f1: 0.5028\n",
            "Epoch 299/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.5669e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0481 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5025\n",
            "Epoch 300/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.6388e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0502 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5025\n",
            "Epoch 301/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.2239e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.0528 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5025\n",
            "Epoch 302/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.5598e-06 - recall_m: 0.9151 - precision_m: 0.9151 - f1: 0.9151 - val_loss: 1.0562 - val_recall_m: 0.4645 - val_precision_m: 0.6491 - val_f1: 0.5033\n",
            "Epoch 303/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.8947e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0579 - val_recall_m: 0.4645 - val_precision_m: 0.6491 - val_f1: 0.5033\n",
            "Epoch 304/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.8898e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0610 - val_recall_m: 0.4645 - val_precision_m: 0.6491 - val_f1: 0.5033\n",
            "Epoch 305/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.4002e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0638 - val_recall_m: 0.4645 - val_precision_m: 0.6491 - val_f1: 0.5033\n",
            "Epoch 306/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.1199e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.0680 - val_recall_m: 0.4645 - val_precision_m: 0.6491 - val_f1: 0.5033\n",
            "Epoch 307/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 7.6234e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0719 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5028\n",
            "Epoch 308/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.0317e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0753 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5028\n",
            "Epoch 309/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.4715e-06 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.0798 - val_recall_m: 0.4645 - val_precision_m: 0.6468 - val_f1: 0.5028\n",
            "Epoch 310/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.1287e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.0841 - val_recall_m: 0.4645 - val_precision_m: 0.6485 - val_f1: 0.5037\n",
            "Epoch 311/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.2599e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0882 - val_recall_m: 0.4645 - val_precision_m: 0.6464 - val_f1: 0.5022\n",
            "Epoch 312/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.8990e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.0920 - val_recall_m: 0.4645 - val_precision_m: 0.6464 - val_f1: 0.5022\n",
            "Epoch 313/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.0661e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.0977 - val_recall_m: 0.4645 - val_precision_m: 0.6485 - val_f1: 0.5032\n",
            "Epoch 314/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.8520e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1003 - val_recall_m: 0.4645 - val_precision_m: 0.6471 - val_f1: 0.5029\n",
            "Epoch 315/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.0851e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1044 - val_recall_m: 0.4645 - val_precision_m: 0.6471 - val_f1: 0.5032\n",
            "Epoch 316/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.0906e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1091 - val_recall_m: 0.4645 - val_precision_m: 0.6471 - val_f1: 0.5032\n",
            "Epoch 317/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.4391e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1126 - val_recall_m: 0.4645 - val_precision_m: 0.6485 - val_f1: 0.5037\n",
            "Epoch 318/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3580e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1195 - val_recall_m: 0.4631 - val_precision_m: 0.6460 - val_f1: 0.5015\n",
            "Epoch 319/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.9572e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1248 - val_recall_m: 0.4655 - val_precision_m: 0.6451 - val_f1: 0.5030\n",
            "Epoch 320/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 1.5470e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1289 - val_recall_m: 0.4645 - val_precision_m: 0.6471 - val_f1: 0.5029\n",
            "Epoch 321/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.0953e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1321 - val_recall_m: 0.4645 - val_precision_m: 0.6471 - val_f1: 0.5029\n",
            "Epoch 322/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.1074e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1370 - val_recall_m: 0.4631 - val_precision_m: 0.6467 - val_f1: 0.5022\n",
            "Epoch 323/500\n",
            "106/106 [==============================] - 0s 4ms/step - loss: 3.0565e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1423 - val_recall_m: 0.4631 - val_precision_m: 0.6474 - val_f1: 0.5026\n",
            "Epoch 324/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0789e-06 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1455 - val_recall_m: 0.4641 - val_precision_m: 0.6474 - val_f1: 0.5033\n",
            "Epoch 325/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.1196e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1480 - val_recall_m: 0.4641 - val_precision_m: 0.6474 - val_f1: 0.5033\n",
            "Epoch 326/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.4227e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1510 - val_recall_m: 0.4641 - val_precision_m: 0.6474 - val_f1: 0.5033\n",
            "Epoch 327/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 6.1798e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1531 - val_recall_m: 0.4641 - val_precision_m: 0.6474 - val_f1: 0.5033\n",
            "Epoch 328/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.6627e-06 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1564 - val_recall_m: 0.4655 - val_precision_m: 0.6478 - val_f1: 0.5041\n",
            "Epoch 329/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.7205e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1609 - val_recall_m: 0.4655 - val_precision_m: 0.6471 - val_f1: 0.5034\n",
            "Epoch 330/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 9.2644e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1638 - val_recall_m: 0.4668 - val_precision_m: 0.6512 - val_f1: 0.5054\n",
            "Epoch 331/500\n",
            "106/106 [==============================] - 1s 6ms/step - loss: 8.1420e-07 - recall_m: 1.0000 - precision_m: 1.0000 - f1: 1.0000 - val_loss: 1.1676 - val_recall_m: 0.4668 - val_precision_m: 0.6518 - val_f1: 0.5061\n",
            "Epoch 332/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 8.9967e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1711 - val_recall_m: 0.4655 - val_precision_m: 0.6478 - val_f1: 0.5041\n",
            "Epoch 333/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.4366e-06 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.1781 - val_recall_m: 0.4635 - val_precision_m: 0.6458 - val_f1: 0.5020\n",
            "Epoch 334/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 8.8326e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1823 - val_recall_m: 0.4635 - val_precision_m: 0.6458 - val_f1: 0.5020\n",
            "Epoch 335/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 5.6273e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.1854 - val_recall_m: 0.4621 - val_precision_m: 0.6454 - val_f1: 0.5013\n",
            "Epoch 336/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 6.1700e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.1880 - val_recall_m: 0.4621 - val_precision_m: 0.6454 - val_f1: 0.5013\n",
            "Epoch 337/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.1596e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1900 - val_recall_m: 0.4621 - val_precision_m: 0.6454 - val_f1: 0.5013\n",
            "Epoch 338/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.0418e-06 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.1951 - val_recall_m: 0.4648 - val_precision_m: 0.6498 - val_f1: 0.5041\n",
            "Epoch 339/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.5073e-07 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.1982 - val_recall_m: 0.4648 - val_precision_m: 0.6498 - val_f1: 0.5041\n",
            "Epoch 340/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.3428e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.2037 - val_recall_m: 0.4648 - val_precision_m: 0.6498 - val_f1: 0.5041\n",
            "Epoch 341/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.9090e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.2075 - val_recall_m: 0.4648 - val_precision_m: 0.6498 - val_f1: 0.5041\n",
            "Epoch 342/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.3687e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.2095 - val_recall_m: 0.4648 - val_precision_m: 0.6498 - val_f1: 0.5041\n",
            "Epoch 343/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3530e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.2130 - val_recall_m: 0.4635 - val_precision_m: 0.6458 - val_f1: 0.5020\n",
            "Epoch 344/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.7273e-07 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.2179 - val_recall_m: 0.4635 - val_precision_m: 0.6458 - val_f1: 0.5020\n",
            "Epoch 345/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.6735e-06 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.2266 - val_recall_m: 0.4695 - val_precision_m: 0.6460 - val_f1: 0.5047\n",
            "Epoch 346/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 4.1931e-07 - recall_m: 0.9340 - precision_m: 0.9340 - f1: 0.9340 - val_loss: 1.2306 - val_recall_m: 0.4695 - val_precision_m: 0.6460 - val_f1: 0.5047\n",
            "Epoch 347/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 1.9315e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2324 - val_recall_m: 0.4695 - val_precision_m: 0.6460 - val_f1: 0.5047\n",
            "Epoch 348/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.7698e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2354 - val_recall_m: 0.4695 - val_precision_m: 0.6460 - val_f1: 0.5047\n",
            "Epoch 349/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 5.3092e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.2399 - val_recall_m: 0.4695 - val_precision_m: 0.6494 - val_f1: 0.5062\n",
            "Epoch 350/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 6.4632e-07 - recall_m: 0.9811 - precision_m: 0.9811 - f1: 0.9811 - val_loss: 1.2484 - val_recall_m: 0.4638 - val_precision_m: 0.6501 - val_f1: 0.5042\n",
            "Epoch 351/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 2.0017e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.2503 - val_recall_m: 0.4638 - val_precision_m: 0.6501 - val_f1: 0.5042\n",
            "Epoch 352/500\n",
            "106/106 [==============================] - 1s 5ms/step - loss: 1.9192e-07 - recall_m: 0.9717 - precision_m: 0.9717 - f1: 0.9717 - val_loss: 1.2531 - val_recall_m: 0.4638 - val_precision_m: 0.6501 - val_f1: 0.5042\n",
            "Epoch 353/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.1961e-07 - recall_m: 0.9528 - precision_m: 0.9528 - f1: 0.9528 - val_loss: 1.2559 - val_recall_m: 0.4638 - val_precision_m: 0.6501 - val_f1: 0.5042\n",
            "Epoch 354/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 2.2738e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2580 - val_recall_m: 0.4638 - val_precision_m: 0.6501 - val_f1: 0.5042\n",
            "Epoch 355/500\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 7.5583e-07 - recall_m: 0.9623 - precision_m: 0.9623 - f1: 0.9623 - val_loss: 1.2682 - val_recall_m: 0.4638 - val_precision_m: 0.6512 - val_f1: 0.5045\n",
            "Epoch 356/500\n",
            "100/106 [===========================>..] - ETA: 0s - loss: 3.5096e-07 - recall_m: 0.9400 - precision_m: 0.9400 - f1: 0.9400Restoring model weights from the end of the best epoch: 256.\n",
            "106/106 [==============================] - 0s 5ms/step - loss: 3.4313e-07 - recall_m: 0.9434 - precision_m: 0.9434 - f1: 0.9434 - val_loss: 1.2741 - val_recall_m: 0.4632 - val_precision_m: 0.6525 - val_f1: 0.5042\n",
            "Epoch 356: early stopping\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x2302a156580>"
            ]
          },
          "execution_count": 266,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.fit(X_train,y_train, validation_data=[X_test,y_test], epochs=500, callbacks = [early_stopping])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_train)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3056    0]\n",
            " [   0  319]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3056\n",
            "           1       1.00      1.00      1.00       319\n",
            "\n",
            "    accuracy                           1.00      3375\n",
            "   macro avg       1.00      1.00      1.00      3375\n",
            "weighted avg       1.00      1.00      1.00      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "247/247 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6795  225]\n",
            " [ 438  417]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      7020\n",
            "           1       0.65      0.49      0.56       855\n",
            "\n",
            "    accuracy                           0.92      7875\n",
            "   macro avg       0.79      0.73      0.76      7875\n",
            "weighted avg       0.91      0.92      0.91      7875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118/118 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_validate)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3255  118]\n",
            " [ 191  186]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      3373\n",
            "           1       0.61      0.49      0.55       377\n",
            "\n",
            "    accuracy                           0.92      3750\n",
            "   macro avg       0.78      0.73      0.75      3750\n",
            "weighted avg       0.91      0.92      0.91      3750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 146,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " actions = {0 : 0, 1 : 1}\n",
        " len(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward(si, a, M, m, y):\n",
        "    l = y[si]\n",
        "\n",
        "    if (a == l) & (si in m):\n",
        "        r = 1\n",
        "    elif  (a != l) & (si in m):\n",
        "        r = -1\n",
        "    if (a == l) & (si in M):\n",
        "        r = 0.1\n",
        "    elif  (a != l) & (si in M):\n",
        "        r = -0.1\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "def step(action, i, M, m, X, y):\n",
        "\n",
        "    r = reward(i,action, M, m, y)\n",
        "\n",
        "    nextState = X[i+1,:]\n",
        "\n",
        "    terminated = False\n",
        "    \n",
        "    l = y[i]\n",
        "\n",
        "    if i == len(y) - 1:\n",
        "        terminated = True\n",
        "    elif (action != l) & (i in m):\n",
        "        print(action, l)\n",
        "        terminated = True\n",
        "\n",
        "\n",
        "    return r, nextState, terminated, i+1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {
        "id": "lC5LkJ-6zCIF"
      },
      "outputs": [],
      "source": [
        "%run -i ./DQN_Class.py\n",
        "gamma=0.2\n",
        "epsilon=.9\n",
        "numberEpisodes= 500\n",
        "LearningQDeep=DeepQLearning(gamma,epsilon,numberEpisodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.4125435562551007e-09"
            ]
          },
          "execution_count": 150,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.96**(500-25)*(0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 151,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LearningQDeep.actionDimension"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9"
            ]
          },
          "execution_count": 152,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LearningQDeep.epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_124 (Dense)           (None, 30)                15030     \n",
            "                                                                 \n",
            " dense_125 (Dense)           (None, 64)                1984      \n",
            "                                                                 \n",
            " dense_126 (Dense)           (None, 20)                1300      \n",
            "                                                                 \n",
            " dense_127 (Dense)           (None, 2)                 42        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,356\n",
            "Trainable params: 18,356\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LearningQDeep.mainNetwork.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kuOS04kzRP2",
        "outputId": "05ad7a66-a3b7-4a44-c1b5-8e675fc2273b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulating episode 0\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 18  25  47  51  61  68  69  70 114 127]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards -1.2\n",
            "Simulating episode 1\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [23 29 30 38 45 50 60 67 78 88]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 0.29999999999999993\n",
            "Simulating episode 2\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 20  78  93 130 151 154 163 171 173 176]\n",
            "\t Reached sample: 21\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 3\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [13 27 32 39 43 44 73 75 85 87]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards -0.4999999999999999\n",
            "Simulating episode 4\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 9 15 21 23 25 29 36 38 41 57]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 0.19999999999999973\n",
            "Simulating episode 5\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 6 10 26 28 30 49 53 68 70 76]\n",
            "\t Reached sample: 71\n",
            "\t Sum of rewards 6.6\n",
            "Simulating episode 6\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [  3  23  29  33  36  43  53  57 106 117]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 0.8999999999999999\n",
            "Simulating episode 7\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1 15 24 29 30 42 52 57 67 78]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 8\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  9 14 18 23 30 31 37 47 66]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 9\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [  6  20  28  51  60  61  66  71 110 138]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 10\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  3  11  14  48  51  98  99 104 111 117]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 2.220446049250313e-16\n",
            "Simulating episode 11\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 7 10 18 26 30 40 45 55 73 91]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -1.5\n",
            "Simulating episode 12\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  9 14 19 31 35 49 65 74 78]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 13\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 2 20 30 41 42 56 57 60 70 87]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 14\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 16  43  52  55  91  92 100 104 111 112]\n",
            "\t Reached sample: 53\n",
            "\t Sum of rewards 2.0\n",
            "Simulating episode 15\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 17  22  25  47  52  74  80  81  82 101]\n",
            "\t Reached sample: 48\n",
            "\t Sum of rewards 1.8000000000000003\n",
            "Simulating episode 16\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 3  9 15 19 22 29 33 35 49 52]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 1.3000000000000003\n",
            "Simulating episode 17\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 4  7 12 20 26 27 45 58 74 93]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -0.20000000000000007\n",
            "Simulating episode 18\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0 10 11 14 20 25 36 48 70 72]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 19\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 29  57  58  67  79  80  83  96 112 117]\n",
            "\t Reached sample: 59\n",
            "\t Sum of rewards 0.2000000000000004\n",
            "Simulating episode 20\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 9 29 31 42 49 57 61 66 76 84]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 21\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 8 12 24 25 50 53 65 71 73 75]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 22\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 17  44  50  61  66  75 112 135 143 157]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 23\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.9\n",
            "0 1\n",
            "\t First 1 index: [ 3  7 10 16 30 52 55 59 64 73]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 24\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 2  5  6  8 10 20 28 38 47 51]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 25\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  3 15 42 49 53 60 63 67 79]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 26\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 3  5  9 11 23 45 68 70 74 87]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 27\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8122499999999999\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8122499999999999\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8122499999999999\n",
            "0 1\n",
            "\t First 1 index: [  0   2  35  61  66 109 116 122 127 133]\n",
            "\t Reached sample: 62\n",
            "\t Sum of rewards 2.4000000000000004\n",
            "Simulating episode 28\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  3 15 17 27 43 46 49 63 93]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 29\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.7330556249999999\n",
            "0 1\n",
            "\t First 1 index: [  9  10  15  83  84  94 100 118 124 141]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 30\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  7  22  33  63  87  95 120 121 140 141]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 31\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6615827015624998\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6615827015624998\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6615827015624998\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6615827015624998\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6615827015624998\n",
            "0 1\n",
            "\t First 1 index: [ 36  73  79  85  89  91  97 101 111 112]\n",
            "\t Reached sample: 90\n",
            "\t Sum of rewards 4.1\n",
            "Simulating episode 32\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [13 26 38 41 47 50 58 63 65 67]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 33\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.597078388160156\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.597078388160156\n",
            "0 1\n",
            "\t First 1 index: [ 8 29 36 38 57 68 73 75 76 79]\n",
            "\t Reached sample: 39\n",
            "\t Sum of rewards 0.8999999999999999\n",
            "Simulating episode 34\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  5  7 29 32 35 39 48 57 62]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 35\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5388632453145408\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5388632453145408\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5388632453145408\n",
            "0 1\n",
            "\t First 1 index: [ 26  32  44  49  59  60  71  73  78 106]\n",
            "\t Reached sample: 60\n",
            "\t Sum of rewards 2.7000000000000006\n",
            "Simulating episode 36\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5119200830488138\n",
            "0 1\n",
            "\t First 1 index: [  3  30  47  63  83 100 109 139 141 146]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 37\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.486324078896373\n",
            "0 1\n",
            "\t First 1 index: [  4  24  28  32  72  89 101 120 127 128]\n",
            "\t Reached sample: 29\n",
            "\t Sum of rewards 0.3999999999999999\n",
            "Simulating episode 38\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4620078749515544\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4620078749515544\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4620078749515544\n",
            "0 1\n",
            "\t First 1 index: [ 26  48  56  60  63  65  72 100 105 109]\n",
            "\t Reached sample: 57\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 39\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.43890748120397666\n",
            "\t First 1 index: [ 3  5  9 11 15 19 23 36 42 45]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 2.0\n",
            "Simulating episode 40\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 6  8 16 18 25 31 32 41 61 72]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 1.5\n",
            "Simulating episode 41\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3961140017865889\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3961140017865889\n",
            "0 1\n",
            "\t First 1 index: [ 20  24  40  47  49  57  74  79  95 103]\n",
            "\t Reached sample: 25\n",
            "\t Sum of rewards -0.9000000000000001\n",
            "Simulating episode 42\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 8 18 19 24 26 32 33 37 43 62]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 43\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3574928866123964\n",
            "0 1\n",
            "\t First 1 index: [13 21 27 45 50 51 54 78 88 94]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 44\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33961824228177656\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33961824228177656\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33961824228177656\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33961824228177656\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33961824228177656\n",
            "0 1\n",
            "\t First 1 index: [  4  36  44  89  90  93 106 107 118 121]\n",
            "\t Reached sample: 107\n",
            "\t Sum of rewards 4.400000000000001\n",
            "Simulating episode 45\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3226373301676877\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3226373301676877\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3226373301676877\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3226373301676877\n",
            "0 1\n",
            "\t First 1 index: [  1   5  14  67  72  73  76  89  99 101]\n",
            "\t Reached sample: 74\n",
            "\t Sum of rewards 3.8000000000000007\n",
            "Simulating episode 46\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3065054636593033\n",
            "0 1\n",
            "\t First 1 index: [17 24 30 37 39 48 53 57 71 81]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards -1.5\n",
            "Simulating episode 47\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 7  9 17 18 31 35 36 41 50 53]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 48\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2766211809525212\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2766211809525212\n",
            "0 1\n",
            "\t First 1 index: [20 29 38 41 47 55 71 82 84 96]\n",
            "\t Reached sample: 39\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 49\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2   4  48  80  85 115 134 166 178 189]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -0.09999999999999998\n",
            "Simulating episode 50\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.24965061580965037\n",
            "0 1\n",
            "\t First 1 index: [ 2 11 14 22 26 27 32 38 47 51]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.2\n",
            "Simulating episode 51\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23716808501916783\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23716808501916783\n",
            "0 1\n",
            "\t First 1 index: [ 10  39  40  43  65  85 102 105 112 116]\n",
            "\t Reached sample: 44\n",
            "\t Sum of rewards 2.4000000000000004\n",
            "Simulating episode 52\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.22530968076820942\n",
            "0 1\n",
            "\t First 1 index: [ 0  3 17 18 26 58 63 64 80 85]\n",
            "\t Reached sample: 27\n",
            "\t Sum of rewards 3.1999999999999993\n",
            "Simulating episode 53\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 14 28 39 42 52 54 56 70 97]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 54\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.20334198689330898\n",
            "0 1\n",
            "\t First 1 index: [  3   4  20  27  35  70  75  98 118 122]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 55\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19317488754864354\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19317488754864354\n",
            "0 1\n",
            "\t First 1 index: [  1  19  28  40  44  52  69  70 108 115]\n",
            "\t Reached sample: 41\n",
            "\t Sum of rewards 2.1\n",
            "Simulating episode 56\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18351614317121134\n",
            "0 1\n",
            "\t First 1 index: [  2  25  44  45  50  63  65  91 118 125]\n",
            "\t Reached sample: 126\n",
            "\t Sum of rewards 5.2\n",
            "Simulating episode 57\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.17434033601265078\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.17434033601265078\n",
            "0 1\n",
            "\t First 1 index: [  2  34  42  48  56  64  67  69  82 104]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 58\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16562331921201823\n",
            "0 1\n",
            "\t First 1 index: [  4  20  25  27  47  51  75  81  99 107]\n",
            "\t Reached sample: 21\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 59\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15734215325141732\n",
            "0 1\n",
            "\t First 1 index: [ 6 16 22 23 28 46 48 75 78 93]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards -0.7000000000000001\n",
            "Simulating episode 60\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [12 29 37 47 58 62 81 85 89 92]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards -0.7999999999999999\n",
            "Simulating episode 61\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.14200129330940411\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.14200129330940411\n",
            "0 1\n",
            "\t First 1 index: [ 5  6 14 19 40 41 56 68 83 93]\n",
            "\t Reached sample: 41\n",
            "\t Sum of rewards 2.3999999999999995\n",
            "Simulating episode 62\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  3  9 38 39 51 72 78 88 93]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 63\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1281561672117372\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1281561672117372\n",
            "0 1\n",
            "\t First 1 index: [ 31  34  58  60  63  87  94 101 105 110]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards -0.8999999999999999\n",
            "Simulating episode 64\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.12174835885115033\n",
            "0 1\n",
            "\t First 1 index: [ 1  2  6 13 28 37 52 67 88 99]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 2.2\n",
            "Simulating episode 65\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11566094090859282\n",
            "0 1\n",
            "\t First 1 index: [ 4 19 29 36 53 60 62 66 74 94]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 1.7000000000000002\n",
            "Simulating episode 66\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10987789386316317\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10987789386316317\n",
            "0 1\n",
            "\t First 1 index: [15 19 24 25 27 31 43 50 52 59]\n",
            "\t Reached sample: 25\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 67\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 9 23 25 27 56 60 61 68 75 77]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards -1.5\n",
            "Simulating episode 68\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09916479921150474\n",
            "0 1\n",
            "\t First 1 index: [ 16  17  20  30  52  68  83  85  98 116]\n",
            "\t Reached sample: 215\n",
            "\t Sum of rewards 15.000000000000002\n",
            "Simulating episode 69\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [10 17 22 33 45 50 69 71 76 83]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards -1.4\n",
            "Simulating episode 70\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08949623128838302\n",
            "0 1\n",
            "\t First 1 index: [ 4 10 20 33 37 40 52 66 81 82]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 71\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [15 27 32 35 46 52 56 63 68 73]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards -1.5\n",
            "Simulating episode 72\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08077034873776566\n",
            "0 1\n",
            "\t First 1 index: [ 8  9 16 17 22 29 36 48 63 77]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 73\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07673183130087738\n",
            "0 1\n",
            "\t First 1 index: [  0  13  18  22  23  25  59  61 105 116]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 0.3999999999999999\n",
            "Simulating episode 74\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0728952397358335\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0728952397358335\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0728952397358335\n",
            "0 1\n",
            "\t First 1 index: [  1  14  40  54  72 101 103 116 122 124]\n",
            "\t Reached sample: 55\n",
            "\t Sum of rewards 1.2999999999999998\n",
            "Simulating episode 75\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 54 57 58 63 66 73 76 93 97]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 76\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.06578795386158974\n",
            "0 1\n",
            "\t First 1 index: [ 0 13 22 53 58 60 76 80 82 87]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 77\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  5  11  21  55  84 113 128 133 172 190]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 78\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.05937362836008474\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.05937362836008474\n",
            "0 1\n",
            "\t First 1 index: [ 15  32  37  39  43  51  85  86 100 102]\n",
            "\t Reached sample: 38\n",
            "\t Sum of rewards -0.10000000000000009\n",
            "Simulating episode 79\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0564049469420805\n",
            "0 1\n",
            "\t First 1 index: [ 8 12 14 26 39 53 58 63 69 88]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -1.4\n",
            "Simulating episode 80\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 3 10 13 29 49 59 72 78 79 83]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 81\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.050905464615227644\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.050905464615227644\n",
            "0 1\n",
            "\t First 1 index: [11 16 23 40 42 44 49 52 54 65]\n",
            "\t Reached sample: 43\n",
            "\t Sum of rewards 1.6\n",
            "Simulating episode 82\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.04836019138446626\n",
            "0 1\n",
            "\t First 1 index: [ 1 14 27 31 35 41 45 51 62 63]\n",
            "\t Reached sample: 28\n",
            "\t Sum of rewards 1.3000000000000003\n",
            "Simulating episode 83\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.04594218181524295\n",
            "0 1\n",
            "\t First 1 index: [ 8 17 19 21 22 24 32 33 34 45]\n",
            "\t Reached sample: 22\n",
            "\t Sum of rewards 1.6\n",
            "Simulating episode 84\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0436450727244808\n",
            "0 1\n",
            "\t First 1 index: [ 12  14  15  26  39  41  72  95 105 122]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards -1.2\n",
            "Simulating episode 85\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.04146281908825676\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.04146281908825676\n",
            "0 1\n",
            "\t First 1 index: [ 8 15 23 31 48 63 65 72 73 88]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 0.7999999999999999\n",
            "Simulating episode 86\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.03938967813384392\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.03938967813384392\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.03938967813384392\n",
            "\t First 1 index: [ 4 11 14 22 24 38 44 55 62 88]\n",
            "\t Reached sample: 56\n",
            "\t Sum of rewards 2.999999999999999\n",
            "Simulating episode 87\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.037420194227151725\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.037420194227151725\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.037420194227151725\n",
            "0 1\n",
            "\t First 1 index: [ 7 12 26 31 32 36 51 52 69 72]\n",
            "\t Reached sample: 70\n",
            "\t Sum of rewards 3.7\n",
            "Simulating episode 88\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.035549184515794134\n",
            "0 1\n",
            "\t First 1 index: [  1  18  38  59  70  80 109 120 135 172]\n",
            "\t Reached sample: 248\n",
            "\t Sum of rewards 7.1\n",
            "Simulating episode 89\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.033771725290004426\n",
            "0 1\n",
            "\t First 1 index: [ 3  5  8 10 16 19 22 26 35 43]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 90\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0320831390255042\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0320831390255042\n",
            "\t First 1 index: [ 7 14 32 37 43 46 47 57 67 87]\n",
            "\t Reached sample: 38\n",
            "\t Sum of rewards 1.4\n",
            "Simulating episode 91\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.03047898207422899\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.03047898207422899\n",
            "0 1\n",
            "\t First 1 index: [ 1 18 42 45 55 56 64 72 73 75]\n",
            "\t Reached sample: 43\n",
            "\t Sum of rewards -0.3999999999999998\n",
            "Simulating episode 92\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02895503297051754\n",
            "0 1\n",
            "\t First 1 index: [  0   2  35  50  52  86 100 123 124 134]\n",
            "\t Reached sample: 125\n",
            "\t Sum of rewards 2.599999999999999\n",
            "Simulating episode 93\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02750728132199166\n",
            "0 1\n",
            "\t First 1 index: [ 5 14 15 17 38 45 50 56 60 64]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 94\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 6  7 18 22 24 52 67 70 76 91]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -1.2\n",
            "Simulating episode 95\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 2 37 45 56 66 69 80 83 89 91]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 96\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0235840553234426\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0235840553234426\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0235840553234426\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0235840553234426\n",
            "0 1\n",
            "\t First 1 index: [  6  10  27  33  67  78  84 108 115 117]\n",
            "\t Reached sample: 79\n",
            "\t Sum of rewards 1.7000000000000002\n",
            "Simulating episode 97\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.02240485255727047\n",
            "0 1\n",
            "\t First 1 index: [14 22 32 36 39 47 57 75 76 77]\n",
            "\t Reached sample: 23\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 98\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.021284609929406943\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.021284609929406943\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.021284609929406943\n",
            "0 1\n",
            "\t First 1 index: [ 31  34  50  62  71  73  76  80 104 106]\n",
            "\t Reached sample: 51\n",
            "\t Sum of rewards -0.6000000000000001\n",
            "Simulating episode 99\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.020220379432936596\n",
            "0 1\n",
            "\t First 1 index: [16 17 22 37 49 50 51 54 60 63]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 0.3999999999999999\n",
            "Simulating episode 100\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  9  25  60  64  81  85  97 105 114 115]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 101\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 4  6 21 22 23 25 26 34 45 53]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -1.2\n",
            "Simulating episode 102\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01733644781631401\n",
            "\t First 1 index: [ 0 18 19 22 24 25 33 48 50 84]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 103\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 7 12 26 28 30 31 47 53 55 63]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 104\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01564614415422339\n",
            "0 1\n",
            "\t First 1 index: [14 18 25 43 45 55 67 82 86 90]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards -1.7999999999999998\n",
            "Simulating episode 105\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.014863836946512221\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.014863836946512221\n",
            "0 1\n",
            "\t First 1 index: [ 6 46 53 62 64 65 69 70 79 92]\n",
            "\t Reached sample: 47\n",
            "\t Sum of rewards -0.5000000000000001\n",
            "Simulating episode 106\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01412064509918661\n",
            "0 1\n",
            "\t First 1 index: [ 1  6  8 10 25 43 51 54 58 69]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 2.5000000000000004\n",
            "Simulating episode 107\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.013414612844227278\n",
            "0 1\n",
            "\t First 1 index: [11 21 27 35 42 58 71 74 76 78]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards -1.3\n",
            "Simulating episode 108\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5  6  9 22 26 27 46 54 55 60]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 109\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.012106688091915117\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.012106688091915117\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.012106688091915117\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.012106688091915117\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.012106688091915117\n",
            "0 1\n",
            "\t First 1 index: [ 20  30  93 110 121 127 137 145 155 164]\n",
            "\t Reached sample: 94\n",
            "\t Sum of rewards -1.5\n",
            "Simulating episode 110\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.01150135368731936\n",
            "0 1\n",
            "\t First 1 index: [  5   8  13  73  75  89 102 111 123 124]\n",
            "\t Reached sample: 125\n",
            "\t Sum of rewards 7.300000000000001\n",
            "Simulating episode 111\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.010926286002953391\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.010926286002953391\n",
            "\t First 1 index: [ 8 11 26 29 30 40 45 52 64 67]\n",
            "\t Reached sample: 27\n",
            "\t Sum of rewards -1.1102230246251565e-16\n",
            "Simulating episode 112\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.010379971702805722\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.010379971702805722\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.010379971702805722\n",
            "0 1\n",
            "\t First 1 index: [  0  45  68  93 110 131 136 145 154 155]\n",
            "\t Reached sample: 69\n",
            "\t Sum of rewards 1.0\n",
            "Simulating episode 113\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.009860973117665435\n",
            "0 1\n",
            "\t First 1 index: [ 19  30  63  64  68  90 116 123 135 160]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards -0.09999999999999998\n",
            "Simulating episode 114\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0 15 16 24 41 48 53 64 72 81]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 115\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.008899528238693053\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.008899528238693053\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.008899528238693053\n",
            "0 1\n",
            "\t First 1 index: [13 30 32 34 39 44 56 58 65 66]\n",
            "\t Reached sample: 59\n",
            "\t Sum of rewards 5.8999999999999995\n",
            "Simulating episode 116\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0084545518267584\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0084545518267584\n",
            "0 1\n",
            "\t First 1 index: [ 13  23  37  39  40  70  72  99 103 104]\n",
            "\t Reached sample: 40\n",
            "\t Sum of rewards 1.5999999999999999\n",
            "Simulating episode 117\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00803182423542048\n",
            "0 1\n",
            "\t First 1 index: [11 16 17 18 19 22 59 60 62 71]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards -0.09999999999999987\n",
            "Simulating episode 118\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.007630233023649456\n",
            "0 1\n",
            "\t First 1 index: [ 3 28 32 44 45 59 60 63 69 71]\n",
            "\t Reached sample: 29\n",
            "\t Sum of rewards -0.2999999999999996\n",
            "Simulating episode 119\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.007248721372466983\n",
            "0 1\n",
            "\t First 1 index: [23 33 42 49 56 63 65 85 87 88]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards -0.8999999999999999\n",
            "Simulating episode 120\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.006886285303843633\n",
            "0 1\n",
            "\t First 1 index: [  0   9  11  24  37  49  79 104 119 124]\n",
            "\t Reached sample: 163\n",
            "\t Sum of rewards 8.8\n",
            "Simulating episode 121\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 2  6  7 21 27 36 49 56 60 70]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 122\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0062148724867188785\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0062148724867188785\n",
            "0 1\n",
            "\t First 1 index: [  9  45  52  60  67  70  80  81  98 107]\n",
            "\t Reached sample: 53\n",
            "\t Sum of rewards 0.5999999999999999\n",
            "Simulating episode 123\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005904128862382934\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005904128862382934\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005904128862382934\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005904128862382934\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005904128862382934\n",
            "0 1\n",
            "\t First 1 index: [  8  21  44  71  87  93  99 101 113 115]\n",
            "\t Reached sample: 94\n",
            "\t Sum of rewards 1.5999999999999992\n",
            "Simulating episode 124\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005608922419263787\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005608922419263787\n",
            "0 1\n",
            "\t First 1 index: [ 2 12 14 21 30 38 49 55 81 86]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 2.2\n",
            "Simulating episode 125\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 13 14 18 37 40 41 47 50 65]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards -1.1102230246251565e-16\n",
            "Simulating episode 126\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.005062052483385567\n",
            "0 1\n",
            "\t First 1 index: [  3  12  23  30  36  40  41  85 113 115]\n",
            "\t Reached sample: 114\n",
            "\t Sum of rewards 4.1\n",
            "Simulating episode 127\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004808949859216288\n",
            "0 1\n",
            "\t First 1 index: [ 1 16 28 51 54 70 82 89 90 97]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards -0.7000000000000001\n",
            "Simulating episode 128\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004568502366255473\n",
            "0 1\n",
            "\t First 1 index: [  5  14  23  36  61  88 116 120 130 131]\n",
            "\t Reached sample: 121\n",
            "\t Sum of rewards 2.8999999999999995\n",
            "Simulating episode 129\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 7 20 29 41 44 46 59 74 75 95]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -0.8999999999999999\n",
            "Simulating episode 130\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004123073385545565\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.004123073385545565\n",
            "0 1\n",
            "\t First 1 index: [  5  22  31  42  45  67  87  88 104 110]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 0.9000000000000001\n",
            "Simulating episode 131\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0039169197162682865\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0039169197162682865\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0039169197162682865\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0039169197162682865\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0039169197162682865\n",
            "0 1\n",
            "\t First 1 index: [ 18  52  65  67  97 102 110 111 130 132]\n",
            "\t Reached sample: 103\n",
            "\t Sum of rewards 2.5000000000000004\n",
            "Simulating episode 132\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.003721073730454872\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.003721073730454872\n",
            "0 1\n",
            "\t First 1 index: [ 0  2 13 15 25 33 36 40 47 56]\n",
            "\t Reached sample: 37\n",
            "\t Sum of rewards 5.2\n",
            "Simulating episode 133\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 10 14 16 17 19 23 35 47 58]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -1.1\n",
            "Simulating episode 134\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0033582690417355214\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0033582690417355214\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0033582690417355214\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0033582690417355214\n",
            "0 1\n",
            "\t First 1 index: [  2  26  63  64  77  95 105 113 118 123]\n",
            "\t Reached sample: 78\n",
            "\t Sum of rewards 3.299999999999999\n",
            "Simulating episode 135\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0031903555896487454\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0031903555896487454\n",
            "0 1\n",
            "\t First 1 index: [ 2  6 26 34 38 47 56 60 75 80]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 1.9000000000000004\n",
            "Simulating episode 136\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.003030837810166308\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.003030837810166308\n",
            "0 1\n",
            "\t First 1 index: [  1  28  36  47  49  67  78  89 103 135]\n",
            "\t Reached sample: 37\n",
            "\t Sum of rewards 1.4\n",
            "Simulating episode 137\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0028792959196579926\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0028792959196579926\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0028792959196579926\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0028792959196579926\n",
            "0 1\n",
            "\t First 1 index: [ 8 32 40 42 43 51 52 73 84 87]\n",
            "\t Reached sample: 85\n",
            "\t Sum of rewards 7.0\n",
            "Simulating episode 138\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002735331123675093\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002735331123675093\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002735331123675093\n",
            "0 1\n",
            "\t First 1 index: [  3   7  13  21  50  54 104 110 116 119]\n",
            "\t Reached sample: 51\n",
            "\t Sum of rewards 4.0\n",
            "Simulating episode 139\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002598564567491338\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002598564567491338\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002598564567491338\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002598564567491338\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002598564567491338\n",
            "0 1\n",
            "\t First 1 index: [  1   3   7  16  18  26  61  76  91 101]\n",
            "\t Reached sample: 102\n",
            "\t Sum of rewards 8.0\n",
            "Simulating episode 140\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002468636339116771\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002468636339116771\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002468636339116771\n",
            "0 1\n",
            "\t First 1 index: [ 5 15 27 56 62 63 68 69 74 78]\n",
            "\t Reached sample: 70\n",
            "\t Sum of rewards 7.0\n",
            "Simulating episode 141\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002345204522160932\n",
            "0 1\n",
            "\t First 1 index: [11 12 48 52 57 59 60 79 83 86]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 142\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0022279442960528853\n",
            "0 1\n",
            "\t First 1 index: [  9  11  31  75 108 118 130 145 161 165]\n",
            "\t Reached sample: 119\n",
            "\t Sum of rewards 7.300000000000001\n",
            "Simulating episode 143\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.002116547081250241\n",
            "0 1\n",
            "\t First 1 index: [ 2 10 14 15 19 20 26 31 37 39]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards 3.500000000000001\n",
            "Simulating episode 144\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 8  9 15 22 27 31 46 54 65 69]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards 0.19999999999999996\n",
            "Simulating episode 145\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0019101837408283422\n",
            "0 1\n",
            "\t First 1 index: [ 4  9 11 31 41 42 44 46 49 53]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 1.3000000000000003\n",
            "Simulating episode 146\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 6 18 29 43 45 57 62 81 86 87]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -0.7999999999999999\n",
            "Simulating episode 147\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0017239408260975788\n",
            "0 1\n",
            "\t First 1 index: [ 8 10 12 20 26 34 47 48 53 65]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 148\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0 16 42 49 56 62 68 69 72 82]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 149\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0015558565955530645\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0015558565955530645\n",
            "\t First 1 index: [11 27 35 38 44 47 54 63 64 66]\n",
            "\t Reached sample: 36\n",
            "\t Sum of rewards 2.1000000000000005\n",
            "Simulating episode 150\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 8 11 42 44 46 50 54 59 60 67]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -1.4\n",
            "Simulating episode 151\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0014041605774866408\n",
            "0 1\n",
            "\t First 1 index: [ 4 19 28 33 34 42 69 76 82 97]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards -1.1102230246251565e-16\n",
            "Simulating episode 152\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0013339525486123086\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0013339525486123086\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0013339525486123086\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0013339525486123086\n",
            "0 1\n",
            "\t First 1 index: [ 2 12 21 22 35 39 49 62 63 68]\n",
            "\t Reached sample: 81\n",
            "\t Sum of rewards 10.4\n",
            "Simulating episode 153\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0012672549211816932\n",
            "0 1\n",
            "\t First 1 index: [ 0  6  9 11 17 24 25 28 29 35]\n",
            "\t Reached sample: 113\n",
            "\t Sum of rewards 13.400000000000002\n",
            "Simulating episode 154\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5  8 10 19 22 24 30 44 45 50]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 155\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001143697566366478\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001143697566366478\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001143697566366478\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001143697566366478\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001143697566366478\n",
            "\t First 1 index: [  3   6  12  13  42  70  87  96 101 108]\n",
            "\t Reached sample: 88\n",
            "\t Sum of rewards 6.1\n",
            "Simulating episode 156\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.001086512688048154\n",
            "\t First 1 index: [  8  26  39  49  61  77  86  94 112 119]\n",
            "\t Reached sample: 120\n",
            "\t Sum of rewards 11.8\n",
            "Simulating episode 157\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0010321870536457462\n",
            "0 1\n",
            "\t First 1 index: [21 23 30 46 58 63 69 73 80 92]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 2.0\n",
            "Simulating episode 158\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009805777009634588\n",
            "0 1\n",
            "\t First 1 index: [ 18  26  27  29  43  55  56  97 112 132]\n",
            "\t Reached sample: 27\n",
            "\t Sum of rewards 0.9000000000000001\n",
            "Simulating episode 159\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009315488159152858\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009315488159152858\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009315488159152858\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009315488159152858\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0009315488159152858\n",
            "0 1\n",
            "\t First 1 index: [ 30  33  53  70  93  95 109 116 144 146]\n",
            "\t Reached sample: 94\n",
            "\t Sum of rewards 5.1\n",
            "Simulating episode 160\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008849713751195214\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008849713751195214\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008849713751195214\n",
            "0 1\n",
            "\t First 1 index: [  2  45  48  53  68  89  93 116 123 136]\n",
            "\t Reached sample: 69\n",
            "\t Sum of rewards 4.999999999999999\n",
            "Simulating episode 161\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008407228063635453\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008407228063635453\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008407228063635453\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0008407228063635453\n",
            "0 1\n",
            "\t First 1 index: [  5  10  17  53  70  97 100 112 114 130]\n",
            "\t Reached sample: 71\n",
            "\t Sum of rewards 5.599999999999998\n",
            "Simulating episode 162\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 3 19 20 36 38 41 44 53 71 79]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 163\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0007587523327430996\n",
            "0 1\n",
            "\t First 1 index: [ 0  3  9 11 29 53 64 68 72 73]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 4.299999999999998\n",
            "Simulating episode 164\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0007208147161059446\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0007208147161059446\n",
            "0 1\n",
            "\t First 1 index: [ 2 13 30 34 36 44 53 60 63 64]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 2.0000000000000004\n",
            "Simulating episode 165\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2  14  19  31  76  88 113 126 129 131]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 166\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000650535281285615\n",
            "0 1\n",
            "\t First 1 index: [ 0  2  9 34 35 59 60 78 79 83]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards 1.5\n",
            "Simulating episode 167\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  4  8 19 28 29 33 34 36 38]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 168\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0005871080913602675\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0005871080913602675\n",
            "0 1\n",
            "\t First 1 index: [17 24 28 37 42 50 66 71 79 86]\n",
            "\t Reached sample: 43\n",
            "\t Sum of rewards 4.799999999999999\n",
            "Simulating episode 169\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2   8  10  29  34  48  89 115 116 120]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards 0.5\n",
            "Simulating episode 170\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0005298650524526413\n",
            "\t First 1 index: [ 1  3 11 13 15 19 23 46 47 54]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards 0.20000000000000018\n",
            "Simulating episode 171\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0005033717998300093\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0005033717998300093\n",
            "0 1\n",
            "\t First 1 index: [ 4  9 34 54 57 67 70 80 86 95]\n",
            "\t Reached sample: 55\n",
            "\t Sum of rewards 4.5\n",
            "Simulating episode 172\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0004782032098385088\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0004782032098385088\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0004782032098385088\n",
            "0 1\n",
            "\t First 1 index: [ 6 13 16 25 43 45 52 53 56 66]\n",
            "\t Reached sample: 46\n",
            "\t Sum of rewards 5.999999999999999\n",
            "Simulating episode 173\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00045429304934658333\n",
            "0 1\n",
            "\t First 1 index: [13 14 18 31 36 38 42 59 61 62]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 3.6000000000000005\n",
            "Simulating episode 174\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00043157839687925413\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00043157839687925413\n",
            "0 1\n",
            "\t First 1 index: [16 23 34 35 46 58 72 76 79 83]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 2.9999999999999996\n",
            "Simulating episode 175\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0004099994770352914\n",
            "\t First 1 index: [  6  11  30  49  50  59 112 123 124 130]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 0.20000000000000018\n",
            "Simulating episode 176\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  9  10  12  33  35  85  86  90 118 121]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards 1.8000000000000003\n",
            "Simulating episode 177\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 4  5 22 30 31 43 47 53 62 73]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -0.7999999999999999\n",
            "Simulating episode 178\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00035152330162313295\n",
            "0 1\n",
            "\t First 1 index: [ 18  38  39  67  74  83 133 140 153 155]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 0.20000000000000018\n",
            "Simulating episode 179\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0003339471365419763\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0003339471365419763\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0003339471365419763\n",
            "0 1\n",
            "\t First 1 index: [ 1  2 27 43 48 51 53 55 59 71]\n",
            "\t Reached sample: 54\n",
            "\t Sum of rewards 8.3\n",
            "Simulating episode 180\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0003172497797148775\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0003172497797148775\n",
            "0 1\n",
            "\t First 1 index: [ 7 10 29 38 49 56 65 88 95 97]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 3.1000000000000005\n",
            "Simulating episode 181\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [14 31 36 44 46 52 74 92 93 94]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 182\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00028631792619267693\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00028631792619267693\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00028631792619267693\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00028631792619267693\n",
            "0 1\n",
            "\t First 1 index: [12 35 40 41 42 49 53 68 71 84]\n",
            "\t Reached sample: 69\n",
            "\t Sum of rewards 9.5\n",
            "Simulating episode 183\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00027200202988304306\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00027200202988304306\n",
            "\t First 1 index: [ 3 11 13 21 31 34 41 47 72 75]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 4.7\n",
            "Simulating episode 184\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 8 15 17 34 43 54 58 59 62 65]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 185\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00024548183196944633\n",
            "0 1\n",
            "\t First 1 index: [ 14  34  35  40  72  80  82  91  94 101]\n",
            "\t Reached sample: 199\n",
            "\t Sum of rewards 23.3\n",
            "Simulating episode 186\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000233207740370974\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000233207740370974\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000233207740370974\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000233207740370974\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.000233207740370974\n",
            "0 1\n",
            "\t First 1 index: [  7   8  48  50  92 100 119 120 124 127]\n",
            "\t Reached sample: 101\n",
            "\t Sum of rewards 8.5\n",
            "Simulating episode 187\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0002215473533524253\n",
            "0 1\n",
            "\t First 1 index: [ 10  31  87  92  93 106 115 141 144 152]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 188\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00021046998568480404\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00021046998568480404\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00021046998568480404\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00021046998568480404\n",
            "0 1\n",
            "\t First 1 index: [ 20  70  79  83  90  97  99 101 108 117]\n",
            "\t Reached sample: 91\n",
            "\t Sum of rewards 6.8\n",
            "Simulating episode 189\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00019994648640056381\n",
            "0 1\n",
            "\t First 1 index: [ 4  7 11 19 32 56 60 73 90 92]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards 3.2\n",
            "Simulating episode 190\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00018994916208053562\n",
            "0 1\n",
            "\t First 1 index: [ 0  7  8 13 32 33 41 42 55 57]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 0.20000000000000007\n",
            "Simulating episode 191\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2   4  10  39  44  47  95  96 109 112]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 192\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00017142911877768337\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00017142911877768337\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00017142911877768337\n",
            "0 1\n",
            "\t First 1 index: [ 8 32 33 38 55 61 66 68 78 88]\n",
            "\t Reached sample: 67\n",
            "\t Sum of rewards 9.4\n",
            "Simulating episode 193\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  5 18 27 30 40 45 48 69 75]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 194\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00015471477969685924\n",
            "0 1\n",
            "\t First 1 index: [ 51  83  91 140 175 207 219 222 279 303]\n",
            "\t Reached sample: 141\n",
            "\t Sum of rewards 10.7\n",
            "Simulating episode 195\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00014697904071201627\n",
            "0 1\n",
            "\t First 1 index: [  0   9  19  27  42  43  47  74  80 110]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 196\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013963008867641546\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013963008867641546\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013963008867641546\n",
            "0 1\n",
            "\t First 1 index: [  8  38  49  68  80  90  91  94  99 101]\n",
            "\t Reached sample: 69\n",
            "\t Sum of rewards 6.299999999999999\n",
            "Simulating episode 197\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00013264858424259467\n",
            "0 1\n",
            "\t First 1 index: [ 13  21  35  50  66 113 122 126 127 140]\n",
            "\t Reached sample: 141\n",
            "\t Sum of rewards 17.900000000000002\n",
            "Simulating episode 198\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00012601615503046493\n",
            "0 1\n",
            "\t First 1 index: [  5   7  14  35  40  52  82  84  93 104]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 199\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 6 12 17 28 41 47 49 62 66 74]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 200\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  6 12 25 33 36 37 49 54 82]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards 0.30000000000000027\n",
            "Simulating episode 201\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00010804310091924485\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.00010804310091924485\n",
            "0 1\n",
            "\t First 1 index: [ 2  8 10 23 33 40 43 50 56 59]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 3.8000000000000007\n",
            "Simulating episode 202\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 15 28 31 34 75 85 86 89 93]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 203\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.750889857961847e-05\n",
            "0 1\n",
            "\t First 1 index: [ 19  20  31  51  54  62  63  66 109 114]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards 0.30000000000000027\n",
            "Simulating episode 204\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.263345365063754e-05\n",
            "0 1\n",
            "\t First 1 index: [ 4 12 17 22 39 52 57 63 75 78]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 2.1000000000000005\n",
            "Simulating episode 205\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.800178096810566e-05\n",
            "0 1\n",
            "\t First 1 index: [  1   2  48  59  74  81  90 115 116 117]\n",
            "\t Reached sample: 116\n",
            "\t Sum of rewards 13.6\n",
            "Simulating episode 206\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.360169191970037e-05\n",
            "0 1\n",
            "\t First 1 index: [ 33  43  63  74  76  77  79  92 111 112]\n",
            "\t Reached sample: 34\n",
            "\t Sum of rewards 1.7000000000000002\n",
            "Simulating episode 207\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.942160732371535e-05\n",
            "0 1\n",
            "\t First 1 index: [ 12  15  41  50  66 125 129 132 137 156]\n",
            "\t Reached sample: 130\n",
            "\t Sum of rewards 14.9\n",
            "Simulating episode 208\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.545052695752958e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.545052695752958e-05\n",
            "0 1\n",
            "\t First 1 index: [ 34  38  39  58  61  65  66  73 100 102]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 1.6000000000000005\n",
            "Simulating episode 209\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 0  6 16 18 23 38 40 46 50 58]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 1.8000000000000003\n",
            "Simulating episode 210\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.809410057917043e-05\n",
            "0 1\n",
            "\t First 1 index: [ 17  30  35  47  52  71  86  94 104 127]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 0.5\n",
            "Simulating episode 211\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.46893955502119e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.46893955502119e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.46893955502119e-05\n",
            "0 1\n",
            "\t First 1 index: [ 11  13  41  56  81 106 120 122 138 151]\n",
            "\t Reached sample: 57\n",
            "\t Sum of rewards 5.500000000000001\n",
            "Simulating episode 212\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.145492577270131e-05\n",
            "0 1\n",
            "\t First 1 index: [ 1  4  7  9 25 27 35 49 53 54]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 1.5\n",
            "Simulating episode 213\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [11 20 43 52 58 60 66 77 79 98]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 214\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.546307050986292e-05\n",
            "0 1\n",
            "\t First 1 index: [ 6 17 21 28 29 31 56 61 71 90]\n",
            "\t Reached sample: 156\n",
            "\t Sum of rewards 22.300000000000004\n",
            "Simulating episode 215\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.2689916984369774e-05\n",
            "0 1\n",
            "\t First 1 index: [  7  23  36  55  63  64  79  82 116 123]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 1.6\n",
            "Simulating episode 216\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.005542113515128e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.005542113515128e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.005542113515128e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.005542113515128e-05\n",
            "0 1\n",
            "\t First 1 index: [  0   7  36  44  47  55  63  75  87 125]\n",
            "\t Reached sample: 76\n",
            "\t Sum of rewards 10.2\n",
            "Simulating episode 217\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.755265007839372e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.755265007839372e-05\n",
            "0 1\n",
            "\t First 1 index: [ 20  23  33  46  47  63  70  77  88 103]\n",
            "\t Reached sample: 34\n",
            "\t Sum of rewards 2.7\n",
            "Simulating episode 218\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.517501757447403e-05\n",
            "0 1\n",
            "\t First 1 index: [  6  21  29  74  87  95 102 109 110 124]\n",
            "\t Reached sample: 22\n",
            "\t Sum of rewards 0.8000000000000007\n",
            "Simulating episode 219\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 8  9 16 28 37 68 70 76 83 89]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 220\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.07704533609628e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.07704533609628e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.07704533609628e-05\n",
            "0 1\n",
            "\t First 1 index: [  7  14  27  40  64  78  92  94 112 113]\n",
            "\t Reached sample: 65\n",
            "\t Sum of rewards 7.000000000000002\n",
            "Simulating episode 221\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.873193069291466e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.873193069291466e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.873193069291466e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.873193069291466e-05\n",
            "0 1\n",
            "\t First 1 index: [ 11  26  32  77  91  99 127 134 150 154]\n",
            "\t Reached sample: 78\n",
            "\t Sum of rewards 7.799999999999999\n",
            "Simulating episode 222\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.679533415826893e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.679533415826893e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.679533415826893e-05\n",
            "0 1\n",
            "\t First 1 index: [12 13 32 44 47 52 63 67 71 73]\n",
            "\t Reached sample: 45\n",
            "\t Sum of rewards 4.699999999999999\n",
            "Simulating episode 223\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0 19 22 31 37 39 42 62 74 78]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 224\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 4 21 24 25 38 42 51 74 80 90]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 225\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.154739962394582e-05\n",
            "0 1\n",
            "\t First 1 index: [ 2  5 13 23 26 28 41 46 76 80]\n",
            "\t Reached sample: 27\n",
            "\t Sum of rewards 4.8\n",
            "Simulating episode 226\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.9970029642748528e-05\n",
            "0 1\n",
            "\t First 1 index: [ 11  30  32  66  79  84  85  96 110 129]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards -0.30000000000000004\n",
            "Simulating episode 227\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.84715281606111e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.84715281606111e-05\n",
            "0 1\n",
            "\t First 1 index: [  1  14  18  20  31  43  50  86 108 109]\n",
            "\t Reached sample: 51\n",
            "\t Sum of rewards 8.8\n",
            "Simulating episode 228\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7047951752580546e-05\n",
            "0 1\n",
            "\t First 1 index: [ 3  8 10 15 16 21 22 25 33 36]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 229\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5695554164951517e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5695554164951517e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5695554164951517e-05\n",
            "0 1\n",
            "\t First 1 index: [ 34  49  61  67  70  71  75  95  98 112]\n",
            "\t Reached sample: 76\n",
            "\t Sum of rewards 10.7\n",
            "Simulating episode 230\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.441077645670394e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.441077645670394e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.441077645670394e-05\n",
            "0 1\n",
            "\t First 1 index: [12 22 41 44 53 58 62 64 83 86]\n",
            "\t Reached sample: 45\n",
            "\t Sum of rewards 4.7\n",
            "Simulating episode 231\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.3190237633868742e-05\n",
            "0 1\n",
            "\t First 1 index: [ 12  30  40  41  46  50  52  83  97 100]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 2.1000000000000005\n",
            "Simulating episode 232\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2030725752175304e-05\n",
            "0 1\n",
            "\t First 1 index: [  0  19  20  29  58  71  80  84 154 156]\n",
            "\t Reached sample: 161\n",
            "\t Sum of rewards 18.5\n",
            "Simulating episode 233\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.092918946456654e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.092918946456654e-05\n",
            "0 1\n",
            "\t First 1 index: [ 30  33  35  59  78 100 117 132 139 143]\n",
            "\t Reached sample: 36\n",
            "\t Sum of rewards 2.7\n",
            "Simulating episode 234\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.988272999133821e-05\n",
            "0 1\n",
            "\t First 1 index: [23 41 42 43 60 65 69 73 87 92]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 0.29999999999999993\n",
            "Simulating episode 235\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8888593491771298e-05\n",
            "0 1\n",
            "\t First 1 index: [  0  15  21  35  53  74 120 135 142 152]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 1.4000000000000004\n",
            "Simulating episode 236\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7944163817182733e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7944163817182733e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7944163817182733e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7944163817182733e-05\n",
            "0 1\n",
            "\t First 1 index: [ 23  26  49  57  61  73  76  77  87 101]\n",
            "\t Reached sample: 77\n",
            "\t Sum of rewards 9.4\n",
            "Simulating episode 237\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7046955626323596e-05\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7046955626323596e-05\n",
            "\t First 1 index: [ 10  15  31  38  39  49  72  91  98 106]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 2.7\n",
            "Simulating episode 238\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  6  40  55  56  57  75  98 108 115 119]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 239\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 7 11 14 18 53 57 72 78 93 99]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 0.8000000000000003\n",
            "Simulating episode 240\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.461563358011919e-05\n",
            "\t First 1 index: [ 0  3 19 28 36 38 40 52 64 66]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 241\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.388485190111323e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.388485190111323e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.388485190111323e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.388485190111323e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.388485190111323e-05\n",
            "0 1\n",
            "\t First 1 index: [  4  48  64  70 101 109 110 114 118 120]\n",
            "\t Reached sample: 119\n",
            "\t Sum of rewards 13.799999999999999\n",
            "Simulating episode 242\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3190609306057568e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3190609306057568e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3190609306057568e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3190609306057568e-05\n",
            "0 1\n",
            "\t First 1 index: [17 24 58 66 70 72 77 84 93 98]\n",
            "\t Reached sample: 67\n",
            "\t Sum of rewards 5.299999999999999\n",
            "Simulating episode 243\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2531078840754689e-05\n",
            "0 1\n",
            "\t First 1 index: [  1   5  20  52  65  69  77  82 101 105]\n",
            "\t Reached sample: 21\n",
            "\t Sum of rewards 2.8000000000000007\n",
            "Simulating episode 244\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1904524898716955e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1904524898716955e-05\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1904524898716955e-05\n",
            "0 1\n",
            "\t First 1 index: [  9  41  53  61  66  95 124 131 144 150]\n",
            "\t Reached sample: 62\n",
            "\t Sum of rewards 5.6\n",
            "Simulating episode 245\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1309298653781106e-05\n",
            "0 1\n",
            "\t First 1 index: [ 4 26 36 39 52 55 64 76 83 91]\n",
            "\t Reached sample: 27\n",
            "\t Sum of rewards 2.3000000000000007\n",
            "Simulating episode 246\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.074383372109205e-05\n",
            "0 1\n",
            "\t First 1 index: [ 7  9 13 14 18 20 50 56 59 66]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 3.8000000000000007\n",
            "Simulating episode 247\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0206642035037448e-05\n",
            "0 1\n",
            "\t First 1 index: [13 14 22 24 28 29 39 65 67 68]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 248\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.696309933285576e-06\n",
            "0 1\n",
            "\t First 1 index: [ 3 40 44 51 54 55 58 66 75 85]\n",
            "\t Reached sample: 148\n",
            "\t Sum of rewards 24.200000000000003\n",
            "Simulating episode 249\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.211494436621297e-06\n",
            "0 1\n",
            "\t First 1 index: [  8  10  13  19  27  53  60  67  76 107]\n",
            "\t Reached sample: 180\n",
            "\t Sum of rewards 24.1\n",
            "Simulating episode 250\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.750919714790231e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.750919714790231e-06\n",
            "0 1\n",
            "\t First 1 index: [16 25 36 41 51 55 68 77 79 82]\n",
            "\t Reached sample: 37\n",
            "\t Sum of rewards 3.3999999999999986\n",
            "Simulating episode 251\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.31337372905072e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.31337372905072e-06\n",
            "0 1\n",
            "\t First 1 index: [ 14  17  18  42  46  48  52  81  97 114]\n",
            "\t Reached sample: 43\n",
            "\t Sum of rewards 5.1\n",
            "Simulating episode 252\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.897705042598182e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.897705042598182e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.897705042598182e-06\n",
            "0 1\n",
            "\t First 1 index: [  1  39  53  58  98 108 110 113 127 130]\n",
            "\t Reached sample: 59\n",
            "\t Sum of rewards 7.1\n",
            "Simulating episode 253\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.502819790468273e-06\n",
            "0 1\n",
            "\t First 1 index: [ 3  7 20 22 26 30 40 47 59 73]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 254\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.127678800944859e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.127678800944859e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.127678800944859e-06\n",
            "0 1\n",
            "\t First 1 index: [ 12  41  44  60  64  74  86  96 100 115]\n",
            "\t Reached sample: 61\n",
            "\t Sum of rewards 6.299999999999999\n",
            "Simulating episode 255\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.7712948608976155e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.7712948608976155e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.7712948608976155e-06\n",
            "0 1\n",
            "\t First 1 index: [ 26  56  58  94 109 141 144 161 180 182]\n",
            "\t Reached sample: 57\n",
            "\t Sum of rewards 4.5\n",
            "Simulating episode 256\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.4327301178527345e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.4327301178527345e-06\n",
            "0 1\n",
            "\t First 1 index: [  0  40  54  55  60  61 108 115 121 135]\n",
            "\t Reached sample: 55\n",
            "\t Sum of rewards 5.399999999999999\n",
            "Simulating episode 257\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.111093611960097e-06\n",
            "0 1\n",
            "\t First 1 index: [  3   9  14  21  35  42  44  92 107 112]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 258\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.805538931362092e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.805538931362092e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.805538931362092e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.805538931362092e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.805538931362092e-06\n",
            "0 1\n",
            "\t First 1 index: [  9  64  66  71 103 109 115 120 124 125]\n",
            "\t Reached sample: 110\n",
            "\t Sum of rewards 11.799999999999999\n",
            "Simulating episode 259\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 4  7 11 15 21 29 37 39 48 59]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 260\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.239498885554288e-06\n",
            "0 1\n",
            "\t First 1 index: [ 2 15 16 17 36 38 43 55 76 84]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 261\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  5 14 21 26 32 54 58 61 62]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 262\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.728647744212744e-06\n",
            "0 1\n",
            "\t First 1 index: [ 5  9 15 19 31 32 35 37 42 59]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 5.700000000000001\n",
            "Simulating episode 263\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.492215357002106e-06\n",
            "0 1\n",
            "\t First 1 index: [ 15  19  22  56  70  83  98 122 139 140]\n",
            "\t Reached sample: 23\n",
            "\t Sum of rewards 2.6000000000000005\n",
            "Simulating episode 264\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.267604589152001e-06\n",
            "\t First 1 index: [  0  12  33  41  59  79  89 104 106 113]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 265\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5  6 16 20 29 37 40 43 44 47]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 2.2\n",
            "Simulating episode 266\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.851513141709681e-06\n",
            "0 1\n",
            "\t First 1 index: [ 4  5 15 17 28 34 36 45 46 55]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards 0.3999999999999999\n",
            "Simulating episode 267\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.6589374846241966e-06\n",
            "0 1\n",
            "\t First 1 index: [ 32  41  56  57  69  73  74  75  87 120]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 1.8000000000000003\n",
            "Simulating episode 268\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.4759906103929867e-06\n",
            "0 1\n",
            "\t First 1 index: [17 20 31 36 40 41 42 53 58 94]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 0.5000000000000002\n",
            "Simulating episode 269\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.3021910798733374e-06\n",
            "0 1\n",
            "\t First 1 index: [ 4 13 17 28 55 67 69 76 81 92]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 2.3000000000000003\n",
            "Simulating episode 270\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 33 37 41 49 62 65 66 74 84]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 271\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.9802274495856867e-06\n",
            "0 1\n",
            "\t First 1 index: [ 4 20 30 31 45 51 56 58 61 75]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards -0.6\n",
            "Simulating episode 272\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.831216077106402e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.831216077106402e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.831216077106402e-06\n",
            "0 1\n",
            "\t First 1 index: [ 3 20 30 35 38 39 54 61 66 68]\n",
            "\t Reached sample: 67\n",
            "\t Sum of rewards 11.600000000000001\n",
            "Simulating episode 273\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.689655273251082e-06\n",
            "0 1\n",
            "\t First 1 index: [ 3 14 16 33 35 47 60 64 75 84]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 1.1000000000000005\n",
            "Simulating episode 274\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  1   7  18  28  62  89  97 100 114 125]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 275\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.427413884109101e-06\n",
            "0 1\n",
            "\t First 1 index: [ 10  31  35  46  47  63  83  90  95 104]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 276\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.306043189903646e-06\n",
            "0 1\n",
            "\t First 1 index: [  0   9  15  33  60  63  82  97 100 109]\n",
            "\t Reached sample: 201\n",
            "\t Sum of rewards 33.5\n",
            "Simulating episode 277\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1907410304084634e-06\n",
            "0 1\n",
            "\t First 1 index: [  4  33  63  65  66  95 104 118 122 130]\n",
            "\t Reached sample: 34\n",
            "\t Sum of rewards 2.4000000000000004\n",
            "Simulating episode 278\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.0812039788880403e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.0812039788880403e-06\n",
            "0 1\n",
            "\t First 1 index: [16 17 21 24 26 31 37 45 53 62]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 6.0\n",
            "Simulating episode 279\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.977143779943638e-06\n",
            "0 1\n",
            "\t First 1 index: [ 18  28  49  55  75  78  81  90  96 104]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 0.6000000000000003\n",
            "Simulating episode 280\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8782865909464561e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8782865909464561e-06\n",
            "0 1\n",
            "\t First 1 index: [ 22  29  36  38  73  74  77  78  83 128]\n",
            "\t Reached sample: 39\n",
            "\t Sum of rewards 3.700000000000001\n",
            "Simulating episode 281\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7843722613991332e-06\n",
            "0 1\n",
            "\t First 1 index: [ 12  18  37  71 106 115 121 122 138 147]\n",
            "\t Reached sample: 122\n",
            "\t Sum of rewards 14.300000000000002\n",
            "Simulating episode 282\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6951536483291766e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6951536483291766e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6951536483291766e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6951536483291766e-06\n",
            "0 1\n",
            "\t First 1 index: [ 3 18 32 39 52 72 79 82 94 97]\n",
            "\t Reached sample: 83\n",
            "\t Sum of rewards 11.900000000000002\n",
            "Simulating episode 283\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6103959659127178e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6103959659127178e-06\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6103959659127178e-06\n",
            "\t First 1 index: [24 34 42 45 51 55 58 70 83 90]\n",
            "\t Reached sample: 46\n",
            "\t Sum of rewards 5.399999999999999\n",
            "Simulating episode 284\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0 11 22 28 37 44 45 50 52 54]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 285\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 3  9 10 16 17 37 38 66 82 89]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 3.0999999999999996\n",
            "Simulating episode 286\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  2 10 32 46 52 83 91 92 94]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 287\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3116775792106952e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3116775792106952e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3116775792106952e-06\n",
            "0 1\n",
            "\t First 1 index: [ 40  47  50  70  72 137 160 166 169 181]\n",
            "\t Reached sample: 48\n",
            "\t Sum of rewards 4.0\n",
            "Simulating episode 288\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2460937002501604e-06\n",
            "0 1\n",
            "\t First 1 index: [ 15  19  25  55  64  79  90 100 101 107]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 2.9000000000000004\n",
            "Simulating episode 289\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1837890152376523e-06\n",
            "0 1\n",
            "\t First 1 index: [10 16 21 45 49 69 74 75 80 83]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 1.3000000000000003\n",
            "Simulating episode 290\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5  7 17 19 43 61 63 81 92 94]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 291\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.068369586251981e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.068369586251981e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.068369586251981e-06\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.068369586251981e-06\n",
            "0 1\n",
            "\t First 1 index: [13 26 31 33 41 49 57 62 68 69]\n",
            "\t Reached sample: 69\n",
            "\t Sum of rewards 12.2\n",
            "Simulating episode 292\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0149511069393819e-06\n",
            "0 1\n",
            "\t First 1 index: [ 1  5  6 12 14 18 22 32 42 46]\n",
            "\t Reached sample: 23\n",
            "\t Sum of rewards 5.999999999999999\n",
            "Simulating episode 293\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.642035515924128e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.642035515924128e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.642035515924128e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.642035515924128e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.642035515924128e-07\n",
            "0 1\n",
            "\t First 1 index: [ 26  32  37  44  56  60  67  78  85 110]\n",
            "\t Reached sample: 111\n",
            "\t Sum of rewards 14.7\n",
            "Simulating episode 294\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.159933740127921e-07\n",
            "0 1\n",
            "\t First 1 index: [ 8  9 26 28 30 37 43 55 63 73]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.19999999999999996\n",
            "Simulating episode 295\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.701937053121525e-07\n",
            "0 1\n",
            "\t First 1 index: [ 6 12 16 26 28 40 45 50 63 89]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 2.0\n",
            "Simulating episode 296\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1 10 11 12 20 30 32 36 41 54]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 297\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.853498190442176e-07\n",
            "0 1\n",
            "\t First 1 index: [ 7  9 12 21 23 25 30 37 42 43]\n",
            "\t Reached sample: 175\n",
            "\t Sum of rewards 29.700000000000003\n",
            "Simulating episode 298\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.460823280920066e-07\n",
            "0 1\n",
            "\t First 1 index: [ 15  42  51  52 101 103 128 131 139 148]\n",
            "\t Reached sample: 180\n",
            "\t Sum of rewards 25.8\n",
            "Simulating episode 299\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  3 34 47 54 57 71 90 96 99]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 300\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.733393011030359e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.733393011030359e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.733393011030359e-07\n",
            "0 1\n",
            "\t First 1 index: [ 19  36  40  48  70  85 101 116 122 136]\n",
            "\t Reached sample: 71\n",
            "\t Sum of rewards 7.599999999999998\n",
            "Simulating episode 301\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.396723360478841e-07\n",
            "0 1\n",
            "\t First 1 index: [ 1  4  5 16 17 24 28 39 45 46]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 3.0999999999999996\n",
            "Simulating episode 302\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.076887192454898e-07\n",
            "0 1\n",
            "\t First 1 index: [  8  37  44  50  66  69  83 108 111 125]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.19999999999999996\n",
            "Simulating episode 303\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.773042832832152e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.773042832832152e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.773042832832152e-07\n",
            "0 1\n",
            "\t First 1 index: [  9  26  39  43  57  67  95  96  98 104]\n",
            "\t Reached sample: 68\n",
            "\t Sum of rewards 9.2\n",
            "Simulating episode 304\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.484390691190545e-07\n",
            "0 1\n",
            "\t First 1 index: [10 13 14 42 54 58 61 68 77 80]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 0.8\n",
            "Simulating episode 305\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [11 18 21 32 43 45 47 51 52 56]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards -0.09999999999999998\n",
            "Simulating episode 306\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.949662598799467e-07\n",
            "0 1\n",
            "\t First 1 index: [ 15  19  24  26  32  82  83  85  92 107]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 0.10000000000000014\n",
            "Simulating episode 307\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.702179468859493e-07\n",
            "0 1\n",
            "\t First 1 index: [ 0  4 14 17 18 27 36 53 54 64]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 2.8000000000000003\n",
            "Simulating episode 308\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.467070495416518e-07\n",
            "0 1\n",
            "\t First 1 index: [  3  12  26  32  47  53  54  64  70 117]\n",
            "\t Reached sample: 119\n",
            "\t Sum of rewards 16.60000000000001\n",
            "Simulating episode 309\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5  6  9 18 26 42 58 59 66 76]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -0.10000000000000009\n",
            "Simulating episode 310\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1 16 27 28 43 52 64 66 69 74]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 311\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.8299545660077364e-07\n",
            "0 1\n",
            "\t First 1 index: [  6  27  35  52  68  73  80 105 115 138]\n",
            "\t Reached sample: 209\n",
            "\t Sum of rewards 25.800000000000004\n",
            "Simulating episode 312\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.6384568377073495e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.6384568377073495e-07\n",
            "0 1\n",
            "\t First 1 index: [16 26 28 35 37 39 51 60 69 86]\n",
            "\t Reached sample: 40\n",
            "\t Sum of rewards 6.600000000000001\n",
            "Simulating episode 313\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.4565339958219817e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.4565339958219817e-07\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.4565339958219817e-07\n",
            "\t First 1 index: [11 29 31 38 40 50 51 55 60 79]\n",
            "\t Reached sample: 52\n",
            "\t Sum of rewards 8.5\n",
            "Simulating episode 314\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.283707296030882e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.283707296030882e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.283707296030882e-07\n",
            "0 1\n",
            "\t First 1 index: [ 38  44  66  67  78  84  98 101 116 128]\n",
            "\t Reached sample: 68\n",
            "\t Sum of rewards 7.6\n",
            "Simulating episode 315\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.119521931229338e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.119521931229338e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.119521931229338e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.119521931229338e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.119521931229338e-07\n",
            "0 1\n",
            "\t First 1 index: [ 0 48 56 62 72 76 81 95 97 98]\n",
            "\t Reached sample: 99\n",
            "\t Sum of rewards 15.899999999999999\n",
            "Simulating episode 316\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.963545834667871e-07\n",
            "0 1\n",
            "\t First 1 index: [ 7 25 33 41 49 60 71 95 97 99]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 2.0000000000000004\n",
            "Simulating episode 317\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.815368542934477e-07\n",
            "0 1\n",
            "\t First 1 index: [13 23 26 34 38 39 50 77 84 88]\n",
            "\t Reached sample: 163\n",
            "\t Sum of rewards 29.100000000000005\n",
            "Simulating episode 318\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.674600115787753e-07\n",
            "0 1\n",
            "\t First 1 index: [ 2  3  6  8  9 16 26 51 76 77]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards 2.5\n",
            "Simulating episode 319\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5408701099983655e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5408701099983655e-07\n",
            "0 1\n",
            "\t First 1 index: [ 35  36  37  54  64  80  86  90  93 105]\n",
            "\t Reached sample: 36\n",
            "\t Sum of rewards 1.9000000000000008\n",
            "Simulating episode 320\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.413826604498447e-07\n",
            "0 1\n",
            "\t First 1 index: [ 9 16 24 27 50 67 68 71 76 85]\n",
            "\t Reached sample: 25\n",
            "\t Sum of rewards 2.4000000000000004\n",
            "Simulating episode 321\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2931352742735246e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2931352742735246e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2931352742735246e-07\n",
            "0 1\n",
            "\t First 1 index: [ 26  61  62  70  76  77  86  93  95 105]\n",
            "\t Reached sample: 63\n",
            "\t Sum of rewards 6.399999999999999\n",
            "Simulating episode 322\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.1784785105598482e-07\n",
            "0 1\n",
            "\t First 1 index: [  6  14  27  28  32  42  49  74  78 103]\n",
            "\t Reached sample: 135\n",
            "\t Sum of rewards 19.4\n",
            "Simulating episode 323\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 14  20  27  39  44  45  48  63  96 102]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 0.40000000000000036\n",
            "Simulating episode 324\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9660768557802627e-07\n",
            "0 1\n",
            "\t First 1 index: [ 5  6  7 35 36 38 50 62 66 78]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 325\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8677730129912496e-07\n",
            "0 1\n",
            "\t First 1 index: [ 3 11 27 32 34 44 51 56 67 74]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 4.1000000000000005\n",
            "Simulating episode 326\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7743843623416871e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7743843623416871e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7743843623416871e-07\n",
            "0 1\n",
            "\t First 1 index: [14 25 40 44 45 46 51 56 77 87]\n",
            "\t Reached sample: 52\n",
            "\t Sum of rewards 8.1\n",
            "Simulating episode 327\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2  12  15  21  61  69  73  85  94 114]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 328\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 0  1  3  5  8 11 20 24 29 48]\n",
            "\t Reached sample: 4\n",
            "\t Sum of rewards 1.1\n",
            "Simulating episode 329\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5213127926627037e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5213127926627037e-07\n",
            "0 1\n",
            "\t First 1 index: [  2  13  23  33  46  67  74  91  94 100]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 3.1000000000000005\n",
            "Simulating episode 330\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.4452471530295685e-07\n",
            "\t First 1 index: [  4   8  18  31  34  55  61 104 114 172]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 2.4000000000000004\n",
            "Simulating episode 331\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.37298479537809e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.37298479537809e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.37298479537809e-07\n",
            "0 1\n",
            "\t First 1 index: [15 24 31 43 48 55 59 60 72 74]\n",
            "\t Reached sample: 75\n",
            "\t Sum of rewards 13.3\n",
            "Simulating episode 332\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3043355556091855e-07\n",
            "0 1\n",
            "\t First 1 index: [ 12  23  61  73  79  81  84 109 114 116]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards 0.0\n",
            "Simulating episode 333\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  2  3  7 21 30 31 63 77 79]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 334\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1771628389372899e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1771628389372899e-07\n",
            "0 1\n",
            "\t First 1 index: [ 12  32  35  49  54  62  74  77  94 115]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 2.7\n",
            "Simulating episode 335\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1183046969904254e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1183046969904254e-07\n",
            "0 1\n",
            "\t First 1 index: [ 4 13 14 19 34 36 39 51 71 87]\n",
            "\t Reached sample: 52\n",
            "\t Sum of rewards 8.6\n",
            "Simulating episode 336\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.062389462140904e-07\n",
            "0 1\n",
            "\t First 1 index: [ 8  9 24 35 59 68 71 75 88 94]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards 0.3999999999999999\n",
            "Simulating episode 337\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0092699890338587e-07\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0092699890338587e-07\n",
            "0 1\n",
            "\t First 1 index: [24 34 39 40 49 54 74 78 81 82]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 2.5000000000000004\n",
            "Simulating episode 338\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.588064895821657e-08\n",
            "0 1\n",
            "\t First 1 index: [24 25 29 41 53 64 67 73 81 88]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 2.2\n",
            "Simulating episode 339\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  6  30  46  49  53  64  94 113 125 144]\n",
            "\t Reached sample: 7\n",
            "\t Sum of rewards -0.4\n",
            "Simulating episode 340\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.653228568479046e-08\n",
            "0 1\n",
            "\t First 1 index: [ 1  2  4 12 13 14 15 39 59 69]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 5.300000000000001\n",
            "Simulating episode 341\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.220567140055093e-08\n",
            "0 1\n",
            "\t First 1 index: [ 1 10 20 21 23 24 39 49 55 69]\n",
            "\t Reached sample: 24\n",
            "\t Sum of rewards 4.5\n",
            "Simulating episode 342\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.809538783052339e-08\n",
            "0 1\n",
            "\t First 1 index: [ 3 16 33 40 41 43 45 67 74 78]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 1.1\n",
            "Simulating episode 343\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.419061843899721e-08\n",
            "0 1\n",
            "\t First 1 index: [  1  13  16  25  34  40  41  97 100 105]\n",
            "\t Reached sample: 17\n",
            "\t Sum of rewards 2.0\n",
            "Simulating episode 344\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.048108751704735e-08\n",
            "0 1\n",
            "\t First 1 index: [ 14  26  37  40  53  87 107 110 114 118]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards -1.1102230246251565e-16\n",
            "Simulating episode 345\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 11 22 25 31 32 53 54 62 70]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 346\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.360918148413524e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.360918148413524e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.360918148413524e-08\n",
            "0 1\n",
            "\t First 1 index: [28 31 47 48 50 57 60 63 78 85]\n",
            "\t Reached sample: 64\n",
            "\t Sum of rewards 10.200000000000001\n",
            "Simulating episode 347\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.042872240992848e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.042872240992848e-08\n",
            "0 1\n",
            "\t First 1 index: [25 34 42 44 46 62 79 81 84 99]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 2.5000000000000004\n",
            "Simulating episode 348\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.740728628943205e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.740728628943205e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.740728628943205e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.740728628943205e-08\n",
            "0 1\n",
            "\t First 1 index: [ 2 14 16 19 46 49 50 56 67 69]\n",
            "\t Reached sample: 74\n",
            "\t Sum of rewards 15.000000000000004\n",
            "Simulating episode 349\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.4536921974960444e-08\n",
            "\t First 1 index: [16 19 30 38 49 52 54 64 79 88]\n",
            "\t Reached sample: 118\n",
            "\t Sum of rewards 21.000000000000007\n",
            "Simulating episode 350\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.181007587621242e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.181007587621242e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.181007587621242e-08\n",
            "0 1\n",
            "\t First 1 index: [ 18  23  24  35  53  60  83  99 113 124]\n",
            "\t Reached sample: 61\n",
            "\t Sum of rewards 9.099999999999998\n",
            "Simulating episode 351\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.9219572082401796e-08\n",
            "0 1\n",
            "\t First 1 index: [ 49  63  82  96 106 108 130 134 138 159]\n",
            "\t Reached sample: 131\n",
            "\t Sum of rewards 14.2\n",
            "Simulating episode 352\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.67585934782817e-08\n",
            "0 1\n",
            "\t First 1 index: [ 8 11 19 27 30 34 48 50 51 87]\n",
            "\t Reached sample: 141\n",
            "\t Sum of rewards 24.0\n",
            "Simulating episode 353\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.442066380436761e-08\n",
            "0 1\n",
            "\t First 1 index: [ 14  17  51  53  56  65  73  90  96 121]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 0.20000000000000018\n",
            "Simulating episode 354\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.219963061414923e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.219963061414923e-08\n",
            "0 1\n",
            "\t First 1 index: [  8  15  17  42  47  48  59  92  99 106]\n",
            "\t Reached sample: 43\n",
            "\t Sum of rewards 5.500000000000001\n",
            "Simulating episode 355\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.0089649083441766e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.0089649083441766e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.0089649083441766e-08\n",
            "0 1\n",
            "\t First 1 index: [ 7 10 15 25 36 49 54 64 77 81]\n",
            "\t Reached sample: 50\n",
            "\t Sum of rewards 7.000000000000002\n",
            "Simulating episode 356\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.808516662926968e-08\n",
            "0 1\n",
            "\t First 1 index: [  9  15  19  51  72  76  80  87 110 115]\n",
            "\t Reached sample: 20\n",
            "\t Sum of rewards 2.5000000000000004\n",
            "Simulating episode 357\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 13  53  59  60  65 102 114 115 129 132]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 358\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.437186288291588e-08\n",
            "0 1\n",
            "\t First 1 index: [  4  23  32  58  64  65 101 103 109 118]\n",
            "\t Reached sample: 123\n",
            "\t Sum of rewards 19.100000000000005\n",
            "Simulating episode 359\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.2653269738770084e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.2653269738770084e-08\n",
            "0 1\n",
            "\t First 1 index: [  1  11  18  36  50  51  71  76 102 104]\n",
            "\t Reached sample: 37\n",
            "\t Sum of rewards 4.099999999999999\n",
            "Simulating episode 360\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.102060625183158e-08\n",
            "0 1\n",
            "\t First 1 index: [11 12 14 17 25 36 41 46 47 58]\n",
            "\t Reached sample: 204\n",
            "\t Sum of rewards 32.900000000000006\n",
            "Simulating episode 361\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.946957593924e-08\n",
            "0 1\n",
            "\t First 1 index: [ 26  43  44  54  58  69  94 115 128 140]\n",
            "\t Reached sample: 171\n",
            "\t Sum of rewards 24.3\n",
            "Simulating episode 362\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7996097142278e-08\n",
            "0 1\n",
            "\t First 1 index: [ 5 19 25 33 37 38 43 52 71 74]\n",
            "\t Reached sample: 122\n",
            "\t Sum of rewards 22.800000000000004\n",
            "Simulating episode 363\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  2   4  10  31  32  46  55  72  96 100]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -0.8\n",
            "Simulating episode 364\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5266477670905895e-08\n",
            "0 1\n",
            "\t First 1 index: [ 31  40  42  48  59  72  91 105 108 119]\n",
            "\t Reached sample: 106\n",
            "\t Sum of rewards 13.8\n",
            "Simulating episode 365\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.40031537873606e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.40031537873606e-08\n",
            "0 1\n",
            "\t First 1 index: [  0  39  52  63  94 104 109 117 119 129]\n",
            "\t Reached sample: 40\n",
            "\t Sum of rewards 3.4\n",
            "Simulating episode 366\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 13 16 18 22 56 65 67 68 73]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 367\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.166284629309294e-08\n",
            "0 1\n",
            "\t First 1 index: [ 2  7 13 14 18 27 35 44 55 61]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 2.1000000000000005\n",
            "Simulating episode 368\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.057970397843829e-08\n",
            "0 1\n",
            "\t First 1 index: [ 8 12 20 25 27 30 59 64 72 82]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 4.200000000000001\n",
            "Simulating episode 369\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9550718779516375e-08\n",
            "0 1\n",
            "\t First 1 index: [  2   9  19  25  31  46  47  78 107 118]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 5.500000000000001\n",
            "Simulating episode 370\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8573182840540554e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8573182840540554e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8573182840540554e-08\n",
            "0 1\n",
            "\t First 1 index: [28 31 34 38 51 58 64 65 67 68]\n",
            "\t Reached sample: 52\n",
            "\t Sum of rewards 7.1\n",
            "Simulating episode 371\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7644523698513526e-08\n",
            "0 1\n",
            "\t First 1 index: [ 15  53  59  67  68  73  98 107 108 113]\n",
            "\t Reached sample: 16\n",
            "\t Sum of rewards 0.30000000000000016\n",
            "Simulating episode 372\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  7   8  10  36  41  56  65  66  92 104]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards 1.8000000000000003\n",
            "Simulating episode 373\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5924182637908456e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5924182637908456e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5924182637908456e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5924182637908456e-08\n",
            "0 1\n",
            "\t First 1 index: [ 4 24 56 60 70 76 88 94 95 96]\n",
            "\t Reached sample: 71\n",
            "\t Sum of rewards 7.6\n",
            "Simulating episode 374\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5127973506013032e-08\n",
            "0 1\n",
            "\t First 1 index: [ 16  21  27  43  73  79  84  93 103 113]\n",
            "\t Reached sample: 186\n",
            "\t Sum of rewards 29.600000000000005\n",
            "Simulating episode 375\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.437157483071238e-08\n",
            "0 1\n",
            "\t First 1 index: [  7  57  87  90  95 104 108 111 121 125]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 376\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.365299608917676e-08\n",
            "0 1\n",
            "\t First 1 index: [  2  34  35  50  72  73  75  82  85 109]\n",
            "\t Reached sample: 35\n",
            "\t Sum of rewards 3.299999999999999\n",
            "Simulating episode 377\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2970346284717922e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2970346284717922e-08\n",
            "0 1\n",
            "\t First 1 index: [ 23  31  39  43  55  60  64  89  98 102]\n",
            "\t Reached sample: 40\n",
            "\t Sum of rewards 3.5000000000000004\n",
            "Simulating episode 378\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2321828970482025e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2321828970482025e-08\n",
            "0 1\n",
            "\t First 1 index: [  1  17  29  40  67  95 109 118 125 128]\n",
            "\t Reached sample: 41\n",
            "\t Sum of rewards 5.1000000000000005\n",
            "Simulating episode 379\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1705737521957923e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1705737521957923e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1705737521957923e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1705737521957923e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1705737521957923e-08\n",
            "0 1\n",
            "\t First 1 index: [  7   9  23  31  50  68  82  87  88 100]\n",
            "\t Reached sample: 89\n",
            "\t Sum of rewards 14.400000000000002\n",
            "Simulating episode 380\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1120450645860026e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1120450645860026e-08\n",
            "0 1\n",
            "\t First 1 index: [ 5 20 25 33 39 47 51 53 65 70]\n",
            "\t Reached sample: 34\n",
            "\t Sum of rewards 4.4\n",
            "Simulating episode 381\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0564428113567025e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0564428113567025e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0564428113567025e-08\n",
            "0 1\n",
            "\t First 1 index: [ 1  4 16 28 40 47 53 64 68 76]\n",
            "\t Reached sample: 77\n",
            "\t Sum of rewards 13.900000000000002\n",
            "Simulating episode 382\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0036206707888674e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0036206707888674e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0036206707888674e-08\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0036206707888674e-08\n",
            "0 1\n",
            "\t First 1 index: [ 8 11 31 45 46 48 68 77 78 79]\n",
            "\t Reached sample: 80\n",
            "\t Sum of rewards 13.600000000000003\n",
            "Simulating episode 383\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.53439637249424e-09\n",
            "0 1\n",
            "\t First 1 index: [13 26 33 41 52 54 55 56 57 63]\n",
            "\t Reached sample: 129\n",
            "\t Sum of rewards 23.200000000000003\n",
            "Simulating episode 384\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 6  9 20 25 28 37 54 58 59 63]\n",
            "\t Reached sample: 10\n",
            "\t Sum of rewards 0.8000000000000003\n",
            "Simulating episode 385\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.604792726176051e-09\n",
            "0 1\n",
            "\t First 1 index: [ 0 17 30 34 61 63 65 74 87 92]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 1.2000000000000002\n",
            "Simulating episode 386\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.174553089867248e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.174553089867248e-09\n",
            "0 1\n",
            "\t First 1 index: [ 6  7 30 37 41 45 47 48 54 55]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 3.599999999999998\n",
            "Simulating episode 387\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.765825435373885e-09\n",
            "0 1\n",
            "\t First 1 index: [ 11  22  33  36  85  86  88 102 132 147]\n",
            "\t Reached sample: 148\n",
            "\t Sum of rewards 19.0\n",
            "Simulating episode 388\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.37753416360519e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.37753416360519e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.37753416360519e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.37753416360519e-09\n",
            "0 1\n",
            "\t First 1 index: [ 10  13  19  23  31  57  60  73  75 111]\n",
            "\t Reached sample: 76\n",
            "\t Sum of rewards 11.3\n",
            "Simulating episode 389\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.00865745542493e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.00865745542493e-09\n",
            "0 1\n",
            "\t First 1 index: [ 9 10 28 36 45 46 53 63 68 96]\n",
            "\t Reached sample: 46\n",
            "\t Sum of rewards 6.1\n",
            "Simulating episode 390\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.658224582653683e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.658224582653683e-09\n",
            "0 1\n",
            "\t First 1 index: [  3  17  22  27  39  41  88 111 121 126]\n",
            "\t Reached sample: 42\n",
            "\t Sum of rewards 7.4\n",
            "Simulating episode 391\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.325313353520999e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.325313353520999e-09\n",
            "0 1\n",
            "\t First 1 index: [ 3 12 20 26 32 45 49 55 59 73]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 5.4\n",
            "Simulating episode 392\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.0090476858449484e-09\n",
            "0 1\n",
            "\t First 1 index: [ 8 12 15 23 28 33 35 64 76 77]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards -0.19999999999999996\n",
            "Simulating episode 393\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.708595301552701e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.708595301552701e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.708595301552701e-09\n",
            "0 1\n",
            "\t First 1 index: [ 7  9 22 32 37 41 54 56 62 68]\n",
            "\t Reached sample: 74\n",
            "\t Sum of rewards 15.600000000000001\n",
            "Simulating episode 394\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.423165536475066e-09\n",
            "0 1\n",
            "\t First 1 index: [ 4  5 21 33 52 53 55 66 69 80]\n",
            "\t Reached sample: 135\n",
            "\t Sum of rewards 23.9\n",
            "Simulating episode 395\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.152007259651312e-09\n",
            "0 1\n",
            "\t First 1 index: [  7  43  72  88  92 104 110 126 160 169]\n",
            "\t Reached sample: 237\n",
            "\t Sum of rewards 34.400000000000006\n",
            "Simulating episode 396\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.8944068966687465e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.8944068966687465e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.8944068966687465e-09\n",
            "0 1\n",
            "\t First 1 index: [17 18 19 41 43 45 59 67 72 89]\n",
            "\t Reached sample: 68\n",
            "\t Sum of rewards 10.8\n",
            "Simulating episode 397\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.649686551835309e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.649686551835309e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.649686551835309e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.649686551835309e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.649686551835309e-09\n",
            "0 1\n",
            "\t First 1 index: [ 17  27  29  52  81  85  86  93 108 117]\n",
            "\t Reached sample: 86\n",
            "\t Sum of rewards 10.4\n",
            "Simulating episode 398\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.417202224243544e-09\n",
            "0 1\n",
            "\t First 1 index: [ 28  48  60  74  84  86 134 135 156 164]\n",
            "\t Reached sample: 174\n",
            "\t Sum of rewards 23.1\n",
            "Simulating episode 399\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1 13 27 32 52 58 65 73 75 77]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 400\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.986525007379797e-09\n",
            "0 1\n",
            "\t First 1 index: [ 0 27 28 45 46 64 84 85 88 89]\n",
            "\t Reached sample: 120\n",
            "\t Sum of rewards 22.200000000000003\n",
            "Simulating episode 401\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.787198757010807e-09\n",
            "\t First 1 index: [ 2 15 21 28 29 30 33 38 40 58]\n",
            "\t Reached sample: 3\n",
            "\t Sum of rewards -1.0\n",
            "Simulating episode 402\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  8  17  18  48  65  66  91  95 101 117]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 1.6\n",
            "Simulating episode 403\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.417946878202253e-09\n",
            "0 1\n",
            "\t First 1 index: [ 8 25 29 51 55 56 70 87 90 92]\n",
            "\t Reached sample: 141\n",
            "\t Sum of rewards 22.500000000000004\n",
            "Simulating episode 404\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.24704953429214e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.24704953429214e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.24704953429214e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.24704953429214e-09\n",
            "0 1\n",
            "\t First 1 index: [ 24  42  62  63  65  81  86  92 100 113]\n",
            "\t Reached sample: 66\n",
            "\t Sum of rewards 7.9\n",
            "Simulating episode 405\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.084697057577533e-09\n",
            "0 1\n",
            "\t First 1 index: [  3  47  51  52  54  56  63  82 116 128]\n",
            "\t Reached sample: 117\n",
            "\t Sum of rewards 17.00000000000001\n",
            "Simulating episode 406\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.930462204698656e-09\n",
            "0 1\n",
            "\t First 1 index: [  1  15  33  45  96 102 113 121 136 153]\n",
            "\t Reached sample: 439\n",
            "\t Sum of rewards 69.00000000000001\n",
            "Simulating episode 407\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [11 30 32 39 58 74 75 79 83 86]\n",
            "\t Reached sample: 12\n",
            "\t Sum of rewards 0.10000000000000009\n",
            "Simulating episode 408\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6447421397405367e-09\n",
            "0 1\n",
            "\t First 1 index: [ 4  9 18 22 52 53 68 81 83 89]\n",
            "\t Reached sample: 23\n",
            "\t Sum of rewards 3.5\n",
            "Simulating episode 409\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5125050327535098e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5125050327535098e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5125050327535098e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.5125050327535098e-09\n",
            "0 1\n",
            "\t First 1 index: [ 8 49 62 64 65 74 78 83 84 99]\n",
            "\t Reached sample: 75\n",
            "\t Sum of rewards 9.100000000000001\n",
            "Simulating episode 410\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.386879781115834e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.386879781115834e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.386879781115834e-09\n",
            "0 1\n",
            "\t First 1 index: [  4   7  58  59 117 121 136 137 152 161]\n",
            "\t Reached sample: 59\n",
            "\t Sum of rewards 6.000000000000001\n",
            "Simulating episode 411\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2675357920600423e-09\n",
            "0 1\n",
            "\t First 1 index: [ 31  41  60  71  96 110 121 128 143 161]\n",
            "\t Reached sample: 195\n",
            "\t Sum of rewards 31.6\n",
            "Simulating episode 412\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.15415900245704e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.15415900245704e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.15415900245704e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.15415900245704e-09\n",
            "0 1\n",
            "\t First 1 index: [  2   5   7  19  33  37  82  97 111 116]\n",
            "\t Reached sample: 83\n",
            "\t Sum of rewards 12.000000000000004\n",
            "Simulating episode 413\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.046451052334188e-09\n",
            "0 1\n",
            "\t First 1 index: [ 15  23  29  38  66 102 103 106 111 121]\n",
            "\t Reached sample: 197\n",
            "\t Sum of rewards 37.900000000000006\n",
            "Simulating episode 414\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9441284997174785e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9441284997174785e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9441284997174785e-09\n",
            "0 1\n",
            "\t First 1 index: [  5  15  20  39  56  71  96  97 103 127]\n",
            "\t Reached sample: 57\n",
            "\t Sum of rewards 7.600000000000001\n",
            "Simulating episode 415\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8469220747316044e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.8469220747316044e-09\n",
            "0 1\n",
            "\t First 1 index: [ 0  2 13 17 22 25 32 41 54 79]\n",
            "\t Reached sample: 55\n",
            "\t Sum of rewards 11.0\n",
            "Simulating episode 416\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.754575970995024e-09\n",
            "0 1\n",
            "\t First 1 index: [ 1 19 22 28 40 51 53 58 74 84]\n",
            "\t Reached sample: 113\n",
            "\t Sum of rewards 20.600000000000005\n",
            "Simulating episode 417\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6668471724452728e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6668471724452728e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6668471724452728e-09\n",
            "0 1\n",
            "\t First 1 index: [ 0  2 31 34 36 39 59 70 72 73]\n",
            "\t Reached sample: 60\n",
            "\t Sum of rewards 9.9\n",
            "Simulating episode 418\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.583504813823009e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.583504813823009e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.583504813823009e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.583504813823009e-09\n",
            "0 1\n",
            "\t First 1 index: [  2  30  31  43  63  74  76  93  95 109]\n",
            "\t Reached sample: 77\n",
            "\t Sum of rewards 10.800000000000002\n",
            "Simulating episode 419\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5043295731318585e-09\n",
            "0 1\n",
            "\t First 1 index: [ 5  7 11 27 31 47 56 58 61 97]\n",
            "\t Reached sample: 32\n",
            "\t Sum of rewards 5.1000000000000005\n",
            "Simulating episode 420\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.4291130944752654e-09\n",
            "0 1\n",
            "\t First 1 index: [  2   3   8  16  53 106 110 117 122 123]\n",
            "\t Reached sample: 9\n",
            "\t Sum of rewards 1.6\n",
            "Simulating episode 421\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3576574397515021e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3576574397515021e-09\n",
            "0 1\n",
            "\t First 1 index: [ 1 12 15 26 33 35 44 87 95 96]\n",
            "\t Reached sample: 34\n",
            "\t Sum of rewards 5.9\n",
            "Simulating episode 422\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.289774567763927e-09\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.289774567763927e-09\n",
            "\t First 1 index: [ 6 25 26 30 34 37 47 53 57 83]\n",
            "\t Reached sample: 38\n",
            "\t Sum of rewards 6.399999999999999\n",
            "Simulating episode 423\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2252858393757306e-09\n",
            "0 1\n",
            "\t First 1 index: [ 6 27 28 29 34 42 43 47 49 60]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 4.4\n",
            "Simulating episode 424\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.164021547406944e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.164021547406944e-09\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.164021547406944e-09\n",
            "\t First 1 index: [ 6 20 30 39 41 42 45 49 57 60]\n",
            "\t Reached sample: 50\n",
            "\t Sum of rewards 10.0\n",
            "Simulating episode 425\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.1058204700365968e-09\n",
            "0 1\n",
            "\t First 1 index: [50 51 53 54 56 61 68 70 72 73]\n",
            "\t Reached sample: 142\n",
            "\t Sum of rewards 25.200000000000003\n",
            "Simulating episode 426\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0505294465347668e-09\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0505294465347668e-09\n",
            "0 1\n",
            "\t First 1 index: [  4   9  13  23  52  55  61  97 109 118]\n",
            "\t Reached sample: 56\n",
            "\t Sum of rewards 8.600000000000001\n",
            "Simulating episode 427\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.980029742080285e-10\n",
            "0 1\n",
            "\t First 1 index: [  2  25  36  45  49  50  78  92 109 116]\n",
            "\t Reached sample: 117\n",
            "\t Sum of rewards 17.90000000000001\n",
            "Simulating episode 428\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.48102825497627e-10\n",
            "0 1\n",
            "\t First 1 index: [ 0 16 29 44 45 55 62 64 70 97]\n",
            "\t Reached sample: 194\n",
            "\t Sum of rewards 38.500000000000014\n",
            "Simulating episode 429\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.006976842227457e-10\n",
            "0 1\n",
            "\t First 1 index: [ 5  6  8 14 15 16 17 18 29 35]\n",
            "\t Reached sample: 112\n",
            "\t Sum of rewards 23.600000000000005\n",
            "Simulating episode 430\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.556628000116083e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.556628000116083e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.556628000116083e-10\n",
            "0 1\n",
            "\t First 1 index: [ 33  42  54  63  70  74  98 102 106 107]\n",
            "\t Reached sample: 75\n",
            "\t Sum of rewards 10.1\n",
            "Simulating episode 431\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.128796600110279e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.128796600110279e-10\n",
            "0 1\n",
            "\t First 1 index: [ 6 22 25 26 27 46 54 59 68 77]\n",
            "\t Reached sample: 28\n",
            "\t Sum of rewards 5.1\n",
            "Simulating episode 432\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.722356770104764e-10\n",
            "0 1\n",
            "\t First 1 index: [ 3 18 28 40 41 83 84 87 88 89]\n",
            "\t Reached sample: 19\n",
            "\t Sum of rewards 1.7000000000000002\n",
            "Simulating episode 433\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.336238931599525e-10\n",
            "0 1\n",
            "\t First 1 index: [ 11  15  17  38  49  50  60  63 103 105]\n",
            "\t Reached sample: 18\n",
            "\t Sum of rewards 2.1\n",
            "Simulating episode 434\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 5 14 38 42 67 71 72 77 78 80]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.7\n",
            "Simulating episode 435\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.620955635768571e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.620955635768571e-10\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.620955635768571e-10\n",
            "\t First 1 index: [16 20 23 31 44 52 55 62 63 76]\n",
            "\t Reached sample: 53\n",
            "\t Sum of rewards 7.900000000000002\n",
            "Simulating episode 436\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 12  16  23  25  28  49  85  91 100 101]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards 0.20000000000000018\n",
            "Simulating episode 437\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.975412461281134e-10\n",
            "0 1\n",
            "\t First 1 index: [ 9 10 14 17 20 22 33 35 61 62]\n",
            "\t Reached sample: 21\n",
            "\t Sum of rewards 4.399999999999999\n",
            "Simulating episode 438\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.676641838217077e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.676641838217077e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.676641838217077e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.676641838217077e-10\n",
            "0 1\n",
            "\t First 1 index: [ 0  7 20 44 45 48 53 64 70 74]\n",
            "\t Reached sample: 83\n",
            "\t Sum of rewards 16.900000000000006\n",
            "Simulating episode 439\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.392809746306223e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.392809746306223e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.392809746306223e-10\n",
            "0 1\n",
            "\t First 1 index: [  3   5  30  49  58  73  82  95 103 105]\n",
            "\t Reached sample: 50\n",
            "\t Sum of rewards 6.200000000000001\n",
            "Simulating episode 440\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.123169258990911e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.123169258990911e-10\n",
            "0 1\n",
            "\t First 1 index: [ 0  2  6 24 26 37 44 74 76 86]\n",
            "\t Reached sample: 38\n",
            "\t Sum of rewards 7.199999999999999\n",
            "Simulating episode 441\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.867010796041365e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.867010796041365e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.867010796041365e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.867010796041365e-10\n",
            "0 1\n",
            "\t First 1 index: [ 1  6 20 26 28 29 40 53 55 61]\n",
            "\t Reached sample: 79\n",
            "\t Sum of rewards 15.70000000000001\n",
            "Simulating episode 442\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.6236602562392967e-10\n",
            "0 1\n",
            "\t First 1 index: [15 21 30 35 54 55 59 60 81 87]\n",
            "\t Reached sample: 22\n",
            "\t Sum of rewards 1.8000000000000007\n",
            "Simulating episode 443\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  0  10  15  42  55  56  64  88  90 101]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards 0.7000000000000002\n",
            "Simulating episode 444\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.1728533812559647e-10\n",
            "0 1\n",
            "\t First 1 index: [  7  21  22  34  40  66  86 104 106 114]\n",
            "\t Reached sample: 279\n",
            "\t Sum of rewards 40.7\n",
            "Simulating episode 445\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.964210712193166e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.964210712193166e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.964210712193166e-10\n",
            "0 1\n",
            "\t First 1 index: [  0   5  51  52  54  89  90 100 102 103]\n",
            "\t Reached sample: 52\n",
            "\t Sum of rewards 5.3\n",
            "Simulating episode 446\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7660001765835075e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7660001765835075e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7660001765835075e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7660001765835075e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7660001765835075e-10\n",
            "0 1\n",
            "\t First 1 index: [ 22  60  61  62  65  69  79  83  96 103]\n",
            "\t Reached sample: 109\n",
            "\t Sum of rewards 18.100000000000005\n",
            "Simulating episode 447\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.577700167754332e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.577700167754332e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.577700167754332e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.577700167754332e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.577700167754332e-10\n",
            "0 1\n",
            "\t First 1 index: [13 23 27 29 35 55 60 62 67 78]\n",
            "\t Reached sample: 89\n",
            "\t Sum of rewards 17.700000000000003\n",
            "Simulating episode 448\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.3988151593666153e-10\n",
            "\t First 1 index: [ 0  3  6 13 17 21 23 25 32 36]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 2.8000000000000007\n",
            "Simulating episode 449\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  9  10  13  25  42  55  59  64  73 107]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards 0.8999999999999999\n",
            "Simulating episode 450\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.06743068132837e-10\n",
            "0 1\n",
            "\t First 1 index: [ 14  17  34  45  61  67  76  92 120 121]\n",
            "\t Reached sample: 121\n",
            "\t Sum of rewards 16.000000000000004\n",
            "Simulating episode 451\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.9140591472619513e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.9140591472619513e-10\n",
            "0 1\n",
            "\t First 1 index: [ 7 17 20 30 38 59 67 89 98 99]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 4.6999999999999975\n",
            "Simulating episode 452\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7683561898988537e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7683561898988537e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7683561898988537e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7683561898988537e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.7683561898988537e-10\n",
            "0 1\n",
            "\t First 1 index: [ 10  34  79  81  98 101 109 122 123 125]\n",
            "\t Reached sample: 102\n",
            "\t Sum of rewards 13.0\n",
            "Simulating episode 453\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6299383804039107e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6299383804039107e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6299383804039107e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6299383804039107e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6299383804039107e-10\n",
            "0 1\n",
            "\t First 1 index: [ 2  7 12 31 33 53 61 62 64 86]\n",
            "\t Reached sample: 107\n",
            "\t Sum of rewards 19.800000000000004\n",
            "Simulating episode 454\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.498441461383715e-10\n",
            "0 1\n",
            "\t First 1 index: [21 29 38 43 59 64 66 82 93 99]\n",
            "\t Reached sample: 22\n",
            "\t Sum of rewards 1.1000000000000005\n",
            "Simulating episode 455\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.373519388314529e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.373519388314529e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.373519388314529e-10\n",
            "0 1\n",
            "\t First 1 index: [23 37 38 42 45 50 64 94 95 99]\n",
            "\t Reached sample: 65\n",
            "\t Sum of rewards 10.2\n",
            "Simulating episode 456\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2548434188988023e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.2548434188988023e-10\n",
            "0 1\n",
            "\t First 1 index: [  5  21  32  44  65  75  87  92  94 101]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 3.8000000000000007\n",
            "Simulating episode 457\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1  4  8 30 40 43 49 55 67 70]\n",
            "\t Reached sample: 5\n",
            "\t Sum of rewards 0.30000000000000027\n",
            "Simulating episode 458\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.034996185556169e-10\n",
            "0 1\n",
            "\t First 1 index: [  4   7  10  13  41  43  48  70 108 115]\n",
            "\t Reached sample: 8\n",
            "\t Sum of rewards 0.6000000000000001\n",
            "Simulating episode 459\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9332463762783605e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9332463762783605e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.9332463762783605e-10\n",
            "0 1\n",
            "\t First 1 index: [ 12  13  23  38  55  83 114 115 116 121]\n",
            "\t Reached sample: 56\n",
            "\t Sum of rewards 7.500000000000002\n",
            "Simulating episode 460\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 1 10 12 13 19 25 33 36 48 49]\n",
            "\t Reached sample: 14\n",
            "\t Sum of rewards 3.0\n",
            "Simulating episode 461\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.7447548545912202e-10\n",
            "0 1\n",
            "\t First 1 index: [ 25  34  35  38  46  52  91  92  98 109]\n",
            "\t Reached sample: 173\n",
            "\t Sum of rewards 27.000000000000007\n",
            "Simulating episode 462\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6575171118616592e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.6575171118616592e-10\n",
            "0 1\n",
            "\t First 1 index: [  3  15  22  33  35  57  60  61  98 115]\n",
            "\t Reached sample: 36\n",
            "\t Sum of rewards 6.1\n",
            "Simulating episode 463\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5746412562685762e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5746412562685762e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5746412562685762e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5746412562685762e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.5746412562685762e-10\n",
            "0 1\n",
            "\t First 1 index: [ 5  6 13 14 22 26 30 34 36 39]\n",
            "\t Reached sample: 109\n",
            "\t Sum of rewards 25.700000000000003\n",
            "Simulating episode 464\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  1   4   5   6  36  37  48  77  90 127]\n",
            "\t Reached sample: 2\n",
            "\t Sum of rewards -0.9\n",
            "Simulating episode 465\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.4211137337823898e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.4211137337823898e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.4211137337823898e-10\n",
            "0 1\n",
            "\t First 1 index: [11 12 13 28 42 48 51 57 61 62]\n",
            "\t Reached sample: 49\n",
            "\t Sum of rewards 7.700000000000001\n",
            "Simulating episode 466\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3500580470932704e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.3500580470932704e-10\n",
            "0 1\n",
            "\t First 1 index: [14 29 45 52 61 67 83 89 97 98]\n",
            "\t Reached sample: 46\n",
            "\t Sum of rewards 4.699999999999998\n",
            "Simulating episode 467\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.282555144738607e-10\n",
            "\t First 1 index: [ 10  12  26  41  51  68  75  85 107 110]\n",
            "\t Reached sample: 210\n",
            "\t Sum of rewards 35.00000000000001\n",
            "Simulating episode 468\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.2184273875016765e-10\n",
            "0 1\n",
            "\t First 1 index: [ 43  63  64  74 104 109 123 124 132 148]\n",
            "\t Reached sample: 125\n",
            "\t Sum of rewards 16.700000000000003\n",
            "Simulating episode 469\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [  1   9  12  27  67  83  86  99 104 133]\n",
            "\t Reached sample: 13\n",
            "\t Sum of rewards 2.0000000000000004\n",
            "Simulating episode 470\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0996307172202628e-10\n",
            "0 1\n",
            "\t First 1 index: [ 21  33  53  60  72  85 101 106 115 124]\n",
            "\t Reached sample: 192\n",
            "\t Sum of rewards 29.200000000000006\n",
            "Simulating episode 471\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0446491813592496e-10\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 1.0446491813592496e-10\n",
            "0 1\n",
            "\t First 1 index: [13 27 28 35 40 61 80 87 88 91]\n",
            "\t Reached sample: 36\n",
            "\t Sum of rewards 5.0\n",
            "Simulating episode 472\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.92416722291287e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.92416722291287e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.92416722291287e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.92416722291287e-11\n",
            "0 1\n",
            "\t First 1 index: [38 42 44 63 78 79 80 84 93 95]\n",
            "\t Reached sample: 80\n",
            "\t Sum of rewards 11.0\n",
            "Simulating episode 473\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.427958861767226e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.427958861767226e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.427958861767226e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 9.427958861767226e-11\n",
            "0 1\n",
            "\t First 1 index: [  9  51  85  87  97  98 106 114 138 140]\n",
            "\t Reached sample: 86\n",
            "\t Sum of rewards 8.7\n",
            "Simulating episode 474\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.956560918678864e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.956560918678864e-11\n",
            "0 1\n",
            "\t First 1 index: [ 4  9 26 31 32 33 34 39 44 49]\n",
            "\t Reached sample: 45\n",
            "\t Sum of rewards 10.399999999999999\n",
            "Simulating episode 475\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.50873287274492e-11\n",
            "0 1\n",
            "\t First 1 index: [  7  25  29  57  77  89 101 123 136 150]\n",
            "\t Reached sample: 452\n",
            "\t Sum of rewards 85.4\n",
            "Simulating episode 476\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 8.083296229107674e-11\n",
            "0 1\n",
            "\t First 1 index: [25 54 70 71 74 78 83 86 89 90]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 1.3000000000000003\n",
            "Simulating episode 477\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.67913141765229e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.67913141765229e-11\n",
            "0 1\n",
            "\t First 1 index: [  8  25  27  30  31  53  64  65  67 122]\n",
            "\t Reached sample: 28\n",
            "\t Sum of rewards 3.5\n",
            "Simulating episode 478\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 7.295174846769675e-11\n",
            "0 1\n",
            "\t First 1 index: [  5  15  30  36  43  57  69  89  94 110]\n",
            "\t Reached sample: 31\n",
            "\t Sum of rewards 3.599999999999998\n",
            "Simulating episode 479\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.930416104431191e-11\n",
            "\t First 1 index: [ 5  6 13 18 21 23 28 49 56 57]\n",
            "\t Reached sample: 6\n",
            "\t Sum of rewards -0.5\n",
            "Simulating episode 480\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.583895299209631e-11\n",
            "0 1\n",
            "\t First 1 index: [ 24  29  30  41  49  75  77  93 124 135]\n",
            "\t Reached sample: 30\n",
            "\t Sum of rewards 2.8000000000000007\n",
            "Simulating episode 481\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 6.25470053424915e-11\n",
            "0 1\n",
            "\t First 1 index: [  7  20  33  46  48  57  61  72  92 114]\n",
            "\t Reached sample: 317\n",
            "\t Sum of rewards 57.40000000000002\n",
            "Simulating episode 482\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.941965507536692e-11\n",
            "0 1\n",
            "\t First 1 index: [ 3  6  8 14 25 38 39 53 90 94]\n",
            "\t Reached sample: 26\n",
            "\t Sum of rewards 4.9\n",
            "Simulating episode 483\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.6448672321598573e-11\n",
            "0 1\n",
            "\t First 1 index: [  4  10  13  22  63  81 106 114 146 153]\n",
            "\t Reached sample: 217\n",
            "\t Sum of rewards 37.5\n",
            "Simulating episode 484\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.362623870551864e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.362623870551864e-11\n",
            "0 1\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.362623870551864e-11\n",
            "\t First 1 index: [14 43 49 51 54 60 62 81 82 87]\n",
            "\t Reached sample: 50\n",
            "\t Sum of rewards 5.1\n",
            "Simulating episode 485\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 5.094492677024271e-11\n",
            "0 1\n",
            "\t First 1 index: [ 19  21  25  48  54  83  87 103 137 141]\n",
            "\t Reached sample: 235\n",
            "\t Sum of rewards 35.30000000000001\n",
            "Simulating episode 486\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.839768043173057e-11\n",
            "0 1\n",
            "\t First 1 index: [ 11  12  23  31  38  41  56  69  81 118]\n",
            "\t Reached sample: 119\n",
            "\t Sum of rewards 18.30000000000001\n",
            "Simulating episode 487\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.597779641014404e-11\n",
            "0 1\n",
            "\t First 1 index: [  0   3  11  20  27  34  76  93 126 127]\n",
            "\t Reached sample: 156\n",
            "\t Sum of rewards 25.0\n",
            "Simulating episode 488\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.3678906589636836e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.3678906589636836e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.3678906589636836e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.3678906589636836e-11\n",
            "0 1\n",
            "\t First 1 index: [ 4 21 26 27 30 32 34 35 46 53]\n",
            "\t Reached sample: 80\n",
            "\t Sum of rewards 19.300000000000004\n",
            "Simulating episode 489\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.149496126015499e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.149496126015499e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.149496126015499e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 4.149496126015499e-11\n",
            "0 1\n",
            "\t First 1 index: [ 14  30  70  79  80  97  98 104 107 108]\n",
            "\t Reached sample: 71\n",
            "\t Sum of rewards 6.999999999999998\n",
            "Simulating episode 490\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.942021319714724e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.942021319714724e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.942021319714724e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.942021319714724e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.942021319714724e-11\n",
            "0 1\n",
            "\t First 1 index: [ 9 12 13 23 31 41 42 45 46 73]\n",
            "\t Reached sample: 116\n",
            "\t Sum of rewards 26.300000000000008\n",
            "Simulating episode 491\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7449202537289876e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7449202537289876e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7449202537289876e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7449202537289876e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.7449202537289876e-11\n",
            "0 1\n",
            "\t First 1 index: [ 1 14 20 32 50 65 79 88 95 99]\n",
            "\t Reached sample: 89\n",
            "\t Sum of rewards 13.700000000000003\n",
            "Simulating episode 492\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.557674241042538e-11\n",
            "0 1\n",
            "\t First 1 index: [ 14  32  48  50  55  67  93  94  95 109]\n",
            "\t Reached sample: 128\n",
            "\t Sum of rewards 22.600000000000005\n",
            "Simulating episode 493\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.379790528990411e-11\n",
            "0 1\n",
            "\t First 1 index: [ 3  7  8 14 38 41 43 56 61 65]\n",
            "\t Reached sample: 15\n",
            "\t Sum of rewards 2.9000000000000004\n",
            "Simulating episode 494\n",
            "0 1\n",
            "\t First train of main network...\n",
            "\t First 1 index: [ 0  7 20 30 35 41 45 46 51 66]\n",
            "\t Reached sample: 1\n",
            "\t Sum of rewards -1\n",
            "Simulating episode 495\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 3.050260952413846e-11\n",
            "0 1\n",
            "\t First 1 index: [ 2  5 16 31 36 39 60 64 68 80]\n",
            "\t Reached sample: 119\n",
            "\t Sum of rewards 22.80000000000001\n",
            "Simulating episode 496\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.897747904793153e-11\n",
            "0 1\n",
            "\t First 1 index: [  1  10  16  32  45  50  52  54  78 101]\n",
            "\t Reached sample: 353\n",
            "\t Sum of rewards 68.30000000000001\n",
            "Simulating episode 497\n",
            "\t First train of main network...\n",
            "0 1\n",
            "\t First 1 index: [ 9 10 21 28 40 50 56 64 68 72]\n",
            "\t Reached sample: 11\n",
            "\t Sum of rewards 0.7000000000000002\n",
            "Simulating episode 498\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6152174840758203e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.6152174840758203e-11\n",
            "0 1\n",
            "\t First 1 index: [  2   8  19  32  87  89  90  94 123 132]\n",
            "\t Reached sample: 33\n",
            "\t Sum of rewards 4.9\n",
            "Simulating episode 499\n",
            "\t First train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.484456609872029e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.484456609872029e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.484456609872029e-11\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 2.484456609872029e-11\n",
            "0 1\n",
            "\t First 1 index: [ 13  30  42  54  58  80  86 104 112 113]\n",
            "\t Reached sample: 81\n",
            "\t Sum of rewards 11.3\n",
            "Wall time: 1h 7min 10s\n"
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "LearningQDeep.trainingEpisodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = LearningQDeep.mainNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_train,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 157,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[2957   76]\n",
            " [  33  309]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(confusion_matrix(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.97      0.98      3033\n",
            "           1       0.80      0.90      0.85       342\n",
            "\n",
            "    accuracy                           0.97      3375\n",
            "   macro avg       0.90      0.94      0.92      3375\n",
            "weighted avg       0.97      0.97      0.97      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_test,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6361  682]\n",
            " [ 272  560]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93      7043\n",
            "           1       0.45      0.67      0.54       832\n",
            "\n",
            "    accuracy                           0.88      7875\n",
            "   macro avg       0.70      0.79      0.74      7875\n",
            "weighted avg       0.91      0.88      0.89      7875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 162,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_validate,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 163,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3009  364]\n",
            " [ 112  265]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 164,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.89      0.93      3373\n",
            "           1       0.42      0.70      0.53       377\n",
            "\n",
            "    accuracy                           0.87      3750\n",
            "   macro avg       0.69      0.80      0.73      3750\n",
            "weighted avg       0.91      0.87      0.89      3750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_validate,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "LearningQDeep.mainNetwork.save('Trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "e4b0dc3f566f05bc103e1f1b3ab48badc3f605c5ba46d00ca4d445c3c8a098ce"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
