{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFz_NRKrx_hl"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification, make_multilabel_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from collections import deque \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "import plotly.express as px"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Gy5DCfcRyGOI"
      },
      "outputs": [],
      "source": [
        "X,y = make_classification(15_000,500,random_state=50,n_classes=2, weights=[0.95])\n",
        "X, X_validate, y, y_validate = train_test_split(X,y, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size =  0.7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_train_ = X_train.copy()\n",
        "# y_train_ = y_train.copy()\n",
        "# rng_idx = pd.Series(y_train).sample(len(y_train)).index\n",
        "# X_train_ = X_train_[rng_idx]\n",
        "# y_train_ = y_train_[rng_idx]\n",
        "# M_idx, m_idx = pd.DataFrame(y_train_).groupby(0).apply(lambda x: x.index.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pd.Series(y_train).value_counts()   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bal_idx = pd.DataFrame(y_train, columns = ['y']).groupby('y').apply(lambda x: x.sample(250)).index.to_frame()[1].values\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rng = np.random.default_rng(1235)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# rng.shuffle(bal_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_bal = X_train[bal_idx]\n",
        "# y_bal = y_train[bal_idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# X_bal = X_train.copy()\n",
        "# y_bal = y_train.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# M_idx, m_idx = pd.DataFrame(y_bal).groupby(0).apply(lambda x: x.index.values)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " actions = {0 : 0, 1 : 1}\n",
        " len(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "lC5LkJ-6zCIF"
      },
      "outputs": [],
      "source": [
        "%run -i ./DQN_Class.py\n",
        "gamma=0.5\n",
        "epsilon=.8\n",
        "numberEpisodes= 120\n",
        "LearningQDeep=DeepQLearning(gamma,epsilon,numberEpisodes)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# NN approach"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "nn = LearningQDeep.buildNetwork()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_120 (Dense)           (None, 30)                15030     \n",
            "                                                                 \n",
            " dense_121 (Dense)           (None, 64)                1984      \n",
            "                                                                 \n",
            " dense_122 (Dense)           (None, 20)                1300      \n",
            "                                                                 \n",
            " dense_123 (Dense)           (None, 1)                 21        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 18,335\n",
            "Trainable params: 18,335\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "                                monitor='val_f1', \n",
        "                                verbose=1,\n",
        "                                patience=100,\n",
        "                                mode='max',\n",
        "                                restore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(3375,)\n",
            "(3375,)\n",
            "[0.104454264 0.0466095544 0.161626264 ... 0.113156877 0.217940584 0.0561327226]\n",
            "1/1 [==============================] - ETA: 0s - loss: 0.1834 - recall_m: 0.0772 - precision_m: 0.0897 - f1: 0.0829WARNING:tensorflow:Early stopping conditioned on metric `val_f1` which is not available. Available metrics are: loss,recall_m,precision_m,f1\n",
            "1/1 [==============================] - 1s 899ms/step - loss: 0.1834 - recall_m: 0.0772 - precision_m: 0.0897 - f1: 0.0829\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1b21fbcb790>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.fit(X_train,y_train, epochs=1, callbacks = [early_stopping], batch_size=X_train.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(1)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([y_train[0]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0])"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array(y_train[0:2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0.476387918 0.145877674 0.244506896]\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.2889 - recall_m: 0.0000e+00 - precision_m: 0.0000e+00 - f1: 0.0000e+00\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.2889241576194763, 0.0, 0.0, 0.0]"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.evaluate(X_train[0:3,:],np.array(y_train[0:3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.28892416266666665"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "np.array([0.476387918, 0.145877674, 0.244506896]).sum()/3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.14587770527236"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "(0.3819394)**2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.3819394]], dtype=float32)"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nn.predict(X_train[1,:].reshape(1,-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 0, 0, ..., 0, 0, 0])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 272,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "106/106 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_train)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 273,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3056    0]\n",
            " [   0  319]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 274,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3056\n",
            "           1       1.00      1.00      1.00       319\n",
            "\n",
            "    accuracy                           1.00      3375\n",
            "   macro avg       1.00      1.00      1.00      3375\n",
            "weighted avg       1.00      1.00      1.00      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 275,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "247/247 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_test)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 276,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6795  225]\n",
            " [ 438  417]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 277,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      7020\n",
            "           1       0.65      0.49      0.56       855\n",
            "\n",
            "    accuracy                           0.92      7875\n",
            "   macro avg       0.79      0.73      0.76      7875\n",
            "weighted avg       0.91      0.92      0.91      7875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 278,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "118/118 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "y_pred = [1 if x>0.5 else 0 for x in nn.predict(X_validate)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 279,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3255  118]\n",
            " [ 191  186]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.95      3373\n",
            "           1       0.61      0.49      0.55       377\n",
            "\n",
            "    accuracy                           0.92      3750\n",
            "   macro avg       0.78      0.73      0.75      3750\n",
            "weighted avg       0.91      0.92      0.91      3750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " actions = {0 : 0, 1 : 1}\n",
        " len(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def reward(si, a, M, m, y):\n",
        "    l = y[si]\n",
        "\n",
        "    if (a == l) & (si in m):\n",
        "        r = 1\n",
        "    elif  (a != l) & (si in m):\n",
        "        r = -1\n",
        "    if (a == l) & (si in M):\n",
        "        r = 0.04\n",
        "    elif  (a != l) & (si in M):\n",
        "        r = -0.04\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def step(action, i, M, m, X, y):\n",
        "    l = y[i]\n",
        "\n",
        "    r = reward(i,action, M, m, y)\n",
        "\n",
        "    if i == len(y) - 1:\n",
        "        terminated = True\n",
        "        return r, None, terminated, i+1\n",
        "\n",
        "    nextState = X[i+1,:]\n",
        "\n",
        "    if (action != l) & (i in m):\n",
        "        # print(action, l)\n",
        "        terminated = True\n",
        "        return r, nextState, terminated, i+1\n",
        "\n",
        "    terminated = False\n",
        "    \n",
        "    return r, nextState, terminated, i+1\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "lC5LkJ-6zCIF"
      },
      "outputs": [],
      "source": [
        "%run -i ./DQN_Class.py\n",
        "gamma=0.25\n",
        "epsilon=.9\n",
        "numberEpisodes= 500\n",
        "LearningQDeep=DeepQLearning(gamma,epsilon,numberEpisodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "3.4125435562551007e-09"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.96**(500-25)*(0.9)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_20 (Dense)            (None, 500)               250500    \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 500)               250500    \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 2)                 1002      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 502,002\n",
            "Trainable params: 502,002\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "LearningQDeep.mainNetwork.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kuOS04kzRP2",
        "outputId": "05ad7a66-a3b7-4a44-c1b5-8e675fc2273b"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[1;32m<timed eval>:1\u001b[0m\n",
            "File \u001b[1;32m~\\DQN\\DQN\\DQL_Classification\\DQN_Class.py:174\u001b[0m, in \u001b[0;36mDeepQLearning.trainingEpisodes\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreplayBuffer\u001b[39m.\u001b[39mappend((currentState,action,reward,nextState,terminated))\n\u001b[0;32m    173\u001b[0m     \u001b[39m# printt(len(self.replayBuffer))\u001b[39;00m\n\u001b[1;32m--> 174\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainNetwork()\n\u001b[0;32m    175\u001b[0m     currentState\u001b[39m=\u001b[39mnextState\n\u001b[0;32m    177\u001b[0m printt(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m First 1 index: \u001b[39m\u001b[39m{\u001b[39;00mm_idx[:\u001b[39m10\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
            "File \u001b[1;32m~\\DQN\\DQN\\DQL_Classification\\DQN_Class.py:225\u001b[0m, in \u001b[0;36mDeepQLearning.trainNetwork\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    222\u001b[0m     nextStateBatch[index,:]\u001b[39m=\u001b[39mtupleS[\u001b[39m3\u001b[39m]\n\u001b[0;32m    224\u001b[0m QnextStateTargetNetwork\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargetNetwork\u001b[39m.\u001b[39mpredict(nextStateBatch, verbose\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m--> 225\u001b[0m QcurrentStateMainNetwork\u001b[39m=\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmainNetwork\u001b[39m.\u001b[39;49mpredict(currentStateBatch, verbose \u001b[39m=\u001b[39;49m \u001b[39m0\u001b[39;49m)\n\u001b[0;32m    227\u001b[0m inputNetwork\u001b[39m=\u001b[39mcurrentStateBatch\n\u001b[0;32m    228\u001b[0m outputNetwork\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mzeros(shape\u001b[39m=\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatchReplayBufferSize,\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mactionDimension))\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\training.py:1758\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1750\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   1751\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1752\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mUsing Model.predict with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1753\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1754\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1755\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1756\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> 1758\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   1759\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   1760\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1761\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   1762\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   1763\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1764\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1765\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1766\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1767\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1768\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   1770\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:1403\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1402\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1403\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:1153\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1150\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1152\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1154\u001b[0m     x,\n\u001b[0;32m   1155\u001b[0m     y,\n\u001b[0;32m   1156\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1157\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1158\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1159\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1160\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1161\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1162\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1163\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1164\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1165\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m   1167\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:325\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m     flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    323\u001b[0m   \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 325\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    327\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2048\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2015\u001b[0m   \u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2016\u001b[0m \n\u001b[0;32m   2017\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2048\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5549\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5547\u001b[0m \u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5548\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m-> 5549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m StructuredFunctionWrapper(\n\u001b[0;32m   5550\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m   5551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5552\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   5553\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5554\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4533\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4526\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   4527\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4528\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4529\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4530\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4531\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m-> 4533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m   4534\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m   4535\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3244\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3236\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3237\u001b[0m \n\u001b[0;32m   3238\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3242\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3244\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[0;32m   3245\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3246\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3247\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3210\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 3210\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   3211\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   3212\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3213\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3553\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3557\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   3558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[0;32m   3560\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3387\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   3388\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3389\u001b[0m ]\n\u001b[0;32m   3390\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   3391\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3392\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   3393\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   3394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   3395\u001b[0m         args,\n\u001b[0;32m   3396\u001b[0m         kwargs,\n\u001b[0;32m   3397\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   3398\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   3399\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   3400\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   3401\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[0;32m   3402\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   3403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   3404\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   3405\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3406\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3408\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3409\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3410\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1143\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1148\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4510\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4504\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m   4505\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m   4506\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m   4507\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   4508\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m   4509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m-> 4510\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   4511\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m   4512\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4440\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m   4439\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m-> 4440\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m   4441\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m   4442\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    698\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    380\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    385\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:316\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    314\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(first_k_indices)\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size:\n\u001b[1;32m--> 316\u001b[0m   index_remainder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensors(tf\u001b[39m.\u001b[39;49mslice(\n\u001b[0;32m    317\u001b[0m       indices, [num_in_full_batch], [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_batch_size]))\n\u001b[0;32m    318\u001b[0m   flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mconcatenate(index_remainder)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    321\u001b[0m   \u001b[39m# 1024 is a magic constant that has not been properly evaluated\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:701\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    665\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensors\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    666\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \n\u001b[0;32m    668\u001b[0m \u001b[39m  `from_tensors` produces a dataset containing only a single element. To slice\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4645\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, element, name)\u001b[0m\n\u001b[0;32m   4643\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mor\u001b[39;00m compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2021\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m30\u001b[39m):\n\u001b[0;32m   4644\u001b[0m   kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m-> 4645\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mtensor_dataset(\n\u001b[0;32m   4646\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensors,\n\u001b[0;32m   4647\u001b[0m     output_shapes\u001b[39m=\u001b[39;49mstructure\u001b[39m.\u001b[39;49mget_flat_tensor_shapes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_structure),\n\u001b[0;32m   4648\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   4649\u001b[0m \u001b[39msuper\u001b[39m(TensorDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(variant_tensor)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7395\u001b[0m, in \u001b[0;36mtensor_dataset\u001b[1;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   7393\u001b[0m   metadata \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7394\u001b[0m metadata \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_str(metadata, \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7395\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   7396\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mTensorDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, components\u001b[39m=\u001b[39;49mcomponents, output_shapes\u001b[39m=\u001b[39;49moutput_shapes,\n\u001b[0;32m   7397\u001b[0m                        metadata\u001b[39m=\u001b[39;49mmetadata, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   7398\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   7399\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    739\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    740\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    741\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    742\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    743\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    745\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    746\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    748\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:689\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    687\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    688\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 689\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    690\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    691\u001b[0m     compute_device)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3697\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3695\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3696\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3697\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3698\u001b[0m       node_def,\n\u001b[0;32m   3699\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3700\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3701\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3702\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3703\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3704\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3705\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3706\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3707\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2097\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2095\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2096\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2097\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2098\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2099\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1936\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1932\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetAttrValueProto(op_desc, compat\u001b[39m.\u001b[39mas_str(name),\n\u001b[0;32m   1933\u001b[0m                                          serialized)\n\u001b[0;32m   1935\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1936\u001b[0m   c_op \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_FinishOperation(op_desc)\n\u001b[0;32m   1937\u001b[0m \u001b[39mexcept\u001b[39;00m errors\u001b[39m.\u001b[39mInvalidArgumentError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   1938\u001b[0m   \u001b[39m# Convert to ValueError for backwards compatibility.\u001b[39;00m\n\u001b[0;32m   1939\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(e\u001b[39m.\u001b[39mmessage)\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "LearningQDeep.trainingEpisodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = LearningQDeep.mainNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_train,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3127   58]\n",
            " [   1  189]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(confusion_matrix(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99      3185\n",
            "           1       0.77      0.99      0.86       190\n",
            "\n",
            "    accuracy                           0.98      3375\n",
            "   macro avg       0.88      0.99      0.93      3375\n",
            "weighted avg       0.99      0.98      0.98      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_test,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[6926  517]\n",
            " [ 166  266]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95      7443\n",
            "           1       0.34      0.62      0.44       432\n",
            "\n",
            "    accuracy                           0.91      7875\n",
            "   macro avg       0.66      0.77      0.70      7875\n",
            "weighted avg       0.94      0.91      0.92      7875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = np.argmax(loaded_model.predict(X_validate,verbose=0), axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3308  251]\n",
            " [  79  112]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.93      0.95      3559\n",
            "           1       0.31      0.59      0.40       191\n",
            "\n",
            "    accuracy                           0.91      3750\n",
            "   macro avg       0.64      0.76      0.68      3750\n",
            "weighted avg       0.94      0.91      0.92      3750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_validate,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "LearningQDeep.mainNetwork.save('Trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier()"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rf.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = rf.predict(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3185    0]\n",
            " [   0  190]]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(confusion_matrix(y_train, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00      3185\n",
            "           1       1.00      1.00      1.00       190\n",
            "\n",
            "    accuracy                           1.00      3375\n",
            "   macro avg       1.00      1.00      1.00      3375\n",
            "weighted avg       1.00      1.00      1.00      3375\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = rf.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[7424   19]\n",
            " [ 123  309]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      7443\n",
            "           1       0.94      0.72      0.81       432\n",
            "\n",
            "    accuracy                           0.98      7875\n",
            "   macro avg       0.96      0.86      0.90      7875\n",
            "weighted avg       0.98      0.98      0.98      7875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [],
      "source": [
        "y_pred  = rf.predict(X_validate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[3550    9]\n",
            " [  68  123]]\n"
          ]
        }
      ],
      "source": [
        "print(confusion_matrix(y_validate, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      3559\n",
            "           1       0.93      0.64      0.76       191\n",
            "\n",
            "    accuracy                           0.98      3750\n",
            "   macro avg       0.96      0.82      0.88      3750\n",
            "weighted avg       0.98      0.98      0.98      3750\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_validate,y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "61251865e30e62dadd10c02289a005295abe3e4116391d19d949c6135f5bb5ad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
