{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MFz_NRKrx_hl"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tqdm import tqdm\n",
        "from collections import deque \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available:  1\n"
          ]
        }
      ],
      "source": [
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Gy5DCfcRyGOI"
      },
      "outputs": [],
      "source": [
        "X,y = make_classification(1000,150,random_state=50,weights=[0.9])\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    896\n",
              "1    104\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pd.Series(y).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vZCrd62yyING"
      },
      "outputs": [],
      "source": [
        "def rew(state):\n",
        "    lr = LogisticRegression(C=state)\n",
        "    lr.fit(X_train,y_train)\n",
        "    y_pred = lr.predict(X_test)\n",
        "    return f1_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        " actions = {0 : -10, 1 : -1, 2 : -0.1, 3 : -0.01, 4 : 0, 5 : 0.01,  6 : 0.1, 7 : 1, 8: 10}\n",
        " len(actions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6ypzcQ4YyJQ2"
      },
      "outputs": [],
      "source": [
        "def step(action, state):\n",
        "    state = state[0]\n",
        "    \n",
        "    r = rew(state)\n",
        "   \n",
        "    next_state = state + actions[action]\n",
        "\n",
        "    return r, np.array([next_state])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "lC5LkJ-6zCIF"
      },
      "outputs": [],
      "source": [
        "%run -i ./DQN_Class.py\n",
        "gamma=0.5\n",
        "epsilon=.8\n",
        "numberEpisodes= 1000\n",
        "LearningQDeep=DeepQLearning(gamma,epsilon,numberEpisodes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "LearningQDeep.epsilon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "0kuOS04kzRP2",
        "outputId": "05ad7a66-a3b7-4a44-c1b5-8e675fc2273b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulating episode 0\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.9067755144418808\n",
            "\t Max state 5.00677551444188\n",
            "Simulating episode 1\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.529136753544159\n",
            "\t Max state 33.72913675354416\n",
            "Simulating episode 2\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.600107078224237\n",
            "\t Max state 48.60010707822424\n",
            "Simulating episode 3\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.28772324801027\n",
            "\t Max state 70.18772324801027\n",
            "Simulating episode 4\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.45372763206694\n",
            "\t Max state 89.35372763206695\n",
            "Simulating episode 5\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.853190632850461\n",
            "\t Max state 25.853190632850463\n",
            "Simulating episode 6\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.57835977015366\n",
            "\t Max state 38.57835977015366\n",
            "Simulating episode 7\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.779620188645495\n",
            "\t Max state 65.6796201886455\n",
            "Simulating episode 8\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.328483014428677\n",
            "\t Max state 34.42848301442868\n",
            "Simulating episode 9\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.955259598383684\n",
            "\t Max state 35.955259598383684\n",
            "Simulating episode 10\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.259673579981813\n",
            "\t Max state 29.479673579981817\n",
            "Simulating episode 11\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 48.618262556335665\n",
            "\t Max state 70.61826255633567\n",
            "Simulating episode 12\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.349799973711214\n",
            "\t Max state 121.3297999737112\n",
            "Simulating episode 13\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.86150280853208\n",
            "\t Max state 57.97150280853208\n",
            "Simulating episode 14\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.142215657326112\n",
            "\t Max state 23.152215657326114\n",
            "Simulating episode 15\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.517678171748056\n",
            "\t Max state 90.50767817174805\n",
            "Simulating episode 16\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.823263964832172\n",
            "\t Max state 27.823263964832172\n",
            "Simulating episode 17\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.920013805720956\n",
            "\t Max state 31.930013805720957\n",
            "Simulating episode 18\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 0.07560465366538982\n",
            "\t Max state 0.07560465366538982\n",
            "Simulating episode 19\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.281143564945634\n",
            "\t Max state 82.48114356494563\n",
            "Simulating episode 20\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.495120368781398\n",
            "\t Max state 13.595120368781398\n",
            "Simulating episode 21\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.6550574167928\n",
            "\t Max state 22.6650574167928\n",
            "Simulating episode 22\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.936507116152558\n",
            "\t Max state 36.936507116152555\n",
            "Simulating episode 23\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.585737315247066\n",
            "\t Max state 7.585737315247066\n",
            "Simulating episode 24\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.11713480381909\n",
            "\t Max state 70.12713480381908\n",
            "Simulating episode 25\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.61580237024304\n",
            "\t Max state 82.60580237024304\n",
            "Simulating episode 26\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.368244955045643\n",
            "\t Max state 53.488244955045644\n",
            "Simulating episode 27\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.177874118810351\n",
            "\t Max state 73.97787411881035\n",
            "Simulating episode 28\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.662802949191205\n",
            "\t Max state 14.672802949191205\n",
            "Simulating episode 29\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.70890894731284\n",
            "\t Max state 66.70890894731284\n",
            "Simulating episode 30\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.612518971849536\n",
            "\t Max state 40.61251897184954\n",
            "Simulating episode 31\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.037837819152073\n",
            "\t Max state 14.037837819152074\n",
            "Simulating episode 32\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.3860009529899076\n",
            "\t Max state 1.4960009529899077\n",
            "Simulating episode 33\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.784409997874338\n",
            "\t Max state 19.784409997874338\n",
            "Simulating episode 34\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 33.21342764529028\n",
            "\t Max state 64.12342764529028\n",
            "Simulating episode 35\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.69696188895051\n",
            "\t Max state 78.7969618889505\n",
            "Simulating episode 36\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.241579943221262\n",
            "\t Max state 25.33157994322126\n",
            "Simulating episode 37\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.24977909578196\n",
            "\t Max state 55.24977909578196\n",
            "Simulating episode 38\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.331524911291936\n",
            "\t Max state 6.331524911291936\n",
            "Simulating episode 39\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.602125765678002\n",
            "\t Max state 41.402125765678\n",
            "Simulating episode 40\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.46732373016585\n",
            "\t Max state 37.57732373016586\n",
            "Simulating episode 41\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.77377223387165\n",
            "\t Max state 43.77377223387165\n",
            "Simulating episode 42\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.361314554478938\n",
            "\t Max state 27.46131455447894\n",
            "Simulating episode 43\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.833853129389762\n",
            "\t Max state 31.843853129389764\n",
            "Simulating episode 44\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.008470565511732\n",
            "\t Max state 2.0184705655117323\n",
            "Simulating episode 45\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.57868603656784\n",
            "\t Max state 42.57868603656784\n",
            "Simulating episode 46\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.378347684606574\n",
            "\t Max state 13.478347684606574\n",
            "Simulating episode 47\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.412414986403757\n",
            "\t Max state 62.122414986403754\n",
            "Simulating episode 48\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.581575800424664\n",
            "\t Max state 18.581575800424663\n",
            "Simulating episode 49\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.30674768734176\n",
            "\t Max state 70.22674768734177\n",
            "Simulating episode 50\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.701975184324105\n",
            "\t Max state 61.701975184324105\n",
            "Simulating episode 51\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 42.660767593453976\n",
            "\t Max state 62.87076759345398\n",
            "Simulating episode 52\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.85672378914311\n",
            "\t Max state 154.10672378914313\n",
            "Simulating episode 53\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.680772619476068\n",
            "\t Max state 41.67077261947607\n",
            "Simulating episode 54\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.234234579238496\n",
            "\t Max state 53.3242345792385\n",
            "Simulating episode 55\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.020617345124595\n",
            "\t Max state 75.01061734512459\n",
            "Simulating episode 56\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.016738505456473\n",
            "\t Max state 40.226738505456474\n",
            "Simulating episode 57\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 47.48415484016547\n",
            "\t Max state 47.48415484016547\n",
            "Simulating episode 58\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 48.17144643109502\n",
            "\t Max state 58.18144643109502\n",
            "Simulating episode 59\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.956884894333776\n",
            "\t Max state 110.95688489433378\n",
            "Simulating episode 60\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.9928000874719\n",
            "\t Max state 48.0928000874719\n",
            "Simulating episode 61\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.39127612328266\n",
            "\t Max state 46.401276123282656\n",
            "Simulating episode 62\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.67490652265963\n",
            "\t Max state 23.67490652265963\n",
            "Simulating episode 63\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.273478272826722\n",
            "\t Max state 35.37347827282672\n",
            "Simulating episode 64\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.300468293803828\n",
            "\t Max state 54.39046829380383\n",
            "Simulating episode 65\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 19.43961744395166\n",
            "\t Max state 71.41961744395167\n",
            "Simulating episode 66\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.485424194615298\n",
            "\t Max state 28.285424194615295\n",
            "Simulating episode 67\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.578131831892791\n",
            "\t Max state 4.77813183189279\n",
            "Simulating episode 68\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.182942581994332\n",
            "\t Max state 77.18294258199431\n",
            "Simulating episode 69\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.76618330948904\n",
            "\t Max state 64.76618330948904\n",
            "Simulating episode 70\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.67429450519996\n",
            "\t Max state 29.67429450519996\n",
            "Simulating episode 71\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.068832391645948\n",
            "\t Max state 10.168832391645948\n",
            "Simulating episode 72\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.555928211541851\n",
            "\t Max state 8.56592821154185\n",
            "Simulating episode 73\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.79979984340974\n",
            "\t Max state 52.599799843409734\n",
            "Simulating episode 74\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.079296825657517\n",
            "\t Max state 17.099296825657518\n",
            "Simulating episode 75\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.2326305364123371\n",
            "\t Max state 19.232630536412337\n",
            "Simulating episode 76\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.43743462448799\n",
            "\t Max state 39.43743462448799\n",
            "Simulating episode 77\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.922844153297312\n",
            "\t Max state 57.012844153297316\n",
            "Simulating episode 78\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.192053879515356\n",
            "\t Max state 52.28205387951536\n",
            "Simulating episode 79\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.072102322101655\n",
            "\t Max state 38.182102322101656\n",
            "Simulating episode 80\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.765869603983234\n",
            "\t Max state 18.765869603983234\n",
            "Simulating episode 81\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.779771677255784\n",
            "\t Max state 30.879771677255786\n",
            "Simulating episode 82\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.573595563258934\n",
            "\t Max state 48.573595563258934\n",
            "Simulating episode 83\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.018718112368329\n",
            "\t Max state 16.32871811236833\n",
            "Simulating episode 84\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.01810960291045\n",
            "\t Max state 104.79810960291044\n",
            "Simulating episode 85\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.380073194073958\n",
            "\t Max state 28.48007319407396\n",
            "Simulating episode 86\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.96749354953576\n",
            "\t Max state 88.36749354953574\n",
            "Simulating episode 87\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.58254830838898\n",
            "\t Max state 45.58254830838898\n",
            "Simulating episode 88\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.787709169685417\n",
            "\t Max state 21.787709169685417\n",
            "Simulating episode 89\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.6198132597298116\n",
            "\t Max state 11.509813259729812\n",
            "Simulating episode 90\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.339840380512467\n",
            "\t Max state 28.339840380512467\n",
            "Simulating episode 91\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.229741616970177\n",
            "\t Max state 2.749741616970177\n",
            "Simulating episode 92\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.1260902586358275\n",
            "\t Max state 3.2260902586358275\n",
            "Simulating episode 93\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.19283529812335\n",
            "\t Max state 51.40283529812335\n",
            "Simulating episode 94\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.936617037530652\n",
            "\t Max state 7.936617037530652\n",
            "Simulating episode 95\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.171407004543525\n",
            "\t Max state 61.271407004543526\n",
            "Simulating episode 96\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.221185892495665\n",
            "\t Max state 37.22118589249567\n",
            "Simulating episode 97\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.46194620711877\n",
            "\t Max state 62.47194620711877\n",
            "Simulating episode 98\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.787092644236231\n",
            "\t Max state 6.787092644236231\n",
            "Simulating episode 99\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5117518516311815\n",
            "\t Max state 20.62175185163118\n",
            "Simulating episode 100\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.988427652304168\n",
            "\t Max state 53.998427652304166\n",
            "Simulating episode 101\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.037537866710243\n",
            "\t Max state 41.22753786671024\n",
            "Simulating episode 102\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.161471341835245\n",
            "\t Max state 32.17147134183524\n",
            "Simulating episode 103\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.545717753853598\n",
            "\t Max state 45.645717753853596\n",
            "Simulating episode 104\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.853021681954116\n",
            "\t Max state 16.953021681954116\n",
            "Simulating episode 105\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.737195991553286\n",
            "\t Max state 19.737195991553286\n",
            "Simulating episode 106\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.311225631642106\n",
            "\t Max state 38.32122563164211\n",
            "Simulating episode 107\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.361111364684129\n",
            "\t Max state 5.361111364684129\n",
            "Simulating episode 108\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.241277397595791\n",
            "\t Max state 24.431277397595792\n",
            "Simulating episode 109\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.06900049387532\n",
            "\t Max state 57.16900049387532\n",
            "Simulating episode 110\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.551606675629614\n",
            "\t Max state 57.551606675629614\n",
            "Simulating episode 111\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.697422236865954\n",
            "\t Max state 31.697422236865954\n",
            "Simulating episode 112\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.057951367087178\n",
            "\t Max state 42.957951367087176\n",
            "Simulating episode 113\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.569512874374098\n",
            "\t Max state 36.7995128743741\n",
            "Simulating episode 114\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.32577316954692\n",
            "\t Max state 39.32577316954692\n",
            "Simulating episode 115\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.2317618501216825\n",
            "\t Max state 32.14176185012168\n",
            "Simulating episode 116\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.798631272052981\n",
            "\t Max state 14.798631272052981\n",
            "Simulating episode 117\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.44447878397324\n",
            "\t Max state 35.57447878397324\n",
            "Simulating episode 118\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.823491778505719\n",
            "\t Max state 19.71349177850572\n",
            "Simulating episode 119\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.001491871113387\n",
            "\t Max state 22.10149187111339\n",
            "Simulating episode 120\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.748022210923146\n",
            "\t Max state 15.748022210923146\n",
            "Simulating episode 121\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.3563730372697407\n",
            "\t Max state 32.35637303726974\n",
            "Simulating episode 122\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.510151935678575\n",
            "\t Max state 45.66015193567858\n",
            "Simulating episode 123\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.700783043492066\n",
            "\t Max state 8.700783043492066\n",
            "Simulating episode 124\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.895910343763953\n",
            "\t Max state 17.795910343763953\n",
            "Simulating episode 125\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.02166554875065\n",
            "\t Max state 9.02166554875065\n",
            "Simulating episode 126\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.291019164390648\n",
            "\t Max state 15.391019164390647\n",
            "Simulating episode 127\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.287711940664968\n",
            "\t Max state 4.287711940664968\n",
            "Simulating episode 128\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.27046607347392\n",
            "\t Max state 58.27046607347392\n",
            "Simulating episode 129\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5000721301504031\n",
            "\t Max state 12.480072130150404\n",
            "Simulating episode 130\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.982381600580467\n",
            "\t Max state 26.782381600580468\n",
            "Simulating episode 131\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.04537061092954\n",
            "\t Max state 48.14537061092954\n",
            "Simulating episode 132\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.557157358791596\n",
            "\t Max state 20.557157358791596\n",
            "Simulating episode 133\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.005472689951324\n",
            "\t Max state 24.215472689951326\n",
            "Simulating episode 134\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.929926319294463\n",
            "\t Max state 30.029926319294464\n",
            "Simulating episode 135\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 49.217886228215235\n",
            "\t Max state 60.427886228215236\n",
            "Simulating episode 136\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.9152163570897542\n",
            "\t Max state 32.915216357089754\n",
            "Simulating episode 137\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.435553957853948\n",
            "\t Max state 22.435553957853948\n",
            "Simulating episode 138\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.923872223593814\n",
            "\t Max state 12.123872223593814\n",
            "Simulating episode 139\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.6447331956719444\n",
            "\t Max state 3.8547331956719444\n",
            "Simulating episode 140\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.45499525088673054\n",
            "\t Max state 0.45499525088673054\n",
            "Simulating episode 141\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.634095227305684\n",
            "\t Max state 7.624095227305684\n",
            "Simulating episode 142\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.869058253774696\n",
            "\t Max state 27.869058253774696\n",
            "Simulating episode 143\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 48.89217060563133\n",
            "\t Max state 74.90217060563133\n",
            "Simulating episode 144\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.964929167536191\n",
            "\t Max state 16.974929167536192\n",
            "Simulating episode 145\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 33.7507263564033\n",
            "\t Max state 33.760726356403296\n",
            "Simulating episode 146\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.628899881197226\n",
            "\t Max state 7.718899881197226\n",
            "Simulating episode 147\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.090976216239795\n",
            "\t Max state 44.13097621623979\n",
            "Simulating episode 148\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.335394867173136\n",
            "\t Max state 25.435394867173137\n",
            "Simulating episode 149\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5836933454900328\n",
            "\t Max state 3.603693345490033\n",
            "Simulating episode 150\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.184259927659905\n",
            "\t Max state 21.184259927659905\n",
            "Simulating episode 151\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.38887442512173\n",
            "\t Max state 23.498874425121734\n",
            "Simulating episode 152\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.24141081602215228\n",
            "\t Max state 22.231410816022155\n",
            "Simulating episode 153\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1193614244284795\n",
            "\t Max state 12.11936142442848\n",
            "Simulating episode 154\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.700096493994291\n",
            "\t Max state 11.700096493994291\n",
            "Simulating episode 155\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.31077185435582\n",
            "\t Max state 46.32077185435582\n",
            "Simulating episode 156\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.054256846539978\n",
            "\t Max state 27.15425684653998\n",
            "Simulating episode 157\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.789935291735512\n",
            "\t Max state 28.88993529173551\n",
            "Simulating episode 158\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.386109929895504\n",
            "\t Max state 21.386109929895504\n",
            "Simulating episode 159\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.14925029248485\n",
            "\t Max state 44.14925029248485\n",
            "Simulating episode 160\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.26419834353605\n",
            "\t Max state 84.47419834353605\n",
            "Simulating episode 161\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.316285994620227\n",
            "\t Max state 16.316285994620227\n",
            "Simulating episode 162\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.12231198292292\n",
            "\t Max state 35.21231198292292\n",
            "Simulating episode 163\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.126915995695178\n",
            "\t Max state 33.41691599569518\n",
            "Simulating episode 164\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.335031501281165\n",
            "\t Max state 44.335031501281165\n",
            "Simulating episode 165\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.42481664943778\n",
            "\t Max state 25.42481664943778\n",
            "Simulating episode 166\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.298521943355281\n",
            "\t Max state 20.268521943355278\n",
            "Simulating episode 167\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.05715205074978\n",
            "\t Max state 41.07715205074979\n",
            "Simulating episode 168\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.287023650264878\n",
            "\t Max state 25.287023650264878\n",
            "Simulating episode 169\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.778873180754026\n",
            "\t Max state 16.778873180754026\n",
            "Simulating episode 170\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.90658317048489\n",
            "\t Max state 16.99658317048489\n",
            "Simulating episode 171\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.950171363625586\n",
            "\t Max state 33.960171363625584\n",
            "Simulating episode 172\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.571593626823354\n",
            "\t Max state 8.681593626823354\n",
            "Simulating episode 173\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.14790335836888\n",
            "\t Max state 25.24790335836888\n",
            "Simulating episode 174\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.40486437960595\n",
            "\t Max state 24.40486437960595\n",
            "Simulating episode 175\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.916503496635997\n",
            "\t Max state 40.216503496636\n",
            "Simulating episode 176\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.931122982140046\n",
            "\t Max state 38.931122982140046\n",
            "Simulating episode 177\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.1728825972012302\n",
            "\t Max state 43.17288259720123\n",
            "Simulating episode 178\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.578774934023595\n",
            "\t Max state 39.5787749340236\n",
            "Simulating episode 179\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 35.87158999504247\n",
            "\t Max state 35.87158999504247\n",
            "Simulating episode 180\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.57502570270118\n",
            "\t Max state 38.605025702701184\n",
            "Simulating episode 181\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.009448693831512\n",
            "\t Max state 47.009448693831516\n",
            "Simulating episode 182\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.716192811602557\n",
            "\t Max state 57.71619281160255\n",
            "Simulating episode 183\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.82554092139067\n",
            "\t Max state 26.92554092139067\n",
            "Simulating episode 184\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.184459953511026\n",
            "\t Max state 4.374459953511026\n",
            "Simulating episode 185\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.25277507281409\n",
            "\t Max state 44.25277507281409\n",
            "Simulating episode 186\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.8\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.2718789951957241\n",
            "\t Max state 27.391878995195725\n",
            "Simulating episode 187\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.573063869884663\n",
            "\t Max state 40.69306386988467\n",
            "Simulating episode 188\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.732421053580275\n",
            "\t Max state 39.71242105358027\n",
            "Simulating episode 189\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.2454850883926145\n",
            "\t Max state 11.245485088392615\n",
            "Simulating episode 190\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.967132446214501\n",
            "\t Max state 16.0671324462145\n",
            "Simulating episode 191\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.4436771773187824\n",
            "\t Max state 13.633677177318782\n",
            "Simulating episode 192\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.17404417633136\n",
            "\t Max state 30.17404417633136\n",
            "Simulating episode 193\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.271028095571424\n",
            "\t Max state 12.271028095571424\n",
            "Simulating episode 194\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 47.454763073333886\n",
            "\t Max state 57.55476307333389\n",
            "Simulating episode 195\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.245506273168109\n",
            "\t Max state 47.27550627316811\n",
            "Simulating episode 196\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.033468063104372\n",
            "\t Max state 28.133468063104374\n",
            "Simulating episode 197\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.082471127146483\n",
            "\t Max state 16.082471127146484\n",
            "Simulating episode 198\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.44786392465176\n",
            "\t Max state 40.36786392465176\n",
            "Simulating episode 199\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.994050243107267\n",
            "\t Max state 10.094050243107267\n",
            "Simulating episode 200\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.18592235219158\n",
            "\t Max state 42.19592235219158\n",
            "Simulating episode 201\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.438653006077812\n",
            "\t Max state 8.438653006077812\n",
            "Simulating episode 202\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.645777932795333\n",
            "\t Max state 44.65577793279533\n",
            "Simulating episode 203\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.7928215784000001\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.45037339751208\n",
            "\t Max state 39.45037339751208\n",
            "Simulating episode 204\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.215293433583963\n",
            "\t Max state 2.2052934335839627\n",
            "Simulating episode 205\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.692930820823989\n",
            "\t Max state 17.902930820823993\n",
            "Simulating episode 206\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.58763491582367\n",
            "\t Max state 30.58763491582367\n",
            "Simulating episode 207\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.912807411640898\n",
            "\t Max state 0.932807411640898\n",
            "Simulating episode 208\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.904572353803495\n",
            "\t Max state 48.8545723538035\n",
            "Simulating episode 209\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.744131840644862\n",
            "\t Max state 49.64413184064486\n",
            "Simulating episode 210\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.7763214215591338\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4960660868032041\n",
            "\t Max state 0.6260660868032041\n",
            "Simulating episode 211\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.23463423020079\n",
            "\t Max state 71.24463423020077\n",
            "Simulating episode 212\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.270984658598845\n",
            "\t Max state 1.390984658598845\n",
            "Simulating episode 213\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9578132100275749\n",
            "\t Max state 0.9578132100275749\n",
            "Simulating episode 214\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.992182152134724\n",
            "\t Max state 33.092182152134725\n",
            "Simulating episode 215\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.991339045967607\n",
            "\t Max state 23.091339045967608\n",
            "Simulating episode 216\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.606786221002105\n",
            "\t Max state 15.616786221002105\n",
            "Simulating episode 217\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.105433062178285\n",
            "\t Max state 49.11543306217828\n",
            "Simulating episode 218\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 35.321039330143066\n",
            "\t Max state 80.58103933014306\n",
            "Simulating episode 219\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.01267698880922\n",
            "\t Max state 38.21267698880922\n",
            "Simulating episode 220\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.8025643542440974\n",
            "\t Max state 44.8025643542441\n",
            "Simulating episode 221\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.8827242758697564\n",
            "\t Max state 33.89272427586975\n",
            "Simulating episode 222\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.28487905880904\n",
            "\t Max state 33.28487905880904\n",
            "Simulating episode 223\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.7465839137210806\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.937814378582814\n",
            "\t Max state 54.94781437858281\n",
            "Simulating episode 224\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.41688971336568\n",
            "\t Max state 38.426889713365675\n",
            "Simulating episode 225\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.415756231136093\n",
            "\t Max state 16.415756231136093\n",
            "Simulating episode 226\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.270488171028774\n",
            "\t Max state 51.17048817102877\n",
            "Simulating episode 227\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.724360449413281\n",
            "\t Max state 17.73436044941328\n",
            "Simulating episode 228\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.133070948569355\n",
            "\t Max state 44.133070948569355\n",
            "Simulating episode 229\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6806413470594794\n",
            "\t Max state 11.780641347059479\n",
            "Simulating episode 230\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.023396383167622\n",
            "\t Max state 11.023396383167622\n",
            "Simulating episode 231\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.227109567120515\n",
            "\t Max state 53.227109567120515\n",
            "Simulating episode 232\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.30745869581561\n",
            "\t Max state 47.31745869581561\n",
            "Simulating episode 233\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.26720231468849\n",
            "\t Max state 18.36720231468849\n",
            "Simulating episode 234\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.73736965896236\n",
            "\t Max state 44.747369658962356\n",
            "Simulating episode 235\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.333521754091851\n",
            "\t Max state 19.443521754091854\n",
            "Simulating episode 236\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.890011930734396\n",
            "\t Max state 50.890011930734396\n",
            "Simulating episode 237\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.068638709473511\n",
            "\t Max state 36.06863870947351\n",
            "Simulating episode 238\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.7136840696226784\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1180024146435725\n",
            "\t Max state 13.928002414643572\n",
            "Simulating episode 239\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.37891147778140244\n",
            "\t Max state 20.7389114777814\n",
            "Simulating episode 240\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8250637099585058\n",
            "\t Max state 0.9350637099585057\n",
            "Simulating episode 241\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.2827005461570581\n",
            "\t Max state 11.192700546157058\n",
            "Simulating episode 242\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7912413585384357\n",
            "\t Max state 12.791241358538436\n",
            "Simulating episode 243\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.4338779320875776\n",
            "\t Max state 11.433877932087578\n",
            "Simulating episode 244\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.52169953046719\n",
            "\t Max state 41.52169953046719\n",
            "Simulating episode 245\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.521582219620505\n",
            "\t Max state 48.521582219620505\n",
            "Simulating episode 246\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6967344252838571\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 48.24752232455273\n",
            "\t Max state 119.05752232455274\n",
            "Simulating episode 247\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.7548874859312\n",
            "\t Max state 41.7448874859312\n",
            "Simulating episode 248\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.9277577433114281\n",
            "\t Max state 21.927757743311428\n",
            "Simulating episode 249\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.198174982191\n",
            "\t Max state 28.198174982191\n",
            "Simulating episode 250\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.04511703520086\n",
            "\t Max state 46.04511703520086\n",
            "Simulating episode 251\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.159431560405288\n",
            "\t Max state 18.159431560405288\n",
            "Simulating episode 252\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.7821178512774303\n",
            "\t Max state 43.89211785127743\n",
            "Simulating episode 253\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.49502587527422603\n",
            "\t Max state 10.495025875274226\n",
            "Simulating episode 254\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.173131950483447\n",
            "\t Max state 18.173131950483448\n",
            "Simulating episode 255\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.834241047300072\n",
            "\t Max state 8.834241047300072\n",
            "Simulating episode 256\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8432774153223728\n",
            "\t Max state 22.943277415322374\n",
            "Simulating episode 257\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.0002482251136566\n",
            "\t Max state 4.000248225113657\n",
            "Simulating episode 258\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.934886769318526\n",
            "\t Max state 9.004886769318526\n",
            "Simulating episode 259\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.01333315828401\n",
            "\t Max state 24.01333315828401\n",
            "Simulating episode 260\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.18984761564136\n",
            "\t Max state 39.18984761564136\n",
            "Simulating episode 261\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.57208702590086\n",
            "\t Max state 26.57208702590086\n",
            "Simulating episode 262\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6640332134021367\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.273714251713166\n",
            "\t Max state 47.323714251713156\n",
            "Simulating episode 263\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4936323679254816\n",
            "\t Max state 17.60363236792548\n",
            "Simulating episode 264\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.244068748448896\n",
            "\t Max state 49.254068748448894\n",
            "Simulating episode 265\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.303573226093791\n",
            "\t Max state 16.31357322609379\n",
            "Simulating episode 266\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.2410850520870813\n",
            "\t Max state 46.13108505208708\n",
            "Simulating episode 267\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.789909965021984\n",
            "\t Max state 54.789909965021984\n",
            "Simulating episode 268\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4440615169589015\n",
            "\t Max state 31.5440615169589\n",
            "Simulating episode 269\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.779873998174246\n",
            "\t Max state 56.889873998174245\n",
            "Simulating episode 270\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8006422622956727\n",
            "\t Max state 10.900642262295673\n",
            "Simulating episode 271\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6463179641309256\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.2618510197752268\n",
            "\t Max state 12.261851019775227\n",
            "Simulating episode 272\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9734883757883459\n",
            "\t Max state 30.983488375788347\n",
            "Simulating episode 273\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.6634574025878557\n",
            "\t Max state 24.583457402587854\n",
            "Simulating episode 274\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.20020277925982\n",
            "\t Max state 16.20020277925982\n",
            "Simulating episode 275\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.2907404492835235\n",
            "\t Max state 11.210740449283524\n",
            "Simulating episode 276\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.396393227397535\n",
            "\t Max state 44.40639322739754\n",
            "Simulating episode 277\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.266213698067283\n",
            "\t Max state 36.366213698067284\n",
            "Simulating episode 278\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.711600294437538\n",
            "\t Max state 46.71160029443754\n",
            "Simulating episode 279\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.6088071852382484\n",
            "\t Max state 21.20880718523825\n",
            "Simulating episode 280\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6290753268471981\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.50480394690654\n",
            "\t Max state 48.51480394690654\n",
            "Simulating episode 281\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.2977805422249111\n",
            "\t Max state 10.487780542224911\n",
            "Simulating episode 282\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.0597488778751476\n",
            "\t Max state 34.93974887787515\n",
            "Simulating episode 283\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.53855796668349\n",
            "\t Max state 42.53855796668349\n",
            "Simulating episode 284\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6215603251035013\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.4778603111292554\n",
            "\t Max state 41.27786031112925\n",
            "Simulating episode 285\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.852355582052951\n",
            "\t Max state 16.972355582052952\n",
            "Simulating episode 286\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.476320146555848\n",
            "\t Max state 27.776320146555847\n",
            "Simulating episode 287\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.966208068522477\n",
            "\t Max state 33.05620806852248\n",
            "Simulating episode 288\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.2731151502092715\n",
            "\t Max state 28.583115150209277\n",
            "Simulating episode 289\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.50337771438164\n",
            "\t Max state 55.51337771438164\n",
            "Simulating episode 290\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.32068013649971\n",
            "\t Max state 50.33068013649971\n",
            "Simulating episode 291\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.576254586105465\n",
            "\t Max state 39.58625458610546\n",
            "Simulating episode 292\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.6067985742195334\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.150330158400143\n",
            "\t Max state 28.26033015840014\n",
            "Simulating episode 293\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.237313653951201\n",
            "\t Max state 9.237313653951201\n",
            "Simulating episode 294\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.592304132551468\n",
            "\t Max state 16.59230413255147\n",
            "Simulating episode 295\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.3502454519214018\n",
            "\t Max state 13.450245451921402\n",
            "Simulating episode 296\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.70838407376354\n",
            "\t Max state 15.918384073763539\n",
            "Simulating episode 297\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.597100351151274\n",
            "\t Max state 0.607100351151274\n",
            "Simulating episode 298\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.782019716550597\n",
            "\t Max state 19.782019716550597\n",
            "Simulating episode 299\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.65098368807615\n",
            "\t Max state 43.65098368807615\n",
            "Simulating episode 300\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.1922833562913\n",
            "\t Max state 42.1922833562913\n",
            "Simulating episode 301\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.199620959627566\n",
            "\t Max state 38.21962095962757\n",
            "Simulating episode 302\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.8698549673330003\n",
            "\t Max state 2.889854967333\n",
            "Simulating episode 303\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5870718994286863\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.07093330643088616\n",
            "\t Max state 31.76093330643089\n",
            "Simulating episode 304\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.45332734058964\n",
            "\t Max state 47.46332734058964\n",
            "Simulating episode 305\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.158193285572974\n",
            "\t Max state 26.168193285572976\n",
            "Simulating episode 306\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.48663635215057\n",
            "\t Max state 39.48663635215057\n",
            "Simulating episode 307\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.486365137519769\n",
            "\t Max state 16.37636513751977\n",
            "Simulating episode 308\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.497022509604369\n",
            "\t Max state 24.39702250960437\n",
            "Simulating episode 309\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.897941924234164\n",
            "\t Max state 15.907941924234164\n",
            "Simulating episode 310\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.770994749321176\n",
            "\t Max state 45.770994749321176\n",
            "Simulating episode 311\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5731292316290628\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.381737055336519\n",
            "\t Max state 25.31173705533652\n",
            "Simulating episode 312\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.956758639353886\n",
            "\t Max state 6.156758639353885\n",
            "Simulating episode 313\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.775120099218675\n",
            "\t Max state 36.775120099218675\n",
            "Simulating episode 314\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.57862797013006\n",
            "\t Max state 34.57862797013006\n",
            "Simulating episode 315\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.074606883468803\n",
            "\t Max state 43.9746068834688\n",
            "Simulating episode 316\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5645837202725589\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.071148004031166\n",
            "\t Max state 93.34114800403115\n",
            "Simulating episode 317\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.0546481212654\n",
            "\t Max state 49.0546481212654\n",
            "Simulating episode 318\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.508438662011518\n",
            "\t Max state 36.67843866201151\n",
            "Simulating episode 319\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.0895823357274055\n",
            "\t Max state 80.7995823357274\n",
            "Simulating episode 320\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.225781113103523\n",
            "\t Max state 26.235781113103524\n",
            "Simulating episode 321\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.690124957467587\n",
            "\t Max state 1.690124957467587\n",
            "Simulating episode 322\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.004639102595075\n",
            "\t Max state 41.014639102595076\n",
            "Simulating episode 323\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5528336365360677\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.473505024203609\n",
            "\t Max state 37.38350502420361\n",
            "Simulating episode 324\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.847307338855103\n",
            "\t Max state 28.777307338855103\n",
            "Simulating episode 325\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.104683558386965\n",
            "\t Max state 7.104683558386965\n",
            "Simulating episode 326\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.249661639478017\n",
            "\t Max state 17.249661639478017\n",
            "Simulating episode 327\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.133609825024962\n",
            "\t Max state 8.233609825024962\n",
            "Simulating episode 328\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.62377483234112\n",
            "\t Max state 45.82377483234112\n",
            "Simulating episode 329\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.665847874046136\n",
            "\t Max state 32.665847874046136\n",
            "Simulating episode 330\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5413280948627941\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.874736500927053\n",
            "\t Max state 43.73473650092705\n",
            "Simulating episode 331\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.832940277498391\n",
            "\t Max state 17.142940277498397\n",
            "Simulating episode 332\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.293504222615624\n",
            "\t Max state 15.303504222615624\n",
            "Simulating episode 333\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.859515850623982\n",
            "\t Max state 25.05951585062398\n",
            "Simulating episode 334\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.17839477832388\n",
            "\t Max state 38.17839477832388\n",
            "Simulating episode 335\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.36489408882012\n",
            "\t Max state 56.464894088820124\n",
            "Simulating episode 336\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.693316943981003\n",
            "\t Max state 32.083316943981\n",
            "Simulating episode 337\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5300620058574603\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 48.54444291463667\n",
            "\t Max state 59.54444291463667\n",
            "Simulating episode 338\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.665932316455169\n",
            "\t Max state 5.665932316455169\n",
            "Simulating episode 339\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.217145814032268\n",
            "\t Max state 27.217145814032268\n",
            "Simulating episode 340\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.559541147462804\n",
            "\t Max state 26.569541147462807\n",
            "Simulating episode 341\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.841124025836093\n",
            "\t Max state 15.841124025836093\n",
            "Simulating episode 342\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.865777207862145\n",
            "\t Max state 44.97577720786215\n",
            "Simulating episode 343\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4590163934426229\n",
            "\t Min state 1.5698924620626307\n",
            "\t Max state 6.69989246206263\n",
            "Simulating episode 344\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.0262110910463507\n",
            "\t Max state 21.01621109104635\n",
            "Simulating episode 345\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5174732948868538\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.41871221592524\n",
            "\t Max state 53.438712215925236\n",
            "Simulating episode 346\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.70737510648933\n",
            "\t Max state 25.71737510648933\n",
            "Simulating episode 347\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.326443635703839\n",
            "\t Max state 14.32644363570384\n",
            "Simulating episode 348\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.0908687030481445\n",
            "\t Max state 37.10086870304814\n",
            "Simulating episode 349\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.062669602767597\n",
            "\t Max state 26.0826696027676\n",
            "Simulating episode 350\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.777272526005198\n",
            "\t Max state 22.7772725260052\n",
            "Simulating episode 351\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.527359582926486\n",
            "\t Max state 26.727359582926486\n",
            "Simulating episode 352\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.5067036705990984\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.03432622937002\n",
            "\t Max state 113.10432622937003\n",
            "Simulating episode 353\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.7909250340253493\n",
            "\t Max state 15.890925034025349\n",
            "Simulating episode 354\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.1664411481864825\n",
            "\t Max state 14.166441148186482\n",
            "Simulating episode 355\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.728987779587424\n",
            "\t Max state 18.768987779587423\n",
            "Simulating episode 356\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.710318333419682\n",
            "\t Max state 47.720318333419684\n",
            "Simulating episode 357\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7912161448579843\n",
            "\t Max state 2.981216144857984\n",
            "Simulating episode 358\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.71754004247348\n",
            "\t Max state 8.71754004247348\n",
            "Simulating episode 359\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.313522980861109\n",
            "\t Max state 34.31352298086111\n",
            "Simulating episode 360\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.494669708559886\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.6104102080038444\n",
            "\t Max state 13.730410208003844\n",
            "Simulating episode 361\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.118296246250361\n",
            "\t Max state 41.25829624625035\n",
            "Simulating episode 362\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.84077110025067\n",
            "\t Max state 20.84077110025067\n",
            "Simulating episode 363\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.350022476759431\n",
            "\t Max state 25.35002247675943\n",
            "Simulating episode 364\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5082004500462634\n",
            "\t Max state 43.79820045004627\n",
            "Simulating episode 365\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.559770933355163\n",
            "\t Max state 7.569770933355163\n",
            "Simulating episode 366\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7366469149608927\n",
            "\t Max state 10.876646914960892\n",
            "Simulating episode 367\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7025830177384722\n",
            "\t Max state 21.722583017738472\n",
            "Simulating episode 368\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4829215471784624\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.841238444712612\n",
            "\t Max state 36.061238444712615\n",
            "Simulating episode 369\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5997345943572095\n",
            "\t Max state 13.30973459435721\n",
            "Simulating episode 370\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.2529336875495818\n",
            "\t Max state 26.69293368754958\n",
            "Simulating episode 371\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.47858827909674834\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.2338730276526535\n",
            "\t Max state 21.103873027652654\n",
            "Simulating episode 372\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.772280417844206\n",
            "\t Max state 17.872280417844205\n",
            "Simulating episode 373\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.14212996021578\n",
            "\t Max state 21.14212996021578\n",
            "Simulating episode 374\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.15667883137571\n",
            "\t Max state 32.15667883137571\n",
            "Simulating episode 375\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.84964406157593\n",
            "\t Max state 62.26964406157593\n",
            "Simulating episode 376\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.42777544057703454\n",
            "\t Max state 31.73777544057704\n",
            "Simulating episode 377\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8080375208865149\n",
            "\t Max state 30.808037520886515\n",
            "Simulating episode 378\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4590163934426229\n",
            "\t Min state 1.5358335725981505\n",
            "\t Max state 21.53583357259815\n",
            "Simulating episode 379\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6748448012995457\n",
            "\t Max state 12.774844801299546\n",
            "Simulating episode 380\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6271749579564556\n",
            "\t Max state 43.60717495795646\n",
            "Simulating episode 381\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.46442291646240874\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.869017644898776\n",
            "\t Max state 49.37901764489877\n",
            "Simulating episode 382\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.961041343139556\n",
            "\t Max state 79.42104134313955\n",
            "Simulating episode 383\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.301970523087885\n",
            "\t Max state 11.301970523087885\n",
            "Simulating episode 384\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.064049692841031\n",
            "\t Max state 18.06404969284103\n",
            "Simulating episode 385\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4588748701822921\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.849592725131458\n",
            "\t Max state 38.02959272513146\n",
            "Simulating episode 386\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.902366925305245\n",
            "\t Max state 38.002366925305246\n",
            "Simulating episode 387\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.586170633673264\n",
            "\t Max state 6.606170633673264\n",
            "Simulating episode 388\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.001604232895936\n",
            "\t Max state 43.10160423289594\n",
            "Simulating episode 389\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5021998736163427\n",
            "\t Max state 25.512199873616343\n",
            "Simulating episode 390\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.035929305083362006\n",
            "\t Max state 31.955929305083362\n",
            "Simulating episode 391\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.028370090232\n",
            "\t Max state 36.038370090232\n",
            "Simulating episode 392\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.072411532407148\n",
            "\t Max state 23.07241153240715\n",
            "Simulating episode 393\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.611840676853388\n",
            "\t Max state 8.611840676853388\n",
            "Simulating episode 394\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4155921149286339\n",
            "\t Max state 11.425592114928634\n",
            "Simulating episode 395\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.772879260981045\n",
            "\t Max state 5.982879260981044\n",
            "Simulating episode 396\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.23019004556685693\n",
            "\t Max state 11.330190045566857\n",
            "Simulating episode 397\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.442625239122472\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7280872259344413\n",
            "\t Max state 21.74808722593444\n",
            "Simulating episode 398\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.007308860565931\n",
            "\t Max state 19.00730886056593\n",
            "Simulating episode 399\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.4123993163955757\n",
            "\t Max state 22.322399316395575\n",
            "Simulating episode 400\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8890826834432448\n",
            "\t Max state 60.019082683443244\n",
            "Simulating episode 401\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.3597409412878925\n",
            "\t Max state 35.26974094128789\n",
            "Simulating episode 402\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.436025577477497\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.45476527181652726\n",
            "\t Max state 11.544765271816527\n",
            "Simulating episode 403\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.45290993659481504\n",
            "\t Max state 2.762909936594815\n",
            "Simulating episode 404\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.65973602355093\n",
            "\t Max state 45.65973602355093\n",
            "Simulating episode 405\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.308461415722078\n",
            "\t Max state 18.30846141572208\n",
            "Simulating episode 406\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.0029594959093209583\n",
            "\t Max state 31.10295949590932\n",
            "Simulating episode 407\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.065254540547926\n",
            "\t Max state 48.08525454054792\n",
            "Simulating episode 408\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.8648767516392475\n",
            "\t Max state 15.864876751639247\n",
            "Simulating episode 409\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8582008717241094\n",
            "\t Max state 1.9482008717241095\n",
            "Simulating episode 410\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.643381264277902\n",
            "\t Max state 24.743381264277904\n",
            "Simulating episode 411\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.424393174703451\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.658739172432725\n",
            "\t Max state 38.66873917243272\n",
            "Simulating episode 412\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.779291427772238\n",
            "\t Max state 14.779291427772238\n",
            "Simulating episode 413\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.31641807857089077\n",
            "\t Max state 21.31641807857089\n",
            "Simulating episode 414\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8141186343055662\n",
            "\t Max state 28.934118634305566\n",
            "Simulating episode 415\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.61506070866177\n",
            "\t Max state 48.61506070866177\n",
            "Simulating episode 416\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.41806535805424144\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.784648476608336\n",
            "\t Max state 65.78464847660834\n",
            "Simulating episode 417\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.7536459702447065\n",
            "\t Max state 18.753645970244705\n",
            "Simulating episode 418\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.1922433727245383\n",
            "\t Max state 10.212243372724538\n",
            "Simulating episode 419\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.77960102569843\n",
            "\t Max state 49.77960102569843\n",
            "Simulating episode 420\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.68423573858248\n",
            "\t Max state 38.68423573858248\n",
            "Simulating episode 421\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.60106095125271\n",
            "\t Max state 45.63106095125271\n",
            "Simulating episode 422\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.1293983080305106\n",
            "\t Max state 13.229398308030511\n",
            "Simulating episode 423\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.253892534973495\n",
            "\t Max state 29.353892534973497\n",
            "Simulating episode 424\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5726339408767459\n",
            "\t Max state 21.952633940876744\n",
            "Simulating episode 425\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.3815358374352016\n",
            "\t Max state 20.391535837435203\n",
            "Simulating episode 426\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.4056913663366211\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.606906528729002\n",
            "\t Max state 18.796906528729\n",
            "Simulating episode 427\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.388021540738734\n",
            "\t Max state 49.58802154073874\n",
            "Simulating episode 428\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.7167730700339536\n",
            "\t Max state 75.30677307003394\n",
            "Simulating episode 429\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4376396426249407\n",
            "\t Max state 10.43763964262494\n",
            "Simulating episode 430\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.16488266431962315\n",
            "\t Max state 13.964882664319623\n",
            "Simulating episode 431\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3996423986920796\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.105610247512326\n",
            "\t Max state 16.215610247512327\n",
            "Simulating episode 432\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.3632208590754\n",
            "\t Max state 71.18322085907539\n",
            "Simulating episode 433\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.173544403996326\n",
            "\t Max state 36.98354440399632\n",
            "Simulating episode 434\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.18618445865971878\n",
            "\t Max state 10.196184458659719\n",
            "Simulating episode 435\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 42.64092285020125\n",
            "\t Max state 113.84092285020124\n",
            "Simulating episode 436\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.283932356781186\n",
            "\t Max state 21.283932356781186\n",
            "Simulating episode 437\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.39250257191753346\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6251535970181195\n",
            "\t Max state 34.63515359701812\n",
            "Simulating episode 438\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7296728070590266\n",
            "\t Max state 20.719672807059027\n",
            "Simulating episode 439\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.7181955103274875\n",
            "\t Max state 14.818195510327488\n",
            "Simulating episode 440\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.516690973431285\n",
            "\t Max state 9.516690973431285\n",
            "Simulating episode 441\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7702531485072386\n",
            "\t Max state 31.78025314850724\n",
            "Simulating episode 442\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6396592008550603\n",
            "\t Max state 30.75965920085506\n",
            "Simulating episode 443\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9787060929868314\n",
            "\t Max state 14.978706092986831\n",
            "Simulating episode 444\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.3565456374582125\n",
            "\t Max state 14.556545637458212\n",
            "Simulating episode 445\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.377593421286903\n",
            "\t Max state 26.477593421286905\n",
            "Simulating episode 446\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.16189820855034\n",
            "\t Max state 18.171898208550342\n",
            "Simulating episode 447\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3808851932457944\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.826585899080136\n",
            "\t Max state 39.06658589908014\n",
            "Simulating episode 448\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.775263190468642\n",
            "\t Max state 44.88526319046864\n",
            "Simulating episode 449\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7659424909474716\n",
            "\t Max state 24.665942490947472\n",
            "Simulating episode 450\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.711735042958971\n",
            "\t Max state 28.731735042958974\n",
            "Simulating episode 451\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.376335097622531\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.396703144290829\n",
            "\t Max state 26.286703144290826\n",
            "Simulating episode 452\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.2873051848888797\n",
            "\t Max state 39.01730518488888\n",
            "Simulating episode 453\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.128896669156506\n",
            "\t Max state 14.128896669156507\n",
            "Simulating episode 454\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7245603469438127\n",
            "\t Max state 4.724560346943813\n",
            "Simulating episode 455\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.6537063322848695\n",
            "\t Max state 49.85370633228487\n",
            "Simulating episode 456\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.081443784036471\n",
            "\t Max state 9.251443784036468\n",
            "Simulating episode 457\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.314764123821874\n",
            "\t Max state 45.32476412382187\n",
            "Simulating episode 458\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.59533731104359\n",
            "\t Max state 6.625337311043589\n",
            "Simulating episode 459\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.755022835345947\n",
            "\t Max state 46.655022835345946\n",
            "Simulating episode 460\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.36629513285972737\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.49511099865245\n",
            "\t Max state 8.285110998652451\n",
            "Simulating episode 461\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.310956728301619\n",
            "\t Max state 54.41095672830162\n",
            "Simulating episode 462\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.02918505406905\n",
            "\t Max state 111.36918505406906\n",
            "Simulating episode 463\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.20718582145878\n",
            "\t Max state 10.217185821458779\n",
            "Simulating episode 464\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.2067567442911455\n",
            "\t Max state 5.2067567442911455\n",
            "Simulating episode 465\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.28258244621856\n",
            "\t Max state 38.28258244621856\n",
            "Simulating episode 466\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.35975107295633135\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7917695261546953\n",
            "\t Max state 1.8317695261546953\n",
            "Simulating episode 467\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.626887693098947\n",
            "\t Max state 58.77688769309895\n",
            "Simulating episode 468\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.241125602956124\n",
            "\t Max state 48.241125602956124\n",
            "Simulating episode 469\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.57052934432438\n",
            "\t Max state 18.84052934432438\n",
            "Simulating episode 470\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7679571597415629\n",
            "\t Max state 12.777957159741563\n",
            "Simulating episode 471\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.9506406368737395\n",
            "\t Max state 18.75064063687374\n",
            "Simulating episode 472\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3533239262089604\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.39720789858001204\n",
            "\t Max state 78.61720789858\n",
            "Simulating episode 473\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1837750245650356\n",
            "\t Max state 34.263775024565035\n",
            "Simulating episode 474\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.763646041258282\n",
            "\t Max state 7.863646041258281\n",
            "Simulating episode 475\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.347500535362581\n",
            "\t Max state 42.85750053536258\n",
            "Simulating episode 476\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3491030804561034\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.821124817977033\n",
            "\t Max state 39.91112481797703\n",
            "Simulating episode 477\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9934469904049772\n",
            "\t Max state 51.55344699040497\n",
            "Simulating episode 478\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.762243465453407\n",
            "\t Max state 5.7922434654534065\n",
            "Simulating episode 479\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.564230993788996\n",
            "\t Max state 18.044230993789\n",
            "Simulating episode 480\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.99465146272575\n",
            "\t Max state 56.80465146272576\n",
            "Simulating episode 481\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3438978594099731\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.357007345476067\n",
            "\t Max state 9.547007345476066\n",
            "Simulating episode 482\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.3047009449859568\n",
            "\t Max state 13.214700944985957\n",
            "Simulating episode 483\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.15720302142453946\n",
            "\t Max state 17.367203021424537\n",
            "Simulating episode 484\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5362658873829812\n",
            "\t Max state 3.5462658873829813\n",
            "Simulating episode 485\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.439966974921088\n",
            "\t Max state 18.439966974921088\n",
            "Simulating episode 486\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.33877024961294344\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.987035126751785\n",
            "\t Max state 49.11703512675178\n",
            "Simulating episode 487\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.263553173936934\n",
            "\t Max state 9.263553173936934\n",
            "Simulating episode 488\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.004824402335739\n",
            "\t Max state 28.10482440233574\n",
            "Simulating episode 489\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.972260639834232\n",
            "\t Max state 119.78226063983429\n",
            "Simulating episode 490\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3347232636513206\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.39358656830369654\n",
            "\t Max state 21.393586568303697\n",
            "Simulating episode 491\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.627529905327975\n",
            "\t Max state 112.06752990532794\n",
            "Simulating episode 492\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3327179365787855\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.583637107707988\n",
            "\t Max state 15.583637107707988\n",
            "Simulating episode 493\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.850793006347539\n",
            "\t Max state 6.9507930063475385\n",
            "Simulating episode 494\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4756997529836777\n",
            "\t Max state 13.475699752983678\n",
            "Simulating episode 495\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5680272890019995\n",
            "\t Max state 13.668027289002\n",
            "Simulating episode 496\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.808573936267734\n",
            "\t Max state 44.808573936267734\n",
            "Simulating episode 497\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.456412444988917\n",
            "\t Max state 45.75641244498892\n",
            "Simulating episode 498\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.697857736677998\n",
            "\t Max state 19.787857736678\n",
            "Simulating episode 499\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.32579343012375356\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.48022927402339377\n",
            "\t Max state 43.52022927402339\n",
            "Simulating episode 500\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.31191367311898\n",
            "\t Max state 28.32191367311898\n",
            "Simulating episode 501\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.42701915948403957\n",
            "\t Max state 37.45701915948404\n",
            "Simulating episode 502\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3159680786600638\n",
            "\t Max state 21.365968078660064\n",
            "Simulating episode 503\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.89940876319669\n",
            "\t Max state 52.89940876319669\n",
            "Simulating episode 504\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.32093576224824943\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5611714969218626\n",
            "\t Max state 61.781171496921864\n",
            "Simulating episode 505\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3754055942680221\n",
            "\t Max state 44.97540559426802\n",
            "Simulating episode 506\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3190130360966202\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.03695633813654169\n",
            "\t Max state 10.086956338136542\n",
            "Simulating episode 507\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.6047413662144283\n",
            "\t Max state 13.604741366214428\n",
            "Simulating episode 508\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.003276875474976\n",
            "\t Max state 35.26327687547497\n",
            "Simulating episode 509\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.44438732176864715\n",
            "\t Max state 14.454387321768646\n",
            "Simulating episode 510\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.45830596846055505\n",
            "\t Max state 35.55830596846056\n",
            "Simulating episode 511\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3142564657240226\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5144988798357659\n",
            "\t Max state 33.15449887983576\n",
            "Simulating episode 512\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.47844459762089975\n",
            "\t Max state 3.4784445976209\n",
            "Simulating episode 513\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.881124951453302\n",
            "\t Max state 38.001124951453306\n",
            "Simulating episode 514\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8576814927452787\n",
            "\t Max state 2.8576814927452787\n",
            "Simulating episode 515\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3105023240702399\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.712748374297044\n",
            "\t Max state 51.63274837429702\n",
            "Simulating episode 516\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.508698274074141\n",
            "\t Max state 3.198698274074141\n",
            "Simulating episode 517\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.784418293465585\n",
            "\t Max state 76.88441829346559\n",
            "Simulating episode 518\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5665466610479076\n",
            "\t Max state 1.8665466610479076\n",
            "Simulating episode 519\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.17644727393467\n",
            "\t Max state 83.27644727393466\n",
            "Simulating episode 520\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.3058726507084031\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.3368150816970825\n",
            "\t Max state 38.436815081697084\n",
            "Simulating episode 521\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.531561386972062\n",
            "\t Max state 6.631561386972062\n",
            "Simulating episode 522\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.74266178873608\n",
            "\t Max state 59.84266178873608\n",
            "Simulating episode 523\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.088691442778373\n",
            "\t Max state 9.098691442778373\n",
            "Simulating episode 524\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 33.6664319422842\n",
            "\t Max state 64.79643194228419\n",
            "Simulating episode 525\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 42.562646816509734\n",
            "\t Max state 63.562646816509734\n",
            "Simulating episode 526\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.79865972077991\n",
            "\t Max state 73.81865972077993\n",
            "Simulating episode 527\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.68297008013968\n",
            "\t Max state 40.90297008013968\n",
            "Simulating episode 528\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.29860832625007394\n",
            "\t Max of rewards 0.5106382978723404\n",
            "\t Min state 0.008512204376172422\n",
            "\t Max state 23.588512204376173\n",
            "Simulating episode 529\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.702769338387995\n",
            "\t Max state 32.91276933838799\n",
            "Simulating episode 530\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.006250624389594\n",
            "\t Max state 41.4062506243896\n",
            "Simulating episode 531\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2959289056762072\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.20307868312177133\n",
            "\t Max state 11.583078683121771\n",
            "Simulating episode 532\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.91585139027487\n",
            "\t Max state 9.11585139027487\n",
            "Simulating episode 533\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.55319062839762\n",
            "\t Max state 51.963190628397626\n",
            "Simulating episode 534\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.121900170386661\n",
            "\t Max state 15.35190017038666\n",
            "Simulating episode 535\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.224813861757305\n",
            "\t Max state 22.234813861757306\n",
            "Simulating episode 536\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.60344805071441\n",
            "\t Max state 114.99344805071443\n",
            "Simulating episode 537\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2906419763338151\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.266655889699928\n",
            "\t Max state 29.226655889699924\n",
            "Simulating episode 538\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4790206082697892\n",
            "\t Max state 10.68902060826979\n",
            "Simulating episode 539\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.28890074025359924\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.562268229834938\n",
            "\t Max state 28.392268229834936\n",
            "Simulating episode 540\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.0208479887993973\n",
            "\t Max state 24.29084798879941\n",
            "Simulating episode 541\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2871699359187399\n",
            "\t Max of rewards 0.5106382978723404\n",
            "\t Min state 0.017176738143746817\n",
            "\t Max state 21.567176738143743\n",
            "Simulating episode 542\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.87296070238049\n",
            "\t Max state 46.97296070238049\n",
            "Simulating episode 543\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.574809940805252\n",
            "\t Max state 49.674809940805254\n",
            "Simulating episode 544\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.638168544965827\n",
            "\t Max state 17.648168544965827\n",
            "Simulating episode 545\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.347308428608715\n",
            "\t Max state 10.347308428608715\n",
            "Simulating episode 546\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.12672182025480735\n",
            "\t Max state 40.136721820254806\n",
            "Simulating episode 547\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2820394902902792\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.020187257240115\n",
            "\t Max state 34.390187257240115\n",
            "Simulating episode 548\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.39956207902397\n",
            "\t Max state 46.809562079023976\n",
            "Simulating episode 549\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.696350068123655\n",
            "\t Max state 37.986350068123656\n",
            "Simulating episode 550\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.849838963082611\n",
            "\t Max state 27.93983896308261\n",
            "Simulating episode 551\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2786702161018518\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.85340013109049\n",
            "\t Max state 45.653400131090486\n",
            "Simulating episode 552\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.90462075498524\n",
            "\t Max state 48.01462075498524\n",
            "Simulating episode 553\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.732999703264163\n",
            "\t Max state 20.832999703264164\n",
            "Simulating episode 554\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.823353732335995\n",
            "\t Max state 16.823353732335995\n",
            "Simulating episode 555\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.8448344709876725\n",
            "\t Max state 37.94483447098767\n",
            "Simulating episode 556\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.04047867108215\n",
            "\t Max state 62.04047867108215\n",
            "Simulating episode 557\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.05263202566336\n",
            "\t Max state 102.54263202566338\n",
            "Simulating episode 558\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.484726740951633\n",
            "\t Max state 28.484726740951633\n",
            "Simulating episode 559\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.684712470343875\n",
            "\t Max state 46.82471247034387\n",
            "Simulating episode 560\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.112245025063103\n",
            "\t Max state 54.132245025063106\n",
            "Simulating episode 561\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2704220728879756\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.239471939363877\n",
            "\t Max state 27.939471939363877\n",
            "Simulating episode 562\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 49.39285810375634\n",
            "\t Max state 185.48285810375634\n",
            "Simulating episode 563\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2688019742493037\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2688019742493037\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.203264637302826\n",
            "\t Max state 67.21326463730284\n",
            "Simulating episode 564\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 49.65178007577987\n",
            "\t Max state 51.65178007577987\n",
            "Simulating episode 565\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.80620943222946\n",
            "\t Max state 26.086209432229456\n",
            "Simulating episode 566\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.451964626260743\n",
            "\t Max state 31.471964626260746\n",
            "Simulating episode 567\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.862077036459553\n",
            "\t Max state 25.882077036459556\n",
            "Simulating episode 568\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.5215164759781317\n",
            "\t Max state 42.54151647597813\n",
            "Simulating episode 569\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 19.841078947011553\n",
            "\t Max state 49.941078947011555\n",
            "Simulating episode 570\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.704732718528362\n",
            "\t Max state 8.704732718528362\n",
            "Simulating episode 571\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.262418060056701\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.430452557322646\n",
            "\t Max state 50.28045255732262\n",
            "Simulating episode 572\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.08394133364756295\n",
            "\t Max state 1.903941333647563\n",
            "Simulating episode 573\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.133530443877213\n",
            "\t Max state 26.133530443877213\n",
            "Simulating episode 574\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.26006337571852456\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.2281512856558\n",
            "\t Max state 50.238151285655796\n",
            "Simulating episode 575\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.494814108568043\n",
            "\t Max state 9.494814108568043\n",
            "Simulating episode 576\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.458727138612794\n",
            "\t Max state 40.57872713861279\n",
            "Simulating episode 577\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.2545981721894\n",
            "\t Max state 10.2545981721894\n",
            "Simulating episode 578\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2569566305664116\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6357704465643422\n",
            "\t Max state 14.265770446564343\n",
            "Simulating episode 579\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.694097965473775\n",
            "\t Max state 3.694097965473775\n",
            "Simulating episode 580\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.751794612159998\n",
            "\t Max state 50.94179461216\n",
            "Simulating episode 581\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.28783923724796\n",
            "\t Max state 64.59783923724795\n",
            "Simulating episode 582\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.25388699892716265\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.435572350088954\n",
            "\t Max state 60.61557235008898\n",
            "Simulating episode 583\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.674792966217106\n",
            "\t Max state 19.674792966217105\n",
            "Simulating episode 584\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.840004291595485\n",
            "\t Max state 12.870004291595485\n",
            "Simulating episode 585\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.287435623068255\n",
            "\t Max state 108.99743562306824\n",
            "Simulating episode 586\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8665767199300431\n",
            "\t Max state 1.9765767199300432\n",
            "Simulating episode 587\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.38200579790722\n",
            "\t Max state 45.58200579790722\n",
            "Simulating episode 588\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.24935117090045217\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.188613014642413\n",
            "\t Max state 6.288613014642412\n",
            "Simulating episode 589\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.449400411360973\n",
            "\t Max state 107.14940041136096\n",
            "Simulating episode 590\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.24785730803558756\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.724488660448234\n",
            "\t Max state 55.434488660448224\n",
            "Simulating episode 591\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.682250751929491\n",
            "\t Max state 19.46225075192949\n",
            "Simulating episode 592\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.24637239490314636\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.565405526663422\n",
            "\t Max state 80.27540552666348\n",
            "Simulating episode 593\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.8747771923145535\n",
            "\t Max state 6.474777192314551\n",
            "Simulating episode 594\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.487607340291564\n",
            "\t Max state 113.43760734029154\n",
            "Simulating episode 595\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.639697328629097\n",
            "\t Max state 58.5296973286291\n",
            "Simulating episode 596\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 40.0908679912186\n",
            "\t Max state 40.1008679912186\n",
            "Simulating episode 597\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.24269891607431476\n",
            "\t Max of rewards 0.5106382978723404\n",
            "\t Min state 0.05764898640274659\n",
            "\t Max state 91.62764898640275\n",
            "Simulating episode 598\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7353875522186157\n",
            "\t Max state 2.225387552218616\n",
            "Simulating episode 599\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.08397893547587\n",
            "\t Max state 28.18397893547587\n",
            "Simulating episode 600\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.199396552368711\n",
            "\t Max state 19.19939655236871\n",
            "Simulating episode 601\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23979960863106667\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23979960863106667\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.338976612266999\n",
            "\t Max state 227.6289766122671\n",
            "Simulating episode 602\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.650864338877135\n",
            "\t Max state 51.83086433887713\n",
            "Simulating episode 603\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.56579983074563\n",
            "\t Max state 15.66579983074563\n",
            "Simulating episode 604\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23764788026823067\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23764788026823067\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.277016529044982\n",
            "\t Max state 44.78701652904493\n",
            "Simulating episode 605\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 39.52226734229627\n",
            "\t Max state 60.59226734229625\n",
            "Simulating episode 606\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.53009535143287\n",
            "\t Max state 31.85009535143289\n",
            "Simulating episode 607\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.638324474207234\n",
            "\t Max state 21.81832447420723\n",
            "Simulating episode 608\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23480891304382479\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.648595874015493\n",
            "\t Max state 31.47859587401549\n",
            "Simulating episode 609\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7591689366973859\n",
            "\t Max state 43.969168936697386\n",
            "Simulating episode 610\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.522629830075886\n",
            "\t Max state 18.522629830075886\n",
            "Simulating episode 611\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6343120514792399\n",
            "\t Max state 1.7543120514792399\n",
            "Simulating episode 612\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.0530107062333167\n",
            "\t Max state 24.263010706233317\n",
            "Simulating episode 613\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.23130784884697536\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8980432463060304\n",
            "\t Max state 41.07804324630603\n",
            "Simulating episode 614\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.387631013805013\n",
            "\t Max state 1.6976310138050132\n",
            "Simulating episode 615\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.3619201553738651\n",
            "\t Max state 22.331920155373865\n",
            "Simulating episode 616\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.8743928406992936\n",
            "\t Max state 35.084392840699294\n",
            "Simulating episode 617\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.877955825510451\n",
            "\t Max state 36.94795582551046\n",
            "Simulating episode 618\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.19701961196980775\n",
            "\t Max state 24.387019611969805\n",
            "Simulating episode 619\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.22717540950178772\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8671021381144369\n",
            "\t Max state 21.86710213811444\n",
            "Simulating episode 620\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.0693028175056454\n",
            "\t Max state 43.169302817505645\n",
            "Simulating episode 621\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.890539730252684\n",
            "\t Max state 18.880539730252686\n",
            "Simulating episode 622\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.97540821543978\n",
            "\t Max state 12.055408215439778\n",
            "Simulating episode 623\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.027307430461576\n",
            "\t Max state 27.027307430461576\n",
            "Simulating episode 624\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.832511646386623\n",
            "\t Max state 25.952511646386622\n",
            "Simulating episode 625\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.018119054187252\n",
            "\t Max state 32.01811905418725\n",
            "Simulating episode 626\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.2224474480167682\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.21032584575721822\n",
            "\t Max state 1.890325845757218\n",
            "Simulating episode 627\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.7508260580544326\n",
            "\t Max state 13.660826058054433\n",
            "Simulating episode 628\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.927592725002673\n",
            "\t Max state 16.857592725002675\n",
            "Simulating episode 629\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.18328691142828837\n",
            "\t Max state 10.743286911428289\n",
            "Simulating episode 630\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.405897565918853\n",
            "\t Max state 8.505897565918852\n",
            "Simulating episode 631\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.21913069659606438\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.266568903102969\n",
            "\t Max state 31.06656890310297\n",
            "Simulating episode 632\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.7286648217764693\n",
            "\t Max state 42.81866482177647\n",
            "Simulating episode 633\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.54583583740105\n",
            "\t Max state 21.54583583740105\n",
            "Simulating episode 634\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.34680698258883347\n",
            "\t Max state 36.756806982588834\n",
            "Simulating episode 635\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.21651293764616214\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.04899956692058893\n",
            "\t Max state 40.91899956692059\n",
            "Simulating episode 636\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.44048505018019624\n",
            "\t Max state 45.250485050180195\n",
            "Simulating episode 637\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.21521580863672396\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.355770475470766\n",
            "\t Max state 141.35577047547076\n",
            "Simulating episode 638\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.9313164328708385\n",
            "\t Max state 38.351316432870846\n",
            "Simulating episode 639\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.4274137788606875\n",
            "\t Max state 49.72741377886069\n",
            "Simulating episode 640\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.21328467137499982\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.786370782977656\n",
            "\t Max state 51.77637078297766\n",
            "Simulating episode 641\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.458477247768668\n",
            "\t Max state 46.75847724776867\n",
            "Simulating episode 642\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.8108402358273248\n",
            "\t Max state 13.770840235827324\n",
            "Simulating episode 643\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.016398317573985\n",
            "\t Max state 8.026398317573985\n",
            "Simulating episode 644\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.9452097903763619\n",
            "\t Max state 23.965209790376363\n",
            "Simulating episode 645\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.779289422046467\n",
            "\t Max state 28.779289422046467\n",
            "Simulating episode 646\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.3856917854562738\n",
            "\t Max state 32.385691785456274\n",
            "Simulating episode 647\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.98472562299807\n",
            "\t Max state 9.98472562299807\n",
            "Simulating episode 648\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.489005691050647\n",
            "\t Max state 25.089005691050648\n",
            "Simulating episode 649\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.20759460792203172\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5029150508731509\n",
            "\t Max state 4.712915050873151\n",
            "Simulating episode 650\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.44718379446872114\n",
            "\t Max state 20.027183794468716\n",
            "Simulating episode 651\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1189194148828283\n",
            "\t Max state 39.048919414882825\n",
            "Simulating episode 652\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.553049110722565\n",
            "\t Max state 6.653049110722565\n",
            "Simulating episode 653\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.20511466033239262\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.213957210880494\n",
            "\t Max state 42.91395721088049\n",
            "Simulating episode 654\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.12935127211081543\n",
            "\t Max state 21.149351272110817\n",
            "Simulating episode 655\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.20388581840234124\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.76961449316914\n",
            "\t Max state 51.11961449316914\n",
            "Simulating episode 656\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.608540580164686\n",
            "\t Max state 62.608540580164686\n",
            "Simulating episode 657\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.30763026947490424\n",
            "\t Max state 111.3176302694749\n",
            "Simulating episode 658\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.442171025870294\n",
            "\t Max state 46.602171025870284\n",
            "Simulating episode 659\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4318090712861078\n",
            "\t Max state 0.4518090712861078\n",
            "Simulating episode 660\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.0116348534926045\n",
            "\t Max state 3.1116348534926046\n",
            "Simulating episode 661\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.20024328840566563\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.567140516424791\n",
            "\t Max state 29.79714051642479\n",
            "Simulating episode 662\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5106382978723404\n",
            "\t Min state 0.10974479798863021\n",
            "\t Max state 15.02974479798863\n",
            "Simulating episode 663\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.440141169729714\n",
            "\t Max state 30.140141169729723\n",
            "Simulating episode 664\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.45425236231225163\n",
            "\t Max state 27.07425236231225\n",
            "Simulating episode 665\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19785116047231613\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3540328602777798\n",
            "\t Max state 14.42403286027778\n",
            "Simulating episode 666\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.439815531708319\n",
            "\t Max state 44.42981553170832\n",
            "Simulating episode 667\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.35480565664886166\n",
            "\t Max state 41.54480565664886\n",
            "Simulating episode 668\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19607583666741668\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.2077089434240627\n",
            "\t Max state 47.12770894342404\n",
            "Simulating episode 669\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.879618416585508\n",
            "\t Max state 50.9096184165855\n",
            "Simulating episode 670\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.656570578348735\n",
            "\t Max state 35.656570578348735\n",
            "Simulating episode 671\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.1659777914090923\n",
            "\t Max state 21.525977791409094\n",
            "Simulating episode 672\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19373349356227948\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.07341324045460848\n",
            "\t Max state 49.713413240454614\n",
            "Simulating episode 673\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.407479504038363\n",
            "\t Max state 27.407479504038363\n",
            "Simulating episode 674\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.6086063985952137\n",
            "\t Max state 42.608606398595214\n",
            "Simulating episode 675\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.546442655348649\n",
            "\t Max state 39.64644265534865\n",
            "Simulating episode 676\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.387875343311325\n",
            "\t Max state 27.387875343311325\n",
            "Simulating episode 677\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.456656469784127\n",
            "\t Max state 36.85665646978413\n",
            "Simulating episode 678\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.19027234031880672\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.027229677765768956\n",
            "\t Max state 40.97722967776577\n",
            "Simulating episode 679\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4597105788883382\n",
            "\t Max state 73.65971057888834\n",
            "Simulating episode 680\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18913241872795672\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.24877098290223443\n",
            "\t Max state 49.38877098290223\n",
            "Simulating episode 681\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18856502147177284\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6489221632032681\n",
            "\t Max state 96.44892216320326\n",
            "Simulating episode 682\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.23146230877344262\n",
            "\t Max state 124.51146230877345\n",
            "Simulating episode 683\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6831929320531955\n",
            "\t Max state 61.38319293205319\n",
            "Simulating episode 684\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18687302244285106\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.24490085134055795\n",
            "\t Max state 40.88490085134056\n",
            "Simulating episode 685\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.2556966694792226\n",
            "\t Max state 16.955696669479224\n",
            "Simulating episode 686\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6342221547157632\n",
            "\t Max state 12.634222154715763\n",
            "Simulating episode 687\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.765205161090041\n",
            "\t Max state 46.82520516109004\n",
            "Simulating episode 688\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.3983717468280439\n",
            "\t Max state 25.75837174682804\n",
            "Simulating episode 689\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.18408669529815028\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.23875860044610525\n",
            "\t Max state 10.438758600446105\n",
            "Simulating episode 690\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.36500043249052\n",
            "\t Max state 19.46500043249052\n",
            "Simulating episode 691\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.29439517485917976\n",
            "\t Max state 2.31439517485918\n",
            "Simulating episode 692\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.2080488567322476\n",
            "\t Max state 41.20804885673225\n",
            "Simulating episode 693\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1818875757696665\n",
            "\t Max of rewards 0.5106382978723404\n",
            "\t Min state 0.11594916082614046\n",
            "\t Max state 11.70594916082614\n",
            "Simulating episode 694\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.851226480055523\n",
            "\t Max state 46.85122648005552\n",
            "Simulating episode 695\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.21335896582837122\n",
            "\t Max state 11.143358965828371\n",
            "Simulating episode 696\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.485049066639462\n",
            "\t Max state 37.49504906663946\n",
            "Simulating episode 697\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.20142437785202483\n",
            "\t Max state 22.951424377852025\n",
            "Simulating episode 698\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1791755829789156\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.4328729956284345\n",
            "\t Max state 15.622872995628434\n",
            "Simulating episode 699\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8471698375765548\n",
            "\t Max state 32.147169837576556\n",
            "Simulating episode 700\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.22514638286844324\n",
            "\t Max state 3.2251463828684432\n",
            "Simulating episode 701\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.62988949221284\n",
            "\t Max state 75.62988949221284\n",
            "Simulating episode 702\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.0252146721864106\n",
            "\t Max state 3.0252146721864106\n",
            "Simulating episode 703\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.02224445229406949\n",
            "\t Max state 41.69224445229406\n",
            "Simulating episode 704\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.17597451465161965\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.06299446346705\n",
            "\t Max state 39.06299446346705\n",
            "Simulating episode 705\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.139241974434139\n",
            "\t Max state 16.239241974434137\n",
            "Simulating episode 706\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.60838751884784\n",
            "\t Max state 40.628387518847845\n",
            "Simulating episode 707\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.20243772909494004\n",
            "\t Max state 22.932437729094943\n",
            "Simulating episode 708\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.29883938577836844\n",
            "\t Max state 3.2988393857783684\n",
            "Simulating episode 709\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.98493092009643\n",
            "\t Max state 31.49493092009644\n",
            "Simulating episode 710\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.797468735264204\n",
            "\t Max state 38.5974687352642\n",
            "Simulating episode 711\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1723121432292791\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3396088587652386\n",
            "\t Max state 13.339608858765239\n",
            "Simulating episode 712\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.807937817000976\n",
            "\t Max state 54.00793781700099\n",
            "Simulating episode 713\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.654771163797577\n",
            "\t Max state 90.68477116379758\n",
            "Simulating episode 714\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.44346970533258\n",
            "\t Max state 32.25346970533258\n",
            "Simulating episode 715\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.17025368377050795\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.903412247143892\n",
            "\t Max state 64.83341224714388\n",
            "Simulating episode 716\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16974292271919642\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16974292271919642\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16974292271919642\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.155480661113323\n",
            "\t Max state 252.22548066111312\n",
            "Simulating episode 717\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.960662773299934\n",
            "\t Max state 48.970662773299935\n",
            "Simulating episode 718\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.864932912548454\n",
            "\t Max state 6.874932912548454\n",
            "Simulating episode 719\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16821981489057816\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.856922817944577\n",
            "\t Max state 67.75692281794457\n",
            "Simulating episode 720\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.4566565075106407\n",
            "\t Max state 42.00665650751064\n",
            "Simulating episode 721\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.685305519777625\n",
            "\t Max state 47.705305519777625\n",
            "Simulating episode 722\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.697750564760188\n",
            "\t Max state 25.70775056476019\n",
            "Simulating episode 723\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1662102428277811\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.4375154807143335\n",
            "\t Max state 22.737515480714332\n",
            "Simulating episode 724\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.488908938871333\n",
            "\t Max state 9.488908938871333\n",
            "Simulating episode 725\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6724481915384096\n",
            "\t Max state 0.7824481915384096\n",
            "Simulating episode 726\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.88261021164406\n",
            "\t Max state 60.88261021164406\n",
            "Simulating episode 727\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1642246773297172\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.071662962470581\n",
            "\t Max state 34.31166296247058\n",
            "Simulating episode 728\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.908483263217736\n",
            "\t Max state 7.908483263217736\n",
            "Simulating episode 729\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.815013640600565\n",
            "\t Max state 22.885013640600576\n",
            "Simulating episode 730\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.8668979127431\n",
            "\t Max state 31.8768979127431\n",
            "Simulating episode 731\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16226283161137342\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16226283161137342\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.927711142870063\n",
            "\t Max state 260.56771114287005\n",
            "Simulating episode 732\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1617760431165393\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 47.89388750570664\n",
            "\t Max state 89.26388750570656\n",
            "Simulating episode 733\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.16129071498718967\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.40427221387774\n",
            "\t Max state 42.46427221387773\n",
            "Simulating episode 734\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.48168356699496\n",
            "\t Max state 14.48168356699496\n",
            "Simulating episode 735\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.589718391666842\n",
            "\t Max state 35.97971839166685\n",
            "Simulating episode 736\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15984344904676032\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.954568290848854\n",
            "\t Max state 26.874568290848856\n",
            "Simulating episode 737\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15936391869962002\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.47966528343256\n",
            "\t Max state 65.02966528343258\n",
            "Simulating episode 738\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.982220503409055\n",
            "\t Max state 8.032220503409054\n",
            "Simulating episode 739\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.1916380107105375\n",
            "\t Max state 15.201638010710539\n",
            "Simulating episode 740\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15793394195430252\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.72244206077544\n",
            "\t Max state 38.72244206077544\n",
            "Simulating episode 741\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.11174005200372\n",
            "\t Max state 28.311740052003724\n",
            "Simulating episode 742\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.24358780868768\n",
            "\t Max state 49.13358780868768\n",
            "Simulating episode 743\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.19704392625846556\n",
            "\t Max state 0.2270439262584656\n",
            "Simulating episode 744\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15604724603964334\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 13.539959971856664\n",
            "\t Max state 120.95995997185663\n",
            "Simulating episode 745\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4590163934426229\n",
            "\t Min state 1.5792103407903824\n",
            "\t Max state 22.899210340790383\n",
            "Simulating episode 746\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15511236698861983\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.160720584167617\n",
            "\t Max state 21.460720584167614\n",
            "Simulating episode 747\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.692283598519305\n",
            "\t Max state 19.422283598519307\n",
            "Simulating episode 748\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.836308157291243\n",
            "\t Max state 6.836308157291243\n",
            "Simulating episode 749\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15372053953159703\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.64045107033634\n",
            "\t Max state 57.75045107033633\n",
            "Simulating episode 750\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.9279739948575134\n",
            "\t Max state 47.82797399485751\n",
            "Simulating episode 751\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15279959977926322\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.08587379813946\n",
            "\t Max state 134.67587379813943\n",
            "Simulating episode 752\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8422062100073031\n",
            "\t Max state 23.872206210007302\n",
            "Simulating episode 753\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.263740913873087\n",
            "\t Max state 7.353740913873087\n",
            "Simulating episode 754\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9483433078219139\n",
            "\t Max state 0.9483433078219139\n",
            "Simulating episode 755\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.15097423927032014\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.381134322646696\n",
            "\t Max state 44.7911343226467\n",
            "Simulating episode 756\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.25720647801486\n",
            "\t Max state 46.66720647801486\n",
            "Simulating episode 757\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.63457578508318\n",
            "\t Max state 83.7645757850832\n",
            "Simulating episode 758\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.14961954334504307\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.476300900525409\n",
            "\t Max state 22.956300900525406\n",
            "Simulating episode 759\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.22941219386320633\n",
            "\t Max state 30.569412193863208\n",
            "Simulating episode 760\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1487231726608629\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.9219696077732218\n",
            "\t Max state 11.20196960777322\n",
            "Simulating episode 761\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1482770031428803\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.27236722951737136\n",
            "\t Max state 44.27236722951737\n",
            "Simulating episode 762\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.840962612251982\n",
            "\t Max state 24.940962612251983\n",
            "Simulating episode 763\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.93654788028469\n",
            "\t Max state 46.93654788028469\n",
            "Simulating episode 764\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.048602048131222\n",
            "\t Max state 27.048602048131222\n",
            "Simulating episode 765\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.921109795688443\n",
            "\t Max state 16.841109795688443\n",
            "Simulating episode 766\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 25.89747045904669\n",
            "\t Max state 25.917470459046694\n",
            "Simulating episode 767\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.159783673040868\n",
            "\t Max state 41.179783673040866\n",
            "Simulating episode 768\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.84139883154274\n",
            "\t Max state 60.74139883154274\n",
            "Simulating episode 769\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.7710345919340424\n",
            "\t Max state 4.7710345919340424\n",
            "Simulating episode 770\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1443212310235819\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.2672827216526485\n",
            "\t Max state 70.15728272165265\n",
            "Simulating episode 771\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1028888169787336\n",
            "\t Max state 49.00288881697873\n",
            "Simulating episode 772\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.5707728598005346\n",
            "\t Max state 26.55077285980053\n",
            "Simulating episode 773\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.957927016829087\n",
            "\t Max state 23.027927016829082\n",
            "Simulating episode 774\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.757530365617152\n",
            "\t Max state 36.76753036561715\n",
            "Simulating episode 775\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.672657302122772\n",
            "\t Max state 17.73265730212277\n",
            "Simulating episode 776\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.14174285447302085\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.2952105929631621\n",
            "\t Max state 40.39521059296316\n",
            "Simulating episode 777\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6539724024759497\n",
            "\t Max state 0.6639724024759497\n",
            "Simulating episode 778\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.70088971112099\n",
            "\t Max state 27.760889711121\n",
            "Simulating episode 779\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.14047099201277735\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.2787666698113547\n",
            "\t Max state 4.248766669811355\n",
            "Simulating episode 780\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.435247548144501\n",
            "\t Max state 30.215247548144504\n",
            "Simulating episode 781\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.3561997865672988\n",
            "\t Max state 3.0061997865672985\n",
            "Simulating episode 782\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1392105420087299\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.596174981759569\n",
            "\t Max state 38.91617498175957\n",
            "Simulating episode 783\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.306170973078483\n",
            "\t Max state 176.4561709730784\n",
            "Simulating episode 784\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1383765316515556\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.06869783468203913\n",
            "\t Max state 47.378697834682036\n",
            "Simulating episode 785\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13796140205660096\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.235069075333403\n",
            "\t Max state 17.615069075333402\n",
            "Simulating episode 786\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.34963587111636374\n",
            "\t Max state 47.519635871116364\n",
            "Simulating episode 787\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.36406605722623586\n",
            "\t Max state 7.294066057226233\n",
            "Simulating episode 788\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.897817911819659\n",
            "\t Max state 5.997817911819658\n",
            "Simulating episode 789\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13631330025897623\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.350776475745637\n",
            "\t Max state 13.830776475745637\n",
            "Simulating episode 790\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.315245998805288\n",
            "\t Max state 38.17524599880529\n",
            "Simulating episode 791\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1354966472771247\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.29675251639469413\n",
            "\t Max state 46.46675251639469\n",
            "Simulating episode 792\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.2942093690423295\n",
            "\t Max state 31.39420936904233\n",
            "Simulating episode 793\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.968238552125971\n",
            "\t Max state 17.66823855212597\n",
            "Simulating episode 794\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3948819421004456\n",
            "\t Max state 31.474881942100446\n",
            "Simulating episode 795\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13387798970608947\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.254220148744551\n",
            "\t Max state 35.574220148744544\n",
            "Simulating episode 796\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4160558711965099\n",
            "\t Max state 1.43605587119651\n",
            "Simulating episode 797\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13307592666976029\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.30453015382120907\n",
            "\t Max state 39.624530153821205\n",
            "Simulating episode 798\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4028776564547911\n",
            "\t Max state 13.412877656454791\n",
            "Simulating episode 799\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13227866879308176\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13227866879308176\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3595109513453095\n",
            "\t Max state 61.29951095134533\n",
            "Simulating episode 800\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4271668084359316\n",
            "\t Max state 30.877166808435934\n",
            "Simulating episode 801\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1314861872883424\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.299680042040581\n",
            "\t Max state 115.11968004204059\n",
            "Simulating episode 802\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.815142054097883\n",
            "\t Max state 45.805142054097885\n",
            "Simulating episode 803\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.13069845354029794\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3516052104545111\n",
            "\t Max state 27.12160521045449\n",
            "Simulating episode 804\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.43698580553735533\n",
            "\t Max state 44.70698580553736\n",
            "Simulating episode 805\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7854791784001836\n",
            "\t Max state 0.7854791784001836\n",
            "Simulating episode 806\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9815591681430639\n",
            "\t Max state 36.79155916814307\n",
            "Simulating episode 807\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.12913711570945913\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.0527771083829869\n",
            "\t Max state 66.34277710838299\n",
            "Simulating episode 808\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8674562900750971\n",
            "\t Max state 50.8674562900751\n",
            "Simulating episode 809\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.41032591876120716\n",
            "\t Max state 2.180325918761207\n",
            "Simulating episode 810\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.127978364883496\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.858495087080001\n",
            "\t Max state 46.05849508708\n",
            "Simulating episode 811\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4063229706232657\n",
            "\t Max state 0.8863229706232656\n",
            "Simulating episode 812\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.127211646499479\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.07255725842297772\n",
            "\t Max state 49.48255725842297\n",
            "Simulating episode 813\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.27787797631043176\n",
            "\t Max state 20.27787797631043\n",
            "Simulating episode 814\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.46124374335817286\n",
            "\t Max state 0.5012437433581729\n",
            "Simulating episode 815\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 19.60978610369422\n",
            "\t Max state 29.60978610369422\n",
            "Simulating episode 816\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.12569196244184253\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.18251408209462028\n",
            "\t Max state 20.18251408209462\n",
            "Simulating episode 817\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4075764142342633\n",
            "\t Max state 19.497576414234263\n",
            "Simulating episode 818\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.12493894189485345\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.46576747377355876\n",
            "\t Max state 19.835767473773558\n",
            "Simulating episode 819\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.433997160918523\n",
            "\t Max state 41.43399716091852\n",
            "Simulating episode 820\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.47457627118644063\n",
            "\t Min state 1.3305167367805968\n",
            "\t Max state 21.230516736780597\n",
            "Simulating episode 821\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1238178613958795\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.020855410115937\n",
            "\t Max state 23.79085541011594\n",
            "Simulating episode 822\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.07101441086252\n",
            "\t Max state 39.87101441086252\n",
            "Simulating episode 823\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4129704250841555\n",
            "\t Max state 10.512970425084156\n",
            "Simulating episode 824\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.960325994794502\n",
            "\t Max state 16.960325994794502\n",
            "Simulating episode 825\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6491032977399112\n",
            "\t Max state 12.649103297739911\n",
            "Simulating episode 826\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.591107478049761\n",
            "\t Max state 35.61110747804976\n",
            "Simulating episode 827\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.3195466777957439\n",
            "\t Max state 12.339546677795743\n",
            "Simulating episode 828\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3977173831180374\n",
            "\t Max state 32.177717383118036\n",
            "Simulating episode 829\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.12087724831120861\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.31759515218215\n",
            "\t Max state 36.31759515218215\n",
            "Simulating episode 830\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.37827621726997\n",
            "\t Max state 44.37827621726997\n",
            "Simulating episode 831\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 2.8299087956361717\n",
            "\t Max state 43.82990879563617\n",
            "Simulating episode 832\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11979261349842642\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.42651860578546574\n",
            "\t Max state 34.866518605785465\n",
            "Simulating episode 833\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.45547951582350144\n",
            "\t Max state 17.615479515823502\n",
            "Simulating episode 834\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3626591226721545\n",
            "\t Max state 20.422659122672155\n",
            "Simulating episode 835\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5008044461946063\n",
            "\t Max state 38.0208044461946\n",
            "Simulating episode 836\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11836155800967517\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.054028921086683\n",
            "\t Max state 49.05402892108668\n",
            "Simulating episode 837\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5051811461924774\n",
            "\t Max state 11.235181146192478\n",
            "Simulating episode 838\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5307943693986249\n",
            "\t Max state 30.650794369398625\n",
            "Simulating episode 839\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.054476943688023916\n",
            "\t Max state 40.014476943688024\n",
            "Simulating episode 840\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.12317454489467039\n",
            "\t Max state 44.32317454489467\n",
            "Simulating episode 841\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11659675527003792\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.56847870637546\n",
            "\t Max state 16.42847870637546\n",
            "Simulating episode 842\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.433297320058536\n",
            "\t Max state 48.41329732005853\n",
            "Simulating episode 843\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11589822410921512\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.72892369988535\n",
            "\t Max state 37.328923699885344\n",
            "Simulating episode 844\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 27.834391437686357\n",
            "\t Max state 37.83439143768636\n",
            "Simulating episode 845\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.3239161056611835\n",
            "\t Max state 36.32391610566118\n",
            "Simulating episode 846\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.16426456938161538\n",
            "\t Max state 31.464264569381616\n",
            "Simulating episode 847\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.353063481740683\n",
            "\t Max state 19.353063481740683\n",
            "Simulating episode 848\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11417015034213682\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11417015034213682\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11417015034213682\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.17257426585558266\n",
            "\t Max state 37.48257426585558\n",
            "Simulating episode 849\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1138276398911104\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.1091847719147819\n",
            "\t Max state 15.829184771914779\n",
            "Simulating episode 850\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.03355316898328731\n",
            "\t Max state 20.043553168983287\n",
            "Simulating episode 851\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.209583904468287\n",
            "\t Max state 34.21958390446829\n",
            "Simulating episode 852\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.23068456130577886\n",
            "\t Max state 28.26068456130578\n",
            "Simulating episode 853\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.0228225996400582\n",
            "\t Max state 11.022822599640058\n",
            "Simulating episode 854\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11213043909294372\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.3202414556209092\n",
            "\t Max state 43.32024145562091\n",
            "Simulating episode 855\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11179404777566489\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.2935026427586209\n",
            "\t Max state 11.08350264275862\n",
            "Simulating episode 856\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.865263971370647\n",
            "\t Max state 46.905263971370644\n",
            "Simulating episode 857\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.04805807587676\n",
            "\t Max state 47.04805807587676\n",
            "Simulating episode 858\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.11079091676653456\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7467928832011381\n",
            "\t Max state 39.146792883201144\n",
            "Simulating episode 859\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5027947768987217\n",
            "\t Max state 34.55279477689872\n",
            "Simulating episode 860\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.0999224451521677\n",
            "\t Max state 30.65992244515217\n",
            "Simulating episode 861\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1097967868790337\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.36601159751678636\n",
            "\t Max state 32.096011597516785\n",
            "Simulating episode 862\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.24317026713245005\n",
            "\t Max state 15.34317026713245\n",
            "Simulating episode 863\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1091389943288414\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4145983425346028\n",
            "\t Max state 19.304598342534604\n",
            "Simulating episode 864\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10881157734585488\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.2848629804072531\n",
            "\t Max state 18.224862980407252\n",
            "Simulating episode 865\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1010011678938074\n",
            "\t Max state 22.30100116789381\n",
            "Simulating episode 866\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10815968718597585\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 1.8734738593183238\n",
            "\t Max state 108.72347385931835\n",
            "Simulating episode 867\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49056603773584906\n",
            "\t Min state 0.18715409535202118\n",
            "\t Max state 1.3971540953520212\n",
            "Simulating episode 868\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10751170250004467\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.777064140537995\n",
            "\t Max state 106.077064140538\n",
            "Simulating episode 869\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10718916739254454\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.169627380936529\n",
            "\t Max state 40.8896273809365\n",
            "Simulating episode 870\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 23.64692129288038\n",
            "\t Max state 33.64692129288038\n",
            "Simulating episode 871\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10654699709069582\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.495082827001122\n",
            "\t Max state 98.76508282700108\n",
            "Simulating episode 872\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5014029532339734\n",
            "\t Max state 32.07140295323398\n",
            "Simulating episode 873\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10590867403112546\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10590867403112546\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.688657451696141\n",
            "\t Max state 231.8086574516962\n",
            "Simulating episode 874\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.432604632263807\n",
            "\t Max state 24.732604632263808\n",
            "Simulating episode 875\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 11.570999937575532\n",
            "\t Max state 17.460999937575544\n",
            "Simulating episode 876\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10495835263950998\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.10218196544824\n",
            "\t Max state 33.412181965448276\n",
            "Simulating episode 877\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.432903372333843\n",
            "\t Max state 45.15290337233384\n",
            "Simulating episode 878\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10432954714884668\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8115949301000693\n",
            "\t Max state 15.581594930100062\n",
            "Simulating episode 879\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10401655850740014\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.014391199708098101\n",
            "\t Max state 15.444391199708093\n",
            "Simulating episode 880\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.0015900846417502557\n",
            "\t Max state 26.61159008464176\n",
            "Simulating episode 881\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1033933953053823\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.10582485649392082\n",
            "\t Max state 10.705824856493917\n",
            "Simulating episode 882\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.86241646757194\n",
            "\t Max state 31.812416467571946\n",
            "Simulating episode 883\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10277396547410775\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.76955021554327\n",
            "\t Max state 169.4395502155433\n",
            "Simulating episode 884\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10246564357768542\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 44.55975364049208\n",
            "\t Max state 144.6697536404921\n",
            "Simulating episode 885\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 35.797230122201\n",
            "\t Max state 234.897230122201\n",
            "Simulating episode 886\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1018517719070115\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.620039543235922\n",
            "\t Max state 150.83003954323596\n",
            "Simulating episode 887\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 43.53063081126618\n",
            "\t Max state 285.8006308112661\n",
            "Simulating episode 888\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1012415779415166\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.1012415779415166\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.89931220614746\n",
            "\t Max state 65.70931220614739\n",
            "Simulating episode 889\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6430424818192684\n",
            "\t Max state 13.843042481819268\n",
            "Simulating episode 890\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6738519344649123\n",
            "\t Max state 22.803851934464912\n",
            "Simulating episode 891\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.10033313452912476\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.14708908861149927\n",
            "\t Max state 22.2470890886115\n",
            "Simulating episode 892\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8268849782806357\n",
            "\t Max state 42.876884978280636\n",
            "Simulating episode 893\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.832326385698556\n",
            "\t Max state 6.832326385698556\n",
            "Simulating episode 894\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0994328426040003\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.726481054551337\n",
            "\t Max state 45.71648105455134\n",
            "Simulating episode 895\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.344008981252026\n",
            "\t Max state 7.344008981252026\n",
            "Simulating episode 896\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09883714044395973\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.358758658047172\n",
            "\t Max state 45.138758658047166\n",
            "Simulating episode 897\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.253523960472805\n",
            "\t Max state 107.83352396047277\n",
            "Simulating episode 898\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09824500713555996\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 28.821444535665456\n",
            "\t Max state 117.45144453566546\n",
            "Simulating episode 899\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 41.29930348947553\n",
            "\t Max state 42.29930348947553\n",
            "Simulating episode 900\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09765642129781081\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.025232206886585\n",
            "\t Max state 246.01523220688657\n",
            "Simulating episode 901\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.385716839987026\n",
            "\t Max state 24.855716839987025\n",
            "Simulating episode 902\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09707136167781562\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8278834692899826\n",
            "\t Max state 28.237883469290008\n",
            "Simulating episode 903\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09678014759278217\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 7.613452448780855\n",
            "\t Max state 46.26345244878091\n",
            "Simulating episode 904\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 33.06494080159223\n",
            "\t Max state 33.16494080159223\n",
            "Simulating episode 905\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5077096703349626\n",
            "\t Max state 5.7377096703349615\n",
            "Simulating episode 906\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.915687104860588\n",
            "\t Max state 32.45568710486059\n",
            "Simulating episode 907\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.817902002546443\n",
            "\t Max state 5.817902002546443\n",
            "Simulating episode 908\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09533712950070637\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09533712950070637\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.22264990576464827\n",
            "\t Max state 32.46264990576465\n",
            "Simulating episode 909\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.93288774527597\n",
            "\t Max state 26.042887745275973\n",
            "Simulating episode 910\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.098614745380079\n",
            "\t Max state 18.09861474538008\n",
            "Simulating episode 911\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09448166686359404\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.279904711274906\n",
            "\t Max state 35.93990471127489\n",
            "Simulating episode 912\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 17.710104211747318\n",
            "\t Max state 29.460104211747336\n",
            "Simulating episode 913\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09391562719741424\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.605150808941826\n",
            "\t Max state 23.765150808941836\n",
            "Simulating episode 914\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.093633880315822\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.093633880315822\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.18129107707496\n",
            "\t Max state 56.001291077074974\n",
            "Simulating episode 915\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.895251540228501\n",
            "\t Max state 4.095251540228501\n",
            "Simulating episode 916\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 14.238450540221821\n",
            "\t Max state 15.238450540221821\n",
            "Simulating episode 917\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09279370097963337\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.15973124474479658\n",
            "\t Max state 1.1997312447447965\n",
            "Simulating episode 918\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09251531987669447\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09251531987669447\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.07255395723601493\n",
            "\t Max state 32.612553957235995\n",
            "Simulating episode 919\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 1.1782191440236955\n",
            "\t Max state 1.2482191440236956\n",
            "Simulating episode 920\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09196106059531318\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.407361872262554\n",
            "\t Max state 33.23736187226257\n",
            "Simulating episode 921\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09168517741352725\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 21.783680846269572\n",
            "\t Max state 224.27368084626949\n",
            "Simulating episode 922\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.71004686836421\n",
            "\t Max state 20.94004686836419\n",
            "Simulating episode 923\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0911358915156428\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 42.660152846714375\n",
            "\t Max state 54.730152846714276\n",
            "Simulating episode 924\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.914317544630272\n",
            "\t Max state 27.314317544630278\n",
            "Simulating episode 925\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09058989638957259\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.323453863929934\n",
            "\t Max state 15.323453863929934\n",
            "Simulating episode 926\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 37.15416317807895\n",
            "\t Max state 37.354163178078956\n",
            "Simulating episode 927\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.09004717232030265\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.575950531003159\n",
            "\t Max state 29.985950531003137\n",
            "Simulating episode 928\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08977703080334175\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.214375545224385\n",
            "\t Max state 75.41437554522432\n",
            "Simulating episode 929\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08950769971093173\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.487511410668546\n",
            "\t Max state 268.93751141066866\n",
            "Simulating episode 930\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08923917661179893\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08923917661179893\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 26.366457878555714\n",
            "\t Max state 49.49645787855576\n",
            "Simulating episode 931\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08897145908196354\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 33.798219819345285\n",
            "\t Max state 54.60821981934532\n",
            "Simulating episode 932\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 16.305901934802986\n",
            "\t Max state 21.32590193480299\n",
            "Simulating episode 933\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 31.492789675944184\n",
            "\t Max state 50.472789675944185\n",
            "Simulating episode 934\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08817311577739169\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08817311577739169\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 15.206955767739249\n",
            "\t Max state 55.92695576773929\n",
            "Simulating episode 935\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08790859643005951\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08790859643005951\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08790859643005951\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08790859643005951\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08790859643005951\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.1441940082951962\n",
            "\t Max state 267.04419400829516\n",
            "Simulating episode 936\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.42951241672812923\n",
            "\t Max state 1.4295124167281292\n",
            "Simulating episode 937\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08738193602884702\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08738193602884702\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.18716047004411115\n",
            "\t Max state 42.28716047004425\n",
            "Simulating episode 938\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.215758193856189\n",
            "\t Max state 9.215758193856189\n",
            "Simulating episode 939\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.882594035293842\n",
            "\t Max state 49.88259403529384\n",
            "Simulating episode 940\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.1315897825525369\n",
            "\t Max state 10.531589782552537\n",
            "Simulating episode 941\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08633806199087525\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.14462231180866233\n",
            "\t Max state 10.484622311808662\n",
            "Simulating episode 942\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08607904780490262\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.03846184170861734\n",
            "\t Max state 42.128461841708614\n",
            "Simulating episode 943\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.36402425139845\n",
            "\t Max state 37.56402425139845\n",
            "Simulating episode 944\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08556334822950346\n",
            "\t Max of rewards 0.45161290322580644\n",
            "\t Min state 2.082653639366542\n",
            "\t Max state 27.192653639366533\n",
            "Simulating episode 945\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08530665818481495\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 30.285909343415135\n",
            "\t Max state 67.98590934341516\n",
            "Simulating episode 946\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 18.67256949128556\n",
            "\t Max state 28.67256949128556\n",
            "Simulating episode 947\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08479558599562972\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.12726860669782\n",
            "\t Max state 234.25726860669775\n",
            "Simulating episode 948\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08454119923764283\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.582913089068523\n",
            "\t Max state 46.422913089068686\n",
            "Simulating episode 949\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0842875756399299\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0842875756399299\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 22.825316840867263\n",
            "\t Max state 45.935316840867316\n",
            "Simulating episode 950\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08403471291301011\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.3458082728514285\n",
            "\t Max state 65.34580827285143\n",
            "Simulating episode 951\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08378260877427107\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08378260877427107\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 5.015359298154182\n",
            "\t Max state 222.06535929815425\n",
            "Simulating episode 952\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08353126094794826\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.918087244889875\n",
            "\t Max state 50.35808724488981\n",
            "Simulating episode 953\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08328066716510442\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08328066716510442\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 29.361823337180667\n",
            "\t Max state 169.95182333718077\n",
            "Simulating episode 954\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0830308251636091\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.08627472147746947\n",
            "\t Max state 18.55627472147747\n",
            "Simulating episode 955\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08278173268811827\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.117944469179726\n",
            "\t Max state 64.00794446917973\n",
            "Simulating episode 956\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.3916429023898198\n",
            "\t Max state 4.39164290238982\n",
            "Simulating episode 957\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 24.850899058081122\n",
            "\t Max state 26.850899058081122\n",
            "Simulating episode 958\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.082038929965601\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.082038929965601\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.0976834109643291\n",
            "\t Max state 57.29768341096433\n",
            "Simulating episode 959\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.4249454872753997\n",
            "\t Max state 31.4349454872754\n",
            "Simulating episode 960\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.316575407700961\n",
            "\t Max state 36.41657540770096\n",
            "Simulating episode 961\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.268020281594763\n",
            "\t Max state 0.298020281594763\n",
            "Simulating episode 962\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.5311386142093846\n",
            "\t Max state 0.7011386142093845\n",
            "Simulating episode 963\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 32.84953611928151\n",
            "\t Max state 68.65953611928151\n",
            "Simulating episode 964\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0805732602803011\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 36.583654314836\n",
            "\t Max state 426.6536543148361\n",
            "Simulating episode 965\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.334299033175617\n",
            "\t Max state 30.90429903317563\n",
            "Simulating episode 966\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.08009054587796181\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 12.755833966895153\n",
            "\t Max state 43.545833966895145\n",
            "Simulating episode 967\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07985027424032792\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.1411522985494393\n",
            "\t Max state 23.671152298549455\n",
            "Simulating episode 968\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07961072341760694\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.7533374417886929\n",
            "\t Max state 73.87333744178869\n",
            "Simulating episode 969\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07937189124735412\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07937189124735412\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 3.496550730675691\n",
            "\t Max state 26.666550730675702\n",
            "Simulating episode 970\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07913377557361206\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.239928287409372\n",
            "\t Max state 69.60992828740933\n",
            "Simulating episode 971\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4827586206896552\n",
            "\t Min state 0.9429723035897009\n",
            "\t Max state 11.132972303589701\n",
            "Simulating episode 972\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07865968512415054\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.10812528708671\n",
            "\t Max state 176.2181252870867\n",
            "Simulating episode 973\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07842370606877809\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 35.572829126448966\n",
            "\t Max state 206.082829126449\n",
            "Simulating episode 974\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 45.625144739957776\n",
            "\t Max state 45.93514473995778\n",
            "Simulating episode 975\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 38.01305028631746\n",
            "\t Max state 58.21305028631746\n",
            "Simulating episode 976\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07772000803678288\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.5609517971541109\n",
            "\t Max state 21.40095179715411\n",
            "Simulating episode 977\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07748684801267253\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.336169916432282\n",
            "\t Max state 90.28616991643234\n",
            "Simulating episode 978\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07725438746863451\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.037317144034890525\n",
            "\t Max state 15.557317144034892\n",
            "Simulating episode 979\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.030130899778177\n",
            "\t Max state 20.540130899778163\n",
            "Simulating episode 980\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07679155643330993\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07679155643330993\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.035046909414610194\n",
            "\t Max state 10.505046909414606\n",
            "Simulating episode 981\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.18690446038548503\n",
            "\t Max state 2.196904460385485\n",
            "Simulating episode 982\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 20.33359448937255\n",
            "\t Max state 20.833594489372558\n",
            "Simulating episode 983\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.31067863348475555\n",
            "\t Max state 21.42067863348476\n",
            "Simulating episode 984\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07587419621288963\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 46.82115631814787\n",
            "\t Max state 100.83115631814788\n",
            "Simulating episode 985\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.030553759737925963\n",
            "\t Max state 49.70055375973793\n",
            "Simulating episode 986\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0754196339033782\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.368305611759264\n",
            "\t Max state 41.068305611759264\n",
            "Simulating episode 987\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07519337500166808\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07519337500166808\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.00890936463734\n",
            "\t Max state 103.4289093646373\n",
            "Simulating episode 988\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07496779487666307\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07496779487666307\n",
            "\t Max of rewards 0.5\n",
            "\t Min state 0.6242408465566807\n",
            "\t Max state 57.634240846556715\n",
            "Simulating episode 989\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.5185185185185186\n",
            "\t Min state 0.31891879585974325\n",
            "\t Max state 60.96891879585974\n",
            "Simulating episode 990\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07451866281755698\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 10.79575407077748\n",
            "\t Max state 109.45575407077749\n",
            "Simulating episode 991\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07429510682910431\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.249774350659868\n",
            "\t Max state 60.00977435065986\n",
            "Simulating episode 992\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 8.233419575431679\n",
            "\t Max state 24.16341957543168\n",
            "Simulating episode 993\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07385000484409115\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07385000484409115\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 4.781600790012771\n",
            "\t Max state 160.21160079001262\n",
            "Simulating episode 994\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07362845482955888\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07362845482955888\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07362845482955888\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07362845482955888\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 34.07129858393916\n",
            "\t Max state 225.51129858393926\n",
            "Simulating episode 995\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.0734075694650702\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.8484285040279396\n",
            "\t Max state 30.24842850402793\n",
            "Simulating episode 996\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.49122807017543857\n",
            "\t Min state 0.6622993049131176\n",
            "\t Max state 28.562299304913115\n",
            "Simulating episode 997\n",
            "\t Fist train of main network...\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 6.822269716922506\n",
            "\t Max state 27.832269716922507\n",
            "Simulating episode 998\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07274888136225574\n",
            "\t Max of rewards 0.4444444444444445\n",
            "\t Min state 9.5140364375643\n",
            "\t Max state 11.5140364375643\n",
            "Simulating episode 999\n",
            "\t Fist train of main network...\n",
            "\t\t [UPDATED] Target network\n",
            "\t\t Current epsilon: 0.07253063471816898\n",
            "\t Max of rewards 0.509090909090909\n",
            "\t Min state 0.28553415020423367\n",
            "\t Max state 34.87553415020423\n",
            "CPU times: total: 9h 21min 14s\n",
            "Wall time: 8h 16min 38s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "LearningQDeep.trainingEpisodes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "LearningQDeep.mainNetwork.save('Trained_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "loaded_model = LearningQDeep.mainNetwork"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "actions_str = {0 : '----', 1 : '---', 2 : '--', 3 : '-', 4 : '0', 5 : '+', 6 : '++',  7 : '+++',8: '++++'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ 0.4444444444444445 [5.01]\n",
            "+ 0.4444444444444445 [5.02]\n",
            "+ 0.4444444444444445 [5.03]\n",
            "+ 0.4444444444444445 [5.04]\n",
            "+ 0.4444444444444445 [5.05]\n",
            "+ 0.4444444444444445 [5.06]\n",
            "+ 0.4444444444444445 [5.07]\n",
            "+ 0.4444444444444445 [5.08]\n",
            "+ 0.4444444444444445 [5.09]\n",
            "+ 0.4444444444444445 [5.1]\n",
            "+ 0.4444444444444445 [5.11]\n",
            "+ 0.4444444444444445 [5.12]\n",
            "+ 0.4444444444444445 [5.13]\n",
            "+ 0.4444444444444445 [5.14]\n",
            "+ 0.4444444444444445 [5.15]\n",
            "+ 0.4444444444444445 [5.16]\n",
            "+ 0.4444444444444445 [5.17]\n",
            "+ 0.4444444444444445 [5.18]\n",
            "+ 0.4444444444444445 [5.19]\n",
            "+ 0.4444444444444445 [5.2]\n",
            "+ 0.4444444444444445 [5.21]\n",
            "+ 0.4444444444444445 [5.22]\n",
            "+ 0.4444444444444445 [5.23]\n",
            "+ 0.4444444444444445 [5.24]\n",
            "+ 0.4444444444444445 [5.25]\n",
            "+ 0.4444444444444445 [5.26]\n",
            "+ 0.4444444444444445 [5.27]\n",
            "+ 0.4444444444444445 [5.28]\n",
            "+ 0.4444444444444445 [5.29]\n",
            "+ 0.4444444444444445 [5.3]\n",
            "+ 0.4444444444444445 [5.31]\n",
            "+ 0.4444444444444445 [5.32]\n",
            "+ 0.4444444444444445 [5.33]\n",
            "+ 0.4444444444444445 [5.34]\n",
            "+ 0.4444444444444445 [5.35]\n",
            "+ 0.4444444444444445 [5.36]\n",
            "+ 0.4444444444444445 [5.37]\n",
            "+ 0.4444444444444445 [5.38]\n",
            "+ 0.4444444444444445 [5.39]\n",
            "+ 0.4444444444444445 [5.4]\n",
            "+ 0.4444444444444445 [5.41]\n",
            "+ 0.4444444444444445 [5.42]\n",
            "+ 0.4444444444444445 [5.43]\n",
            "+ 0.4444444444444445 [5.44]\n",
            "+ 0.4444444444444445 [5.45]\n",
            "+ 0.4444444444444445 [5.46]\n",
            "+ 0.4444444444444445 [5.47]\n",
            "+ 0.4444444444444445 [5.48]\n",
            "+ 0.4444444444444445 [5.49]\n",
            "+ 0.4444444444444445 [5.5]\n",
            "+ 0.4444444444444445 [5.51]\n",
            "+ 0.4444444444444445 [5.52]\n",
            "+ 0.4444444444444445 [5.53]\n",
            "+ 0.4444444444444445 [5.54]\n",
            "+ 0.4444444444444445 [5.55]\n",
            "+ 0.4444444444444445 [5.56]\n",
            "+ 0.4444444444444445 [5.57]\n",
            "+ 0.4444444444444445 [5.58]\n",
            "+ 0.4444444444444445 [5.59]\n",
            "+ 0.4444444444444445 [5.6]\n",
            "+ 0.4444444444444445 [5.61]\n",
            "+ 0.4444444444444445 [5.62]\n",
            "+ 0.4444444444444445 [5.63]\n",
            "+ 0.4444444444444445 [5.64]\n",
            "+ 0.4444444444444445 [5.65]\n",
            "+ 0.4444444444444445 [5.66]\n",
            "+ 0.4444444444444445 [5.67]\n",
            "+ 0.4444444444444445 [5.68]\n",
            "+ 0.4444444444444445 [5.69]\n",
            "+ 0.4444444444444445 [5.7]\n",
            "+ 0.4444444444444445 [5.71]\n",
            "+ 0.4444444444444445 [5.72]\n",
            "+ 0.4444444444444445 [5.73]\n",
            "+ 0.4444444444444445 [5.74]\n",
            "+ 0.4444444444444445 [5.75]\n",
            "+ 0.4444444444444445 [5.76]\n",
            "+ 0.4444444444444445 [5.77]\n",
            "+ 0.4444444444444445 [5.78]\n",
            "+ 0.4444444444444445 [5.79]\n",
            "+ 0.4444444444444445 [5.8]\n",
            "+ 0.4444444444444445 [5.81]\n",
            "+ 0.4444444444444445 [5.82]\n",
            "+ 0.4444444444444445 [5.83]\n",
            "+ 0.4444444444444445 [5.84]\n",
            "+ 0.4444444444444445 [5.85]\n",
            "+ 0.4444444444444445 [5.86]\n",
            "+ 0.4444444444444445 [5.87]\n",
            "+ 0.4444444444444445 [5.88]\n",
            "+ 0.4444444444444445 [5.89]\n",
            "+ 0.4444444444444445 [5.9]\n",
            "+ 0.4444444444444445 [5.91]\n",
            "+ 0.4444444444444445 [5.92]\n",
            "+ 0.4444444444444445 [5.93]\n",
            "+ 0.4444444444444445 [5.94]\n",
            "+ 0.4444444444444445 [5.95]\n",
            "+ 0.4444444444444445 [5.96]\n",
            "+ 0.4444444444444445 [5.97]\n",
            "+ 0.4444444444444445 [5.98]\n",
            "+ 0.4444444444444445 [5.99]\n",
            "+ 0.4444444444444445 [6.]\n",
            "+ 0.4444444444444445 [6.01]\n",
            "+ 0.4444444444444445 [6.02]\n",
            "+ 0.4444444444444445 [6.03]\n",
            "+ 0.4444444444444445 [6.04]\n",
            "+ 0.4444444444444445 [6.05]\n",
            "+ 0.4444444444444445 [6.06]\n",
            "+ 0.4444444444444445 [6.07]\n",
            "+ 0.4444444444444445 [6.08]\n",
            "+ 0.4444444444444445 [6.09]\n",
            "+ 0.4444444444444445 [6.1]\n",
            "+ 0.4444444444444445 [6.11]\n",
            "+ 0.4444444444444445 [6.12]\n",
            "+ 0.4444444444444445 [6.13]\n",
            "+ 0.4444444444444445 [6.14]\n",
            "+ 0.4444444444444445 [6.15]\n",
            "+ 0.4444444444444445 [6.16]\n",
            "+ 0.4444444444444445 [6.17]\n",
            "+ 0.4444444444444445 [6.18]\n",
            "+ 0.4444444444444445 [6.19]\n",
            "+ 0.4444444444444445 [6.2]\n",
            "+ 0.4444444444444445 [6.21]\n",
            "+ 0.4444444444444445 [6.22]\n",
            "+ 0.4444444444444445 [6.23]\n",
            "+ 0.4444444444444445 [6.24]\n",
            "+ 0.4444444444444445 [6.25]\n",
            "+ 0.4444444444444445 [6.26]\n",
            "+ 0.4444444444444445 [6.27]\n",
            "+ 0.4444444444444445 [6.28]\n",
            "+ 0.4444444444444445 [6.29]\n",
            "+ 0.4444444444444445 [6.3]\n",
            "+ 0.4444444444444445 [6.31]\n",
            "+ 0.4444444444444445 [6.32]\n",
            "+ 0.4444444444444445 [6.33]\n",
            "+ 0.4444444444444445 [6.34]\n",
            "+ 0.4444444444444445 [6.35]\n",
            "+ 0.4444444444444445 [6.36]\n",
            "+ 0.4444444444444445 [6.37]\n",
            "+ 0.4444444444444445 [6.38]\n",
            "+ 0.4444444444444445 [6.39]\n",
            "+ 0.4444444444444445 [6.4]\n",
            "+ 0.4444444444444445 [6.41]\n",
            "+ 0.4444444444444445 [6.42]\n",
            "+ 0.4444444444444445 [6.43]\n",
            "+ 0.4444444444444445 [6.44]\n",
            "+ 0.4444444444444445 [6.45]\n",
            "+ 0.4444444444444445 [6.46]\n",
            "+ 0.4444444444444445 [6.47]\n",
            "+ 0.4444444444444445 [6.48]\n",
            "+ 0.4444444444444445 [6.49]\n",
            "+ 0.4444444444444445 [6.5]\n",
            "+ 0.4444444444444445 [6.51]\n",
            "+ 0.4444444444444445 [6.52]\n",
            "+ 0.4444444444444445 [6.53]\n",
            "+ 0.4444444444444445 [6.54]\n",
            "+ 0.4444444444444445 [6.55]\n",
            "+ 0.4444444444444445 [6.56]\n",
            "+ 0.4444444444444445 [6.57]\n",
            "+ 0.4444444444444445 [6.58]\n",
            "+ 0.4444444444444445 [6.59]\n",
            "+ 0.4444444444444445 [6.6]\n",
            "+ 0.4444444444444445 [6.61]\n",
            "+ 0.4444444444444445 [6.62]\n",
            "+ 0.4444444444444445 [6.63]\n",
            "+ 0.4444444444444445 [6.64]\n",
            "+ 0.4444444444444445 [6.65]\n",
            "+ 0.4444444444444445 [6.66]\n",
            "+ 0.4444444444444445 [6.67]\n",
            "+ 0.4444444444444445 [6.68]\n",
            "+ 0.4444444444444445 [6.69]\n",
            "+ 0.4444444444444445 [6.7]\n",
            "+ 0.4444444444444445 [6.71]\n",
            "+ 0.4444444444444445 [6.72]\n",
            "+ 0.4444444444444445 [6.73]\n",
            "+ 0.4444444444444445 [6.74]\n",
            "+ 0.4444444444444445 [6.75]\n",
            "+ 0.4444444444444445 [6.76]\n",
            "+ 0.4444444444444445 [6.77]\n",
            "+ 0.4444444444444445 [6.78]\n",
            "+ 0.4444444444444445 [6.79]\n",
            "+ 0.4444444444444445 [6.8]\n",
            "+ 0.4444444444444445 [6.81]\n",
            "+ 0.4444444444444445 [6.82]\n",
            "+ 0.4444444444444445 [6.83]\n",
            "+ 0.4444444444444445 [6.84]\n",
            "+ 0.4444444444444445 [6.85]\n",
            "+ 0.4444444444444445 [6.86]\n",
            "+ 0.4444444444444445 [6.87]\n",
            "+ 0.4444444444444445 [6.88]\n",
            "+ 0.4444444444444445 [6.89]\n",
            "+ 0.4444444444444445 [6.9]\n",
            "+ 0.4444444444444445 [6.91]\n",
            "+ 0.4444444444444445 [6.92]\n",
            "+ 0.4444444444444445 [6.93]\n",
            "+ 0.4444444444444445 [6.94]\n",
            "+ 0.4444444444444445 [6.95]\n",
            "+ 0.4444444444444445 [6.96]\n",
            "+ 0.4444444444444445 [6.97]\n",
            "+ 0.4444444444444445 [6.98]\n",
            "+ 0.4444444444444445 [6.99]\n",
            "+ 0.4444444444444445 [7.]\n",
            "+ 0.4444444444444445 [7.01]\n",
            "+ 0.4444444444444445 [7.02]\n",
            "+ 0.4444444444444445 [7.03]\n",
            "+ 0.4444444444444445 [7.04]\n",
            "+ 0.4444444444444445 [7.05]\n",
            "+ 0.4444444444444445 [7.06]\n",
            "+ 0.4444444444444445 [7.07]\n",
            "+ 0.4444444444444445 [7.08]\n",
            "+ 0.4444444444444445 [7.09]\n",
            "+ 0.4444444444444445 [7.1]\n",
            "+ 0.4444444444444445 [7.11]\n",
            "+ 0.4444444444444445 [7.12]\n",
            "+ 0.4444444444444445 [7.13]\n",
            "+ 0.4444444444444445 [7.14]\n",
            "+ 0.4444444444444445 [7.15]\n",
            "+ 0.4444444444444445 [7.16]\n",
            "+ 0.4444444444444445 [7.17]\n",
            "+ 0.4444444444444445 [7.18]\n",
            "+ 0.4444444444444445 [7.19]\n",
            "+ 0.4444444444444445 [7.2]\n",
            "+ 0.4444444444444445 [7.21]\n",
            "+ 0.4444444444444445 [7.22]\n",
            "+ 0.4444444444444445 [7.23]\n",
            "+ 0.4444444444444445 [7.24]\n",
            "+ 0.4444444444444445 [7.25]\n",
            "+ 0.4444444444444445 [7.26]\n",
            "+ 0.4444444444444445 [7.27]\n",
            "+ 0.4444444444444445 [7.28]\n",
            "+ 0.4444444444444445 [7.29]\n",
            "+ 0.4444444444444445 [7.3]\n",
            "+ 0.4444444444444445 [7.31]\n",
            "+ 0.4444444444444445 [7.32]\n",
            "+ 0.4444444444444445 [7.33]\n",
            "+ 0.4444444444444445 [7.34]\n",
            "+ 0.4444444444444445 [7.35]\n",
            "+ 0.4444444444444445 [7.36]\n",
            "+ 0.4444444444444445 [7.37]\n",
            "+ 0.4444444444444445 [7.38]\n",
            "+ 0.4444444444444445 [7.39]\n",
            "+ 0.4444444444444445 [7.4]\n",
            "+ 0.4444444444444445 [7.41]\n",
            "+ 0.4444444444444445 [7.42]\n",
            "+ 0.4444444444444445 [7.43]\n",
            "+ 0.4444444444444445 [7.44]\n",
            "+ 0.4444444444444445 [7.45]\n",
            "+ 0.4444444444444445 [7.46]\n",
            "+ 0.4444444444444445 [7.47]\n",
            "+ 0.4444444444444445 [7.48]\n",
            "+ 0.4444444444444445 [7.49]\n",
            "+ 0.4444444444444445 [7.5]\n",
            "+ 0.4444444444444445 [7.51]\n",
            "+ 0.4444444444444445 [7.52]\n",
            "+ 0.4444444444444445 [7.53]\n",
            "+ 0.4444444444444445 [7.54]\n",
            "+ 0.4444444444444445 [7.55]\n",
            "+ 0.4444444444444445 [7.56]\n",
            "+ 0.4444444444444445 [7.57]\n",
            "+ 0.4444444444444445 [7.58]\n",
            "+ 0.4444444444444445 [7.59]\n",
            "+ 0.4444444444444445 [7.6]\n",
            "+ 0.4444444444444445 [7.61]\n",
            "+ 0.4444444444444445 [7.62]\n",
            "+ 0.4444444444444445 [7.63]\n",
            "+ 0.4444444444444445 [7.64]\n",
            "+ 0.4444444444444445 [7.65]\n",
            "+ 0.4444444444444445 [7.66]\n",
            "+ 0.4444444444444445 [7.67]\n",
            "+ 0.4444444444444445 [7.68]\n",
            "+ 0.4444444444444445 [7.69]\n",
            "+ 0.4444444444444445 [7.7]\n",
            "+ 0.4444444444444445 [7.71]\n",
            "+ 0.4444444444444445 [7.72]\n",
            "+ 0.4444444444444445 [7.73]\n",
            "+ 0.4444444444444445 [7.74]\n",
            "+ 0.4444444444444445 [7.75]\n",
            "+ 0.4444444444444445 [7.76]\n",
            "+ 0.4444444444444445 [7.77]\n",
            "+ 0.4444444444444445 [7.78]\n",
            "+ 0.4444444444444445 [7.79]\n",
            "+ 0.4444444444444445 [7.8]\n",
            "+ 0.4444444444444445 [7.81]\n",
            "+ 0.4444444444444445 [7.82]\n",
            "+ 0.4444444444444445 [7.83]\n",
            "+ 0.4444444444444445 [7.84]\n",
            "+ 0.4444444444444445 [7.85]\n",
            "+ 0.4444444444444445 [7.86]\n",
            "+ 0.4444444444444445 [7.87]\n",
            "+ 0.4444444444444445 [7.88]\n",
            "+ 0.4444444444444445 [7.89]\n",
            "+ 0.4444444444444445 [7.9]\n",
            "+ 0.4444444444444445 [7.91]\n",
            "+ 0.4444444444444445 [7.92]\n",
            "+ 0.4444444444444445 [7.93]\n",
            "+ 0.4444444444444445 [7.94]\n",
            "+ 0.4444444444444445 [7.95]\n",
            "+ 0.4444444444444445 [7.96]\n",
            "+ 0.4444444444444445 [7.97]\n",
            "+ 0.4444444444444445 [7.98]\n",
            "+ 0.4444444444444445 [7.99]\n",
            "+ 0.4444444444444445 [8.]\n",
            "+ 0.4444444444444445 [8.01]\n",
            "+ 0.4444444444444445 [8.02]\n",
            "+ 0.4444444444444445 [8.03]\n",
            "+ 0.4444444444444445 [8.04]\n",
            "+ 0.4444444444444445 [8.05]\n",
            "+ 0.4444444444444445 [8.06]\n",
            "+ 0.4444444444444445 [8.07]\n",
            "+ 0.4444444444444445 [8.08]\n",
            "+ 0.4444444444444445 [8.09]\n",
            "+ 0.4444444444444445 [8.1]\n",
            "+ 0.4444444444444445 [8.11]\n",
            "+ 0.4444444444444445 [8.12]\n",
            "+ 0.4444444444444445 [8.13]\n",
            "+ 0.4444444444444445 [8.14]\n",
            "+ 0.4444444444444445 [8.15]\n",
            "+ 0.4444444444444445 [8.16]\n",
            "+ 0.4444444444444445 [8.17]\n",
            "+ 0.4444444444444445 [8.18]\n",
            "+ 0.4444444444444445 [8.19]\n",
            "+ 0.4444444444444445 [8.2]\n",
            "+ 0.4444444444444445 [8.21]\n",
            "+ 0.4444444444444445 [8.22]\n",
            "+ 0.4444444444444445 [8.23]\n",
            "+ 0.4444444444444445 [8.24]\n",
            "+ 0.4444444444444445 [8.25]\n",
            "+ 0.4444444444444445 [8.26]\n",
            "+ 0.4444444444444445 [8.27]\n",
            "+ 0.4444444444444445 [8.28]\n",
            "+ 0.4444444444444445 [8.29]\n",
            "+ 0.4444444444444445 [8.3]\n",
            "+ 0.4444444444444445 [8.31]\n",
            "+ 0.4444444444444445 [8.32]\n",
            "+ 0.4444444444444445 [8.33]\n",
            "+ 0.4444444444444445 [8.34]\n",
            "+ 0.4444444444444445 [8.35]\n",
            "+ 0.4444444444444445 [8.36]\n",
            "+ 0.4444444444444445 [8.37]\n",
            "+ 0.4444444444444445 [8.38]\n",
            "+ 0.4444444444444445 [8.39]\n",
            "+ 0.4444444444444445 [8.4]\n",
            "+ 0.4444444444444445 [8.41]\n",
            "+ 0.4444444444444445 [8.42]\n",
            "+ 0.4444444444444445 [8.43]\n",
            "+ 0.4444444444444445 [8.44]\n",
            "+ 0.4444444444444445 [8.45]\n",
            "+ 0.4444444444444445 [8.46]\n",
            "+ 0.4444444444444445 [8.47]\n",
            "+ 0.4444444444444445 [8.48]\n",
            "+ 0.4444444444444445 [8.49]\n",
            "+ 0.4444444444444445 [8.5]\n",
            "+ 0.4444444444444445 [8.51]\n",
            "+ 0.4444444444444445 [8.52]\n",
            "+ 0.4444444444444445 [8.53]\n",
            "+ 0.4444444444444445 [8.54]\n",
            "+ 0.4444444444444445 [8.55]\n",
            "+ 0.4444444444444445 [8.56]\n",
            "+ 0.4444444444444445 [8.57]\n",
            "+ 0.4444444444444445 [8.58]\n",
            "+ 0.4444444444444445 [8.59]\n",
            "+ 0.4444444444444445 [8.6]\n",
            "+ 0.4444444444444445 [8.61]\n",
            "+ 0.4444444444444445 [8.62]\n",
            "+ 0.4444444444444445 [8.63]\n",
            "+ 0.4444444444444445 [8.64]\n",
            "+ 0.4444444444444445 [8.65]\n",
            "+ 0.4444444444444445 [8.66]\n",
            "+ 0.4444444444444445 [8.67]\n",
            "+ 0.4444444444444445 [8.68]\n",
            "+ 0.4444444444444445 [8.69]\n",
            "+ 0.4444444444444445 [8.7]\n",
            "+ 0.4444444444444445 [8.71]\n",
            "+ 0.4444444444444445 [8.72]\n",
            "+ 0.4444444444444445 [8.73]\n",
            "+ 0.4444444444444445 [8.74]\n",
            "+ 0.4444444444444445 [8.75]\n",
            "+ 0.4444444444444445 [8.76]\n",
            "+ 0.4444444444444445 [8.77]\n",
            "+ 0.4444444444444445 [8.78]\n",
            "+ 0.4444444444444445 [8.79]\n",
            "+ 0.4444444444444445 [8.8]\n",
            "+ 0.4444444444444445 [8.81]\n",
            "+ 0.4444444444444445 [8.82]\n",
            "+ 0.4444444444444445 [8.83]\n",
            "+ 0.4444444444444445 [8.84]\n",
            "+ 0.4444444444444445 [8.85]\n",
            "+ 0.4444444444444445 [8.86]\n",
            "+ 0.4444444444444445 [8.87]\n",
            "+ 0.4444444444444445 [8.88]\n",
            "+ 0.4444444444444445 [8.89]\n",
            "+ 0.4444444444444445 [8.9]\n",
            "+ 0.4444444444444445 [8.91]\n",
            "+ 0.4444444444444445 [8.92]\n",
            "+ 0.4444444444444445 [8.93]\n",
            "+ 0.4444444444444445 [8.94]\n",
            "+ 0.4444444444444445 [8.95]\n",
            "+ 0.4444444444444445 [8.96]\n",
            "+ 0.4444444444444445 [8.97]\n",
            "+ 0.4444444444444445 [8.98]\n",
            "+ 0.4444444444444445 [8.99]\n",
            "+ 0.4444444444444445 [9.]\n",
            "+ 0.4444444444444445 [9.01]\n",
            "+ 0.4444444444444445 [9.02]\n",
            "+ 0.4444444444444445 [9.03]\n",
            "+ 0.4444444444444445 [9.04]\n",
            "+ 0.4444444444444445 [9.05]\n",
            "+ 0.4444444444444445 [9.06]\n",
            "+ 0.4444444444444445 [9.07]\n",
            "+ 0.4444444444444445 [9.08]\n",
            "+ 0.4444444444444445 [9.09]\n",
            "+ 0.4444444444444445 [9.1]\n",
            "+ 0.4444444444444445 [9.11]\n",
            "+ 0.4444444444444445 [9.12]\n",
            "+ 0.4444444444444445 [9.13]\n",
            "+ 0.4444444444444445 [9.14]\n",
            "+ 0.4444444444444445 [9.15]\n",
            "+ 0.4444444444444445 [9.16]\n",
            "+ 0.4444444444444445 [9.17]\n",
            "+ 0.4444444444444445 [9.18]\n",
            "+ 0.4444444444444445 [9.19]\n",
            "+ 0.4444444444444445 [9.2]\n",
            "+ 0.4444444444444445 [9.21]\n",
            "+ 0.4444444444444445 [9.22]\n",
            "+ 0.4444444444444445 [9.23]\n",
            "+ 0.4444444444444445 [9.24]\n",
            "+ 0.4444444444444445 [9.25]\n",
            "+ 0.4444444444444445 [9.26]\n",
            "+ 0.4444444444444445 [9.27]\n",
            "+ 0.4444444444444445 [9.28]\n",
            "+ 0.4444444444444445 [9.29]\n",
            "+ 0.4444444444444445 [9.3]\n",
            "+ 0.4444444444444445 [9.31]\n",
            "+ 0.4444444444444445 [9.32]\n",
            "+ 0.4444444444444445 [9.33]\n",
            "+ 0.4444444444444445 [9.34]\n",
            "+ 0.4444444444444445 [9.35]\n",
            "+ 0.4444444444444445 [9.36]\n",
            "+ 0.4444444444444445 [9.37]\n",
            "+ 0.4444444444444445 [9.38]\n",
            "+ 0.4444444444444445 [9.39]\n",
            "+ 0.4444444444444445 [9.4]\n",
            "+ 0.4444444444444445 [9.41]\n",
            "+ 0.4444444444444445 [9.42]\n",
            "+ 0.4444444444444445 [9.43]\n",
            "+ 0.4444444444444445 [9.44]\n",
            "+ 0.4444444444444445 [9.45]\n",
            "+ 0.4444444444444445 [9.46]\n",
            "+ 0.4444444444444445 [9.47]\n",
            "+ 0.4444444444444445 [9.48]\n",
            "+ 0.4444444444444445 [9.49]\n",
            "+ 0.4444444444444445 [9.5]\n",
            "+ 0.4444444444444445 [9.51]\n",
            "+ 0.4444444444444445 [9.52]\n",
            "+ 0.4444444444444445 [9.53]\n",
            "+ 0.4444444444444445 [9.54]\n",
            "+ 0.4444444444444445 [9.55]\n",
            "+ 0.4444444444444445 [9.56]\n",
            "+ 0.4444444444444445 [9.57]\n",
            "+ 0.4444444444444445 [9.58]\n",
            "+ 0.4444444444444445 [9.59]\n",
            "+ 0.4444444444444445 [9.6]\n",
            "+ 0.4444444444444445 [9.61]\n",
            "+ 0.4444444444444445 [9.62]\n",
            "+ 0.4444444444444445 [9.63]\n",
            "+ 0.4444444444444445 [9.64]\n",
            "+ 0.4444444444444445 [9.65]\n",
            "+ 0.4444444444444445 [9.66]\n",
            "+ 0.4444444444444445 [9.67]\n",
            "+ 0.4444444444444445 [9.68]\n",
            "+ 0.4444444444444445 [9.69]\n",
            "+ 0.4444444444444445 [9.7]\n",
            "+ 0.4444444444444445 [9.71]\n",
            "+ 0.4444444444444445 [9.72]\n",
            "+ 0.4444444444444445 [9.73]\n",
            "+ 0.4444444444444445 [9.74]\n",
            "+ 0.4444444444444445 [9.75]\n",
            "+ 0.4444444444444445 [9.76]\n",
            "+ 0.4444444444444445 [9.77]\n",
            "+ 0.4444444444444445 [9.78]\n",
            "+ 0.4444444444444445 [9.79]\n",
            "+ 0.4444444444444445 [9.8]\n",
            "+ 0.4444444444444445 [9.81]\n",
            "+ 0.4444444444444445 [9.82]\n",
            "+ 0.4444444444444445 [9.83]\n",
            "+ 0.4444444444444445 [9.84]\n",
            "+ 0.4444444444444445 [9.85]\n",
            "+ 0.4444444444444445 [9.86]\n",
            "+ 0.4444444444444445 [9.87]\n",
            "+ 0.4444444444444445 [9.88]\n",
            "+ 0.4444444444444445 [9.89]\n",
            "+ 0.4444444444444445 [9.9]\n",
            "+ 0.4444444444444445 [9.91]\n",
            "+ 0.4444444444444445 [9.92]\n",
            "+ 0.4444444444444445 [9.93]\n",
            "+ 0.4444444444444445 [9.94]\n",
            "+ 0.4444444444444445 [9.95]\n",
            "+ 0.4444444444444445 [9.96]\n",
            "+ 0.4444444444444445 [9.97]\n",
            "+ 0.4444444444444445 [9.98]\n",
            "+ 0.4444444444444445 [9.99]\n",
            "+ 0.4444444444444445 [10.]\n",
            "+ 0.4444444444444445 [10.01]\n",
            "+ 0.4444444444444445 [10.02]\n",
            "+ 0.4444444444444445 [10.03]\n",
            "+ 0.4444444444444445 [10.04]\n",
            "+ 0.4444444444444445 [10.05]\n",
            "+ 0.4444444444444445 [10.06]\n",
            "+ 0.4444444444444445 [10.07]\n",
            "+ 0.4444444444444445 [10.08]\n",
            "+ 0.4444444444444445 [10.09]\n",
            "+ 0.4444444444444445 [10.1]\n",
            "+ 0.4444444444444445 [10.11]\n",
            "+ 0.4444444444444445 [10.12]\n",
            "+ 0.4444444444444445 [10.13]\n",
            "+ 0.4444444444444445 [10.14]\n",
            "+ 0.4444444444444445 [10.15]\n",
            "+ 0.4444444444444445 [10.16]\n",
            "+ 0.4444444444444445 [10.17]\n",
            "+ 0.4444444444444445 [10.18]\n",
            "+ 0.4444444444444445 [10.19]\n",
            "+ 0.4444444444444445 [10.2]\n",
            "+ 0.4444444444444445 [10.21]\n",
            "+ 0.4444444444444445 [10.22]\n",
            "+ 0.4444444444444445 [10.23]\n",
            "+ 0.4444444444444445 [10.24]\n",
            "+ 0.4444444444444445 [10.25]\n",
            "+ 0.4444444444444445 [10.26]\n",
            "+ 0.4444444444444445 [10.27]\n",
            "+ 0.4444444444444445 [10.28]\n",
            "+ 0.4444444444444445 [10.29]\n",
            "+ 0.4444444444444445 [10.3]\n",
            "+ 0.4444444444444445 [10.31]\n",
            "+ 0.4444444444444445 [10.32]\n",
            "+ 0.4444444444444445 [10.33]\n",
            "+ 0.4444444444444445 [10.34]\n",
            "+ 0.4444444444444445 [10.35]\n",
            "+ 0.4444444444444445 [10.36]\n",
            "+ 0.4444444444444445 [10.37]\n",
            "+ 0.4444444444444445 [10.38]\n",
            "+ 0.4444444444444445 [10.39]\n",
            "+ 0.4444444444444445 [10.4]\n",
            "+ 0.4444444444444445 [10.41]\n",
            "+ 0.4444444444444445 [10.42]\n",
            "+ 0.4444444444444445 [10.43]\n",
            "+ 0.4444444444444445 [10.44]\n",
            "+ 0.4444444444444445 [10.45]\n",
            "+ 0.4444444444444445 [10.46]\n",
            "+ 0.4444444444444445 [10.47]\n",
            "+ 0.4444444444444445 [10.48]\n",
            "+ 0.4444444444444445 [10.49]\n",
            "+ 0.4444444444444445 [10.5]\n",
            "+ 0.4444444444444445 [10.51]\n",
            "+ 0.4444444444444445 [10.52]\n",
            "+ 0.4444444444444445 [10.53]\n",
            "+ 0.4444444444444445 [10.54]\n",
            "+ 0.4444444444444445 [10.55]\n",
            "+ 0.4444444444444445 [10.56]\n",
            "+ 0.4444444444444445 [10.57]\n",
            "+ 0.4444444444444445 [10.58]\n",
            "+ 0.4444444444444445 [10.59]\n",
            "+ 0.4444444444444445 [10.6]\n",
            "+ 0.4444444444444445 [10.61]\n",
            "+ 0.4444444444444445 [10.62]\n",
            "+ 0.4444444444444445 [10.63]\n",
            "+ 0.4444444444444445 [10.64]\n",
            "+ 0.4444444444444445 [10.65]\n",
            "+ 0.4444444444444445 [10.66]\n",
            "+ 0.4444444444444445 [10.67]\n",
            "+ 0.4444444444444445 [10.68]\n",
            "+ 0.4444444444444445 [10.69]\n",
            "+ 0.4444444444444445 [10.7]\n",
            "+ 0.4444444444444445 [10.71]\n",
            "+ 0.4444444444444445 [10.72]\n",
            "+ 0.4444444444444445 [10.73]\n",
            "+ 0.4444444444444445 [10.74]\n",
            "+ 0.4444444444444445 [10.75]\n",
            "+ 0.4444444444444445 [10.76]\n",
            "+ 0.4444444444444445 [10.77]\n",
            "+ 0.4444444444444445 [10.78]\n",
            "+ 0.4444444444444445 [10.79]\n",
            "+ 0.4444444444444445 [10.8]\n",
            "+ 0.4444444444444445 [10.81]\n",
            "+ 0.4444444444444445 [10.82]\n",
            "+ 0.4444444444444445 [10.83]\n",
            "+ 0.4444444444444445 [10.84]\n",
            "+ 0.4444444444444445 [10.85]\n",
            "+ 0.4444444444444445 [10.86]\n",
            "+ 0.4444444444444445 [10.87]\n",
            "+ 0.4444444444444445 [10.88]\n",
            "+ 0.4444444444444445 [10.89]\n",
            "+ 0.4444444444444445 [10.9]\n",
            "+ 0.4444444444444445 [10.91]\n",
            "+ 0.4444444444444445 [10.92]\n",
            "+ 0.4444444444444445 [10.93]\n",
            "+ 0.4444444444444445 [10.94]\n",
            "+ 0.4444444444444445 [10.95]\n",
            "+ 0.4444444444444445 [10.96]\n",
            "+ 0.4444444444444445 [10.97]\n",
            "+ 0.4444444444444445 [10.98]\n",
            "+ 0.4444444444444445 [10.99]\n",
            "+ 0.4444444444444445 [11.]\n",
            "+ 0.4444444444444445 [11.01]\n",
            "+ 0.4444444444444445 [11.02]\n",
            "+ 0.4444444444444445 [11.03]\n",
            "+ 0.4444444444444445 [11.04]\n",
            "+ 0.4444444444444445 [11.05]\n",
            "+ 0.4444444444444445 [11.06]\n",
            "+ 0.4444444444444445 [11.07]\n",
            "+ 0.4444444444444445 [11.08]\n",
            "+ 0.4444444444444445 [11.09]\n",
            "+ 0.4444444444444445 [11.1]\n",
            "+ 0.4444444444444445 [11.11]\n",
            "+ 0.4444444444444445 [11.12]\n",
            "+ 0.4444444444444445 [11.13]\n",
            "+ 0.4444444444444445 [11.14]\n",
            "+ 0.4444444444444445 [11.15]\n",
            "+ 0.4444444444444445 [11.16]\n",
            "+ 0.4444444444444445 [11.17]\n",
            "+ 0.4444444444444445 [11.18]\n",
            "+ 0.4444444444444445 [11.19]\n",
            "+ 0.4444444444444445 [11.2]\n",
            "+ 0.4444444444444445 [11.21]\n",
            "+ 0.4444444444444445 [11.22]\n",
            "+ 0.4444444444444445 [11.23]\n",
            "+ 0.4444444444444445 [11.24]\n",
            "+ 0.4444444444444445 [11.25]\n",
            "+ 0.4444444444444445 [11.26]\n",
            "+ 0.4444444444444445 [11.27]\n",
            "+ 0.4444444444444445 [11.28]\n",
            "+ 0.4444444444444445 [11.29]\n",
            "+ 0.4444444444444445 [11.3]\n",
            "+ 0.4444444444444445 [11.31]\n",
            "+ 0.4444444444444445 [11.32]\n",
            "+ 0.4444444444444445 [11.33]\n",
            "+ 0.4444444444444445 [11.34]\n",
            "+ 0.4444444444444445 [11.35]\n",
            "+ 0.4444444444444445 [11.36]\n",
            "+ 0.4444444444444445 [11.37]\n",
            "+ 0.4444444444444445 [11.38]\n",
            "+ 0.4444444444444445 [11.39]\n",
            "+ 0.4444444444444445 [11.4]\n",
            "+ 0.4444444444444445 [11.41]\n",
            "+ 0.4444444444444445 [11.42]\n",
            "+ 0.4444444444444445 [11.43]\n",
            "+ 0.4444444444444445 [11.44]\n",
            "+ 0.4444444444444445 [11.45]\n",
            "+ 0.4444444444444445 [11.46]\n",
            "+ 0.4444444444444445 [11.47]\n",
            "+ 0.4444444444444445 [11.48]\n",
            "+ 0.4444444444444445 [11.49]\n",
            "+ 0.4444444444444445 [11.5]\n",
            "+ 0.4444444444444445 [11.51]\n",
            "+ 0.4444444444444445 [11.52]\n",
            "+ 0.4444444444444445 [11.53]\n",
            "+ 0.4444444444444445 [11.54]\n",
            "+ 0.4444444444444445 [11.55]\n",
            "+ 0.4444444444444445 [11.56]\n",
            "+ 0.4444444444444445 [11.57]\n",
            "+ 0.4444444444444445 [11.58]\n",
            "+ 0.4444444444444445 [11.59]\n",
            "+ 0.4444444444444445 [11.6]\n",
            "+ 0.4444444444444445 [11.61]\n",
            "+ 0.4444444444444445 [11.62]\n",
            "+ 0.4444444444444445 [11.63]\n",
            "+ 0.4444444444444445 [11.64]\n",
            "+ 0.4444444444444445 [11.65]\n",
            "+ 0.4444444444444445 [11.66]\n",
            "+ 0.4444444444444445 [11.67]\n",
            "+ 0.4444444444444445 [11.68]\n",
            "+ 0.4444444444444445 [11.69]\n",
            "+ 0.4444444444444445 [11.7]\n",
            "+ 0.4444444444444445 [11.71]\n",
            "+ 0.4444444444444445 [11.72]\n",
            "+ 0.4444444444444445 [11.73]\n",
            "+ 0.4444444444444445 [11.74]\n",
            "+ 0.4444444444444445 [11.75]\n",
            "+ 0.4444444444444445 [11.76]\n",
            "+ 0.4444444444444445 [11.77]\n",
            "+ 0.4444444444444445 [11.78]\n",
            "+ 0.4444444444444445 [11.79]\n",
            "+ 0.4444444444444445 [11.8]\n",
            "+ 0.4444444444444445 [11.81]\n",
            "+ 0.4444444444444445 [11.82]\n",
            "+ 0.4444444444444445 [11.83]\n",
            "+ 0.4444444444444445 [11.84]\n",
            "+ 0.4444444444444445 [11.85]\n",
            "+ 0.4444444444444445 [11.86]\n",
            "+ 0.4444444444444445 [11.87]\n",
            "+ 0.4444444444444445 [11.88]\n",
            "+ 0.4444444444444445 [11.89]\n",
            "+ 0.4444444444444445 [11.9]\n",
            "+ 0.4444444444444445 [11.91]\n",
            "+ 0.4444444444444445 [11.92]\n",
            "+ 0.4444444444444445 [11.93]\n",
            "+ 0.4444444444444445 [11.94]\n",
            "+ 0.4444444444444445 [11.95]\n",
            "+ 0.4444444444444445 [11.96]\n",
            "+ 0.4444444444444445 [11.97]\n",
            "+ 0.4444444444444445 [11.98]\n",
            "+ 0.4444444444444445 [11.99]\n",
            "+ 0.4444444444444445 [12.]\n",
            "+ 0.4444444444444445 [12.01]\n",
            "+ 0.4444444444444445 [12.02]\n",
            "+ 0.4444444444444445 [12.03]\n",
            "+ 0.4444444444444445 [12.04]\n",
            "+ 0.4444444444444445 [12.05]\n",
            "+ 0.4444444444444445 [12.06]\n",
            "+ 0.4444444444444445 [12.07]\n",
            "+ 0.4444444444444445 [12.08]\n",
            "+ 0.4444444444444445 [12.09]\n",
            "+ 0.4444444444444445 [12.1]\n",
            "+ 0.4444444444444445 [12.11]\n",
            "+ 0.4444444444444445 [12.12]\n",
            "+ 0.4444444444444445 [12.13]\n",
            "+ 0.4444444444444445 [12.14]\n",
            "+ 0.4444444444444445 [12.15]\n",
            "+ 0.4444444444444445 [12.16]\n",
            "+ 0.4444444444444445 [12.17]\n",
            "+ 0.4444444444444445 [12.18]\n",
            "+ 0.4444444444444445 [12.19]\n",
            "+ 0.4444444444444445 [12.2]\n",
            "+ 0.4444444444444445 [12.21]\n",
            "+ 0.4444444444444445 [12.22]\n",
            "+ 0.4444444444444445 [12.23]\n",
            "+ 0.4444444444444445 [12.24]\n",
            "+ 0.4444444444444445 [12.25]\n",
            "+ 0.4444444444444445 [12.26]\n",
            "+ 0.4444444444444445 [12.27]\n",
            "+ 0.4444444444444445 [12.28]\n",
            "+ 0.4444444444444445 [12.29]\n",
            "+ 0.4444444444444445 [12.3]\n",
            "+ 0.4444444444444445 [12.31]\n",
            "+ 0.4444444444444445 [12.32]\n",
            "+ 0.4444444444444445 [12.33]\n",
            "+ 0.4444444444444445 [12.34]\n",
            "+ 0.4444444444444445 [12.35]\n",
            "+ 0.4444444444444445 [12.36]\n",
            "+ 0.4444444444444445 [12.37]\n",
            "+ 0.4444444444444445 [12.38]\n",
            "+ 0.4444444444444445 [12.39]\n",
            "+ 0.4444444444444445 [12.4]\n",
            "+ 0.4444444444444445 [12.41]\n",
            "+ 0.4444444444444445 [12.42]\n",
            "+ 0.4444444444444445 [12.43]\n",
            "+ 0.4444444444444445 [12.44]\n",
            "+ 0.4444444444444445 [12.45]\n",
            "+ 0.4444444444444445 [12.46]\n",
            "+ 0.4444444444444445 [12.47]\n",
            "+ 0.4444444444444445 [12.48]\n",
            "+ 0.4444444444444445 [12.49]\n",
            "+ 0.4444444444444445 [12.5]\n",
            "+ 0.4444444444444445 [12.51]\n",
            "+ 0.4444444444444445 [12.52]\n",
            "+ 0.4444444444444445 [12.53]\n",
            "+ 0.4444444444444445 [12.54]\n",
            "+ 0.4444444444444445 [12.55]\n",
            "+ 0.4444444444444445 [12.56]\n",
            "+ 0.4444444444444445 [12.57]\n",
            "+ 0.4444444444444445 [12.58]\n",
            "+ 0.4444444444444445 [12.59]\n",
            "+ 0.4444444444444445 [12.6]\n",
            "+ 0.4444444444444445 [12.61]\n",
            "+ 0.4444444444444445 [12.62]\n",
            "+ 0.4444444444444445 [12.63]\n",
            "+ 0.4444444444444445 [12.64]\n",
            "+ 0.4444444444444445 [12.65]\n",
            "+ 0.4444444444444445 [12.66]\n",
            "+ 0.4444444444444445 [12.67]\n",
            "+ 0.4444444444444445 [12.68]\n",
            "+ 0.4444444444444445 [12.69]\n",
            "+ 0.4444444444444445 [12.7]\n",
            "+ 0.4444444444444445 [12.71]\n",
            "+ 0.4444444444444445 [12.72]\n",
            "+ 0.4444444444444445 [12.73]\n",
            "+ 0.4444444444444445 [12.74]\n",
            "+ 0.4444444444444445 [12.75]\n",
            "+ 0.4444444444444445 [12.76]\n",
            "+ 0.4444444444444445 [12.77]\n",
            "+ 0.4444444444444445 [12.78]\n",
            "+ 0.4444444444444445 [12.79]\n",
            "+ 0.4444444444444445 [12.8]\n",
            "+ 0.4444444444444445 [12.81]\n",
            "+ 0.4444444444444445 [12.82]\n",
            "+ 0.4444444444444445 [12.83]\n",
            "+ 0.4444444444444445 [12.84]\n",
            "+ 0.4444444444444445 [12.85]\n",
            "+ 0.4444444444444445 [12.86]\n",
            "+ 0.4444444444444445 [12.87]\n",
            "+ 0.4444444444444445 [12.88]\n",
            "+ 0.4444444444444445 [12.89]\n",
            "+ 0.4444444444444445 [12.9]\n",
            "+ 0.4444444444444445 [12.91]\n",
            "+ 0.4444444444444445 [12.92]\n",
            "+ 0.4444444444444445 [12.93]\n",
            "+ 0.4444444444444445 [12.94]\n",
            "+ 0.4444444444444445 [12.95]\n",
            "+ 0.4444444444444445 [12.96]\n",
            "+ 0.4444444444444445 [12.97]\n",
            "+ 0.4444444444444445 [12.98]\n",
            "+ 0.4444444444444445 [12.99]\n",
            "+ 0.4444444444444445 [13.]\n",
            "+ 0.4444444444444445 [13.01]\n",
            "+ 0.4444444444444445 [13.02]\n",
            "+ 0.4444444444444445 [13.03]\n",
            "+ 0.4444444444444445 [13.04]\n",
            "+ 0.4444444444444445 [13.05]\n",
            "++ 0.4444444444444445 [13.15]\n",
            "++ 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n",
            "--- 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n",
            "--- 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n",
            "--- 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n",
            "--- 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n",
            "--- 0.4444444444444445 [13.25]\n",
            "++ 0.4444444444444445 [13.35]\n",
            "++ 0.4444444444444445 [13.45]\n",
            "++ 0.4444444444444445 [13.55]\n",
            "++ 0.4444444444444445 [13.65]\n",
            "++ 0.4444444444444445 [13.75]\n",
            "++ 0.4444444444444445 [13.85]\n",
            "++ 0.4444444444444445 [13.95]\n",
            "++ 0.4444444444444445 [14.05]\n",
            "++ 0.4444444444444445 [14.15]\n",
            "++ 0.4444444444444445 [14.25]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn [17], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# print(currentState)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m terminated:\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# get the Q-value (1 by 2 vector)\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m     Qvalues\u001b[38;5;241m=\u001b[39m\u001b[43mloaded_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrentState\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# select the action that gives the max Qvalue\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     action\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39mwhere(Qvalues[\u001b[38;5;241m0\u001b[39m,:]\u001b[38;5;241m==\u001b[39mnp\u001b[38;5;241m.\u001b[39mmax(Qvalues[\u001b[38;5;241m0\u001b[39m,:]))[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\training.py:1758\u001b[0m, in \u001b[0;36mModel.predict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1750\u001b[0m   \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[0;32m   1751\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   1752\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mUsing Model.predict with \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1753\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mMultiWorkerDistributionStrategy or TPUStrategy and \u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1754\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mAutoShardPolicy.FILE might lead to out-of-order result\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m   1755\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m. Consider setting it to AutoShardPolicy.DATA.\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   1756\u001b[0m         stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m-> 1758\u001b[0m data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39;49mget_data_handler(\n\u001b[0;32m   1759\u001b[0m     x\u001b[39m=\u001b[39;49mx,\n\u001b[0;32m   1760\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1761\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49msteps,\n\u001b[0;32m   1762\u001b[0m     initial_epoch\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m   1763\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m   1764\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1765\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1766\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1767\u001b[0m     model\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[0;32m   1768\u001b[0m     steps_per_execution\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_steps_per_execution)\n\u001b[0;32m   1770\u001b[0m \u001b[39m# Container that configures and calls `tf.keras.Callback`s.\u001b[39;00m\n\u001b[0;32m   1771\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(callbacks, callbacks_module\u001b[39m.\u001b[39mCallbackList):\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:1403\u001b[0m, in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(kwargs[\u001b[39m\"\u001b[39m\u001b[39mmodel\u001b[39m\u001b[39m\"\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m_cluster_coordinator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   1402\u001b[0m   \u001b[39mreturn\u001b[39;00m _ClusterCoordinatorDataHandler(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m-> 1403\u001b[0m \u001b[39mreturn\u001b[39;00m DataHandler(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:1153\u001b[0m, in \u001b[0;36mDataHandler.__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1150\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution \u001b[39m=\u001b[39m steps_per_execution\n\u001b[0;32m   1152\u001b[0m adapter_cls \u001b[39m=\u001b[39m select_data_adapter(x, y)\n\u001b[1;32m-> 1153\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_adapter \u001b[39m=\u001b[39m adapter_cls(\n\u001b[0;32m   1154\u001b[0m     x,\n\u001b[0;32m   1155\u001b[0m     y,\n\u001b[0;32m   1156\u001b[0m     batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[0;32m   1157\u001b[0m     steps\u001b[39m=\u001b[39;49msteps_per_epoch,\n\u001b[0;32m   1158\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs \u001b[39m-\u001b[39;49m initial_epoch,\n\u001b[0;32m   1159\u001b[0m     sample_weights\u001b[39m=\u001b[39;49msample_weight,\n\u001b[0;32m   1160\u001b[0m     shuffle\u001b[39m=\u001b[39;49mshuffle,\n\u001b[0;32m   1161\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[0;32m   1162\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[0;32m   1163\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[0;32m   1164\u001b[0m     distribution_strategy\u001b[39m=\u001b[39;49mtf\u001b[39m.\u001b[39;49mdistribute\u001b[39m.\u001b[39;49mget_strategy(),\n\u001b[0;32m   1165\u001b[0m     model\u001b[39m=\u001b[39;49mmodel)\n\u001b[0;32m   1167\u001b[0m strategy \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mget_strategy()\n\u001b[0;32m   1169\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_current_step \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:325\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m     flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mshuffle(\u001b[39m1024\u001b[39m)\u001b[39m.\u001b[39mrepeat(epochs)\n\u001b[0;32m    323\u001b[0m   \u001b[39mreturn\u001b[39;00m flat_dataset\n\u001b[1;32m--> 325\u001b[0m indices_dataset \u001b[39m=\u001b[39m indices_dataset\u001b[39m.\u001b[39;49mflat_map(slice_batch_indices)\n\u001b[0;32m    327\u001b[0m dataset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslice_inputs(indices_dataset, inputs)\n\u001b[0;32m    329\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2048\u001b[0m, in \u001b[0;36mDatasetV2.flat_map\u001b[1;34m(self, map_func, name)\u001b[0m\n\u001b[0;32m   2014\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_map\u001b[39m(\u001b[39mself\u001b[39m, map_func, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m   2015\u001b[0m   \u001b[39m\"\"\"Maps `map_func` across this dataset and flattens the result.\u001b[39;00m\n\u001b[0;32m   2016\u001b[0m \n\u001b[0;32m   2017\u001b[0m \u001b[39m  The type signature is:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2046\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m   2047\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2048\u001b[0m   \u001b[39mreturn\u001b[39;00m FlatMapDataset(\u001b[39mself\u001b[39;49m, map_func, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5549\u001b[0m, in \u001b[0;36mFlatMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, name)\u001b[0m\n\u001b[0;32m   5547\u001b[0m \u001b[39m\"\"\"See `Dataset.flat_map()` for details.\"\"\"\u001b[39;00m\n\u001b[0;32m   5548\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_dataset \u001b[39m=\u001b[39m input_dataset\n\u001b[1;32m-> 5549\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func \u001b[39m=\u001b[39m StructuredFunctionWrapper(\n\u001b[0;32m   5550\u001b[0m     map_func, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_transformation_name(), dataset\u001b[39m=\u001b[39;49minput_dataset)\n\u001b[0;32m   5551\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure, DatasetSpec):\n\u001b[0;32m   5552\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m   5553\u001b[0m       \u001b[39m\"\u001b[39m\u001b[39mThe `map_func` argument must return a `Dataset` object. Got \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   5554\u001b[0m       \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m_get_type(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_map_func\u001b[39m.\u001b[39moutput_structure)\u001b[39m!r}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4533\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   4526\u001b[0m       warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   4527\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4528\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4529\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   4530\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   4531\u001b[0m     fn_factory \u001b[39m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m-> 4533\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function \u001b[39m=\u001b[39m fn_factory()\n\u001b[0;32m   4534\u001b[0m \u001b[39m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m   4535\u001b[0m add_to_graph \u001b[39m&\u001b[39m\u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m context\u001b[39m.\u001b[39mexecuting_eagerly()\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3244\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3235\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_concrete_function\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m   3236\u001b[0m   \u001b[39m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   3237\u001b[0m \n\u001b[0;32m   3238\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3242\u001b[0m \u001b[39m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   3243\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3244\u001b[0m   graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_concrete_function_garbage_collected(\n\u001b[0;32m   3245\u001b[0m       \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   3246\u001b[0m   graph_function\u001b[39m.\u001b[39m_garbage_collector\u001b[39m.\u001b[39mrelease()  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   3247\u001b[0m   \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3210\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m   args, kwargs \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m-> 3210\u001b[0m   graph_function, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_define_function(args, kwargs)\n\u001b[0;32m   3211\u001b[0m   seen_names \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m()\n\u001b[0;32m   3212\u001b[0m   captured \u001b[39m=\u001b[39m object_identity\u001b[39m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   3213\u001b[0m       graph_function\u001b[39m.\u001b[39mgraph\u001b[39m.\u001b[39minternal_captures)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3557\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   3553\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_define_function_with_shape_relaxation(\n\u001b[0;32m   3554\u001b[0m       args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[0;32m   3556\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mmissed\u001b[39m.\u001b[39madd(call_context_key)\n\u001b[1;32m-> 3557\u001b[0m graph_function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_graph_function(args, kwargs)\n\u001b[0;32m   3558\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_cache\u001b[39m.\u001b[39mprimary[cache_key] \u001b[39m=\u001b[39m graph_function\n\u001b[0;32m   3560\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:3392\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   3387\u001b[0m missing_arg_names \u001b[39m=\u001b[39m [\n\u001b[0;32m   3388\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m_\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (arg, i) \u001b[39mfor\u001b[39;00m i, arg \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   3389\u001b[0m ]\n\u001b[0;32m   3390\u001b[0m arg_names \u001b[39m=\u001b[39m base_arg_names \u001b[39m+\u001b[39m missing_arg_names\n\u001b[0;32m   3391\u001b[0m graph_function \u001b[39m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 3392\u001b[0m     func_graph_module\u001b[39m.\u001b[39;49mfunc_graph_from_py_func(\n\u001b[0;32m   3393\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name,\n\u001b[0;32m   3394\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_python_function,\n\u001b[0;32m   3395\u001b[0m         args,\n\u001b[0;32m   3396\u001b[0m         kwargs,\n\u001b[0;32m   3397\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_signature,\n\u001b[0;32m   3398\u001b[0m         autograph\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph,\n\u001b[0;32m   3399\u001b[0m         autograph_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_autograph_options,\n\u001b[0;32m   3400\u001b[0m         arg_names\u001b[39m=\u001b[39;49marg_names,\n\u001b[0;32m   3401\u001b[0m         override_flat_arg_shapes\u001b[39m=\u001b[39;49moverride_flat_arg_shapes,\n\u001b[0;32m   3402\u001b[0m         capture_by_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_capture_by_value),\n\u001b[0;32m   3403\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_function_attributes,\n\u001b[0;32m   3404\u001b[0m     function_spec\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_spec,\n\u001b[0;32m   3405\u001b[0m     \u001b[39m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   3406\u001b[0m     \u001b[39m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   3407\u001b[0m     \u001b[39m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   3408\u001b[0m     \u001b[39m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   3409\u001b[0m     shared_func_graph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n\u001b[0;32m   3410\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1143\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1140\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1141\u001b[0m   _, original_func \u001b[39m=\u001b[39m tf_decorator\u001b[39m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1143\u001b[0m func_outputs \u001b[39m=\u001b[39m python_func(\u001b[39m*\u001b[39;49mfunc_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfunc_kwargs)\n\u001b[0;32m   1145\u001b[0m \u001b[39m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1146\u001b[0m \u001b[39m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1147\u001b[0m func_outputs \u001b[39m=\u001b[39m nest\u001b[39m.\u001b[39mmap_structure(convert, func_outputs,\n\u001b[0;32m   1148\u001b[0m                                   expand_composites\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4510\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4504\u001b[0m \u001b[39m@eager_function\u001b[39m\u001b[39m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m   4505\u001b[0m     input_signature\u001b[39m=\u001b[39mstructure\u001b[39m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m   4506\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_input_structure),\n\u001b[0;32m   4507\u001b[0m     autograph\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   4508\u001b[0m     attributes\u001b[39m=\u001b[39mdefun_kwargs)\n\u001b[0;32m   4509\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_fn\u001b[39m(\u001b[39m*\u001b[39margs):  \u001b[39m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m-> 4510\u001b[0m   ret \u001b[39m=\u001b[39m wrapper_helper(\u001b[39m*\u001b[39;49margs)\n\u001b[0;32m   4511\u001b[0m   ret \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_tensor_list(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_structure, ret)\n\u001b[0;32m   4512\u001b[0m   \u001b[39mreturn\u001b[39;00m [ops\u001b[39m.\u001b[39mconvert_to_tensor(t) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m ret]\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4440\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m   4438\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m   4439\u001b[0m   nested_args \u001b[39m=\u001b[39m (nested_args,)\n\u001b[1;32m-> 4440\u001b[0m ret \u001b[39m=\u001b[39m autograph\u001b[39m.\u001b[39;49mtf_convert(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func, ag_ctx)(\u001b[39m*\u001b[39;49mnested_args)\n\u001b[0;32m   4441\u001b[0m \u001b[39mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m   4442\u001b[0m   ret \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(ret)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:696\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    694\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    695\u001b[0m   \u001b[39mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 696\u001b[0m     \u001b[39mreturn\u001b[39;00m converted_call(f, args, kwargs, options\u001b[39m=\u001b[39;49moptions)\n\u001b[0;32m    697\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    698\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(e, \u001b[39m'\u001b[39m\u001b[39mag_error_metadata\u001b[39m\u001b[39m'\u001b[39m):\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:383\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    380\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39muser_requested \u001b[39mand\u001b[39;00m conversion\u001b[39m.\u001b[39mis_allowlisted(f):\n\u001b[1;32m--> 383\u001b[0m   \u001b[39mreturn\u001b[39;00m _call_unconverted(f, args, kwargs, options)\n\u001b[0;32m    385\u001b[0m \u001b[39m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[39;00m\n\u001b[0;32m    386\u001b[0m \u001b[39m# call conversion from generated code while in nonrecursive mode. In that\u001b[39;00m\n\u001b[0;32m    387\u001b[0m \u001b[39m# case we evidently don't want to recurse, but we still have to convert\u001b[39;00m\n\u001b[0;32m    388\u001b[0m \u001b[39m# things like builtins.\u001b[39;00m\n\u001b[0;32m    389\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m options\u001b[39m.\u001b[39minternal_convert_user_code:\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:464\u001b[0m, in \u001b[0;36m_call_unconverted\u001b[1;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[0;32m    461\u001b[0m   \u001b[39mreturn\u001b[39;00m f\u001b[39m.\u001b[39m\u001b[39m__self__\u001b[39m\u001b[39m.\u001b[39mcall(args, kwargs)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 464\u001b[0m   \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    465\u001b[0m \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39margs)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\keras\\engine\\data_adapter.py:316\u001b[0m, in \u001b[0;36mTensorLikeDataAdapter.__init__.<locals>.slice_batch_indices\u001b[1;34m(indices)\u001b[0m\n\u001b[0;32m    314\u001b[0m flat_dataset \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataset\u001b[39m.\u001b[39mfrom_tensor_slices(first_k_indices)\n\u001b[0;32m    315\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_partial_batch_size:\n\u001b[1;32m--> 316\u001b[0m   index_remainder \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mdata\u001b[39m.\u001b[39;49mDataset\u001b[39m.\u001b[39;49mfrom_tensors(tf\u001b[39m.\u001b[39;49mslice(\n\u001b[0;32m    317\u001b[0m       indices, [num_in_full_batch], [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_partial_batch_size]))\n\u001b[0;32m    318\u001b[0m   flat_dataset \u001b[39m=\u001b[39m flat_dataset\u001b[39m.\u001b[39mconcatenate(index_remainder)\n\u001b[0;32m    320\u001b[0m \u001b[39mif\u001b[39;00m shuffle \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbatch\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    321\u001b[0m   \u001b[39m# 1024 is a magic constant that has not been properly evaluated\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:701\u001b[0m, in \u001b[0;36mDatasetV2.from_tensors\u001b[1;34m(tensors, name)\u001b[0m\n\u001b[0;32m    664\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    665\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensors\u001b[39m(tensors, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    666\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` with a single element, comprising the given tensors.\u001b[39;00m\n\u001b[0;32m    667\u001b[0m \n\u001b[0;32m    668\u001b[0m \u001b[39m  `from_tensors` produces a dataset containing only a single element. To slice\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    700\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorDataset(tensors, name\u001b[39m=\u001b[39;49mname)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:4645\u001b[0m, in \u001b[0;36mTensorDataset.__init__\u001b[1;34m(self, element, name)\u001b[0m\n\u001b[0;32m   4643\u001b[0m \u001b[39mif\u001b[39;00m name \u001b[39mor\u001b[39;00m compat\u001b[39m.\u001b[39mforward_compatible(\u001b[39m2021\u001b[39m, \u001b[39m9\u001b[39m, \u001b[39m30\u001b[39m):\n\u001b[0;32m   4644\u001b[0m   kwargs[\u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_metadata\u001b[39m.\u001b[39mSerializeToString()\n\u001b[1;32m-> 4645\u001b[0m variant_tensor \u001b[39m=\u001b[39m gen_dataset_ops\u001b[39m.\u001b[39;49mtensor_dataset(\n\u001b[0;32m   4646\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tensors,\n\u001b[0;32m   4647\u001b[0m     output_shapes\u001b[39m=\u001b[39;49mstructure\u001b[39m.\u001b[39;49mget_flat_tensor_shapes(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_structure),\n\u001b[0;32m   4648\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m   4649\u001b[0m \u001b[39msuper\u001b[39m(TensorDataset, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(variant_tensor)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:7395\u001b[0m, in \u001b[0;36mtensor_dataset\u001b[1;34m(components, output_shapes, metadata, name)\u001b[0m\n\u001b[0;32m   7393\u001b[0m   metadata \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   7394\u001b[0m metadata \u001b[39m=\u001b[39m _execute\u001b[39m.\u001b[39mmake_str(metadata, \u001b[39m\"\u001b[39m\u001b[39mmetadata\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m-> 7395\u001b[0m _, _, _op, _outputs \u001b[39m=\u001b[39m _op_def_library\u001b[39m.\u001b[39;49m_apply_op_helper(\n\u001b[0;32m   7396\u001b[0m       \u001b[39m\"\u001b[39;49m\u001b[39mTensorDataset\u001b[39;49m\u001b[39m\"\u001b[39;49m, components\u001b[39m=\u001b[39;49mcomponents, output_shapes\u001b[39m=\u001b[39;49moutput_shapes,\n\u001b[0;32m   7397\u001b[0m                        metadata\u001b[39m=\u001b[39;49mmetadata, name\u001b[39m=\u001b[39;49mname)\n\u001b[0;32m   7398\u001b[0m _result \u001b[39m=\u001b[39m _outputs[:]\n\u001b[0;32m   7399\u001b[0m \u001b[39mif\u001b[39;00m _execute\u001b[39m.\u001b[39mmust_record_gradient():\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:744\u001b[0m, in \u001b[0;36m_apply_op_helper\u001b[1;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    739\u001b[0m must_colocate_inputs \u001b[39m=\u001b[39m [val \u001b[39mfor\u001b[39;00m arg, val \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(op_def\u001b[39m.\u001b[39minput_arg, inputs)\n\u001b[0;32m    740\u001b[0m                         \u001b[39mif\u001b[39;00m arg\u001b[39m.\u001b[39mis_ref]\n\u001b[0;32m    741\u001b[0m \u001b[39mwith\u001b[39;00m _MaybeColocateWith(must_colocate_inputs):\n\u001b[0;32m    742\u001b[0m   \u001b[39m# Add Op to graph\u001b[39;00m\n\u001b[0;32m    743\u001b[0m   \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m--> 744\u001b[0m   op \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39;49m_create_op_internal(op_type_name, inputs, dtypes\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,\n\u001b[0;32m    745\u001b[0m                              name\u001b[39m=\u001b[39;49mscope, input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m    746\u001b[0m                              attrs\u001b[39m=\u001b[39;49mattr_protos, op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m    748\u001b[0m \u001b[39m# `outputs` is returned as a separate return value so that the output\u001b[39;00m\n\u001b[0;32m    749\u001b[0m \u001b[39m# tensors can the `op` per se can be decoupled so that the\u001b[39;00m\n\u001b[0;32m    750\u001b[0m \u001b[39m# `op_callbacks` can function properly. See framework/op_callbacks.py\u001b[39;00m\n\u001b[0;32m    751\u001b[0m \u001b[39m# for more details.\u001b[39;00m\n\u001b[0;32m    752\u001b[0m outputs \u001b[39m=\u001b[39m op\u001b[39m.\u001b[39moutputs\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:689\u001b[0m, in \u001b[0;36mFuncGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    687\u001b[0m   inp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcapture(inp)\n\u001b[0;32m    688\u001b[0m   captured_inputs\u001b[39m.\u001b[39mappend(inp)\n\u001b[1;32m--> 689\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m(FuncGraph, \u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_create_op_internal(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    690\u001b[0m     op_type, captured_inputs, dtypes, input_types, name, attrs, op_def,\n\u001b[0;32m    691\u001b[0m     compute_device)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:3697\u001b[0m, in \u001b[0;36mGraph._create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3694\u001b[0m \u001b[39m# _create_op_helper mutates the new Operation. `_mutation_lock` ensures a\u001b[39;00m\n\u001b[0;32m   3695\u001b[0m \u001b[39m# Session.run call cannot occur between creating and mutating the op.\u001b[39;00m\n\u001b[0;32m   3696\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mutation_lock():\n\u001b[1;32m-> 3697\u001b[0m   ret \u001b[39m=\u001b[39m Operation(\n\u001b[0;32m   3698\u001b[0m       node_def,\n\u001b[0;32m   3699\u001b[0m       \u001b[39mself\u001b[39;49m,\n\u001b[0;32m   3700\u001b[0m       inputs\u001b[39m=\u001b[39;49minputs,\n\u001b[0;32m   3701\u001b[0m       output_types\u001b[39m=\u001b[39;49mdtypes,\n\u001b[0;32m   3702\u001b[0m       control_inputs\u001b[39m=\u001b[39;49mcontrol_inputs,\n\u001b[0;32m   3703\u001b[0m       input_types\u001b[39m=\u001b[39;49minput_types,\n\u001b[0;32m   3704\u001b[0m       original_op\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_default_original_op,\n\u001b[0;32m   3705\u001b[0m       op_def\u001b[39m=\u001b[39;49mop_def)\n\u001b[0;32m   3706\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_op_helper(ret, compute_device\u001b[39m=\u001b[39mcompute_device)\n\u001b[0;32m   3707\u001b[0m \u001b[39mreturn\u001b[39;00m ret\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:2097\u001b[0m, in \u001b[0;36mOperation.__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   2095\u001b[0m   \u001b[39mif\u001b[39;00m op_def \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2096\u001b[0m     op_def \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39m_get_op_def(node_def\u001b[39m.\u001b[39mop)\n\u001b[1;32m-> 2097\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op \u001b[39m=\u001b[39m _create_c_op(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_graph, node_def, inputs,\n\u001b[0;32m   2098\u001b[0m                             control_input_ops, op_def)\n\u001b[0;32m   2099\u001b[0m   name \u001b[39m=\u001b[39m compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mname)\n\u001b[0;32m   2101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_traceback \u001b[39m=\u001b[39m tf_stack\u001b[39m.\u001b[39mextract_stack_for_node(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_c_op)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
            "File \u001b[1;32mc:\\Python\\3870\\WPy64-3870\\python-3.8.7.amd64\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1909\u001b[0m, in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1907\u001b[0m inputs \u001b[39m=\u001b[39m _reconstruct_sequence_inputs(op_def, inputs, node_def\u001b[39m.\u001b[39mattr)\n\u001b[0;32m   1908\u001b[0m \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 1909\u001b[0m op_desc \u001b[39m=\u001b[39m pywrap_tf_session\u001b[39m.\u001b[39;49mTF_NewOperation(graph\u001b[39m.\u001b[39;49m_c_graph,\n\u001b[0;32m   1910\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mop),\n\u001b[0;32m   1911\u001b[0m                                             compat\u001b[39m.\u001b[39;49mas_str(node_def\u001b[39m.\u001b[39;49mname))\n\u001b[0;32m   1912\u001b[0m \u001b[39mif\u001b[39;00m node_def\u001b[39m.\u001b[39mdevice:\n\u001b[0;32m   1913\u001b[0m   pywrap_tf_session\u001b[39m.\u001b[39mTF_SetDevice(op_desc, compat\u001b[39m.\u001b[39mas_str(node_def\u001b[39m.\u001b[39mdevice))\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "terminalState=False\n",
        "currentState = np.array([5])\n",
        "terminated = False\n",
        "# print(currentState)\n",
        "while not terminated:\n",
        "    # get the Q-value (1 by 2 vector)\n",
        "    Qvalues=loaded_model.predict(currentState.reshape(1,1))\n",
        "    # select the action that gives the max Qvalue\n",
        "    action=np.random.choice(np.where(Qvalues[0,:]==np.max(Qvalues[0,:]))[0])\n",
        "    # print(action)\n",
        "\n",
        "    # if you want random actions for comparison\n",
        "    #action = env.action_space.sample()\n",
        "    # apply the action\n",
        "    r, currentState = step(action, currentState)\n",
        "    if currentState<=0:\n",
        "        terminated = True\n",
        "\n",
        "    print(actions_str[action], r,currentState)\n",
        "    # sum the rewards\n",
        "    # sumObtainedRewards+=currentReward"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rew(0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "61251865e30e62dadd10c02289a005295abe3e4116391d19d949c6135f5bb5ad"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
